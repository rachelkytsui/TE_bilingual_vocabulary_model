---
title: "TE_computation"
date: "Last update: Dec 2nd 2020"
output: html_document
---

# Preparations
## load libraries
```{r setup, include=FALSE}

library(here)
library(tidyverse)
library(tidylog)
library(ggpubr)
library(regclass) # for correlation
library(effects)
# library(jtools)
library(FRACTION) # this allows us to use the is.wholenumber function

`%notin%` <- Negate(`%in%`)

```

# Generating dataframe for computational model
#### Set 1: Calculate other variables based on V, W, and B ####
```{r}
### Generating variables: V, W, and B
## V = 600 ##
# Items on vocabulary measure (e.g. words on the CDI)
V <- 600

# Total word vocabulary of a child
W <- seq(0, 2*V, by = 25) 

# Balance, i.e. proportion use of non-dominant language (B ≤ .50)
B <- seq(0.5, 1, by = 0.025) 

# Generating sequence of W and B
W_seq <- W %>% # a sequence of 0 to 2V
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>%  # a sequence of 0.5 to 1
  rep(., length(W)) # generate N repetitions of the sequence based on length of W

# Creating the dataframe
TE_V600 <- data.frame(V, W_seq) %>%
  arrange(W_seq) %>%
  rename(W = W_seq) %>%
  mutate(B = B_seq)
  

## V = 450 ##
# Items on vocabulary measure (e.g. words on the CDI)
V <- 450

# Total word vocabulary of a child
W <- seq(0, 2*V, by = 25) 

# Balance, i.e. proportion use of non-dominant language (B ≤ .50)
B <- seq(0.5, 1, by = 0.025) 

# Generating sequence of W and B
W_seq <- W %>% # a sequence of 0 to 2V
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>%  # a sequence of 0.5 to 1
  rep(., length(W)) # generate N repetitions of the sequence based on length of W

# Creating the dataframe
TE_V450 <- data.frame(V, W_seq) %>%
  arrange(W_seq) %>%
  rename(W = W_seq) %>%
  mutate(B = B_seq) 
  

## V = 300 ##
# Items on vocabulary measure (e.g. words on the CDI)
V <- 300

# Total word vocabulary of a child
W <- seq(0, 2*V, by = 25) 

# Balance, i.e. proportion use of non-dominant language (B ≤ .50)
B <- seq(0.5, 1, by = 0.025) 

# Generating sequence of W and B
W_seq <- W %>% # a sequence of 0 to 2V
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>%  # a sequence of 0.5 to 1
  rep(., length(W)) # generate N repetitions of the sequence based on length of W

# Creating the dataframe
TE_V300 <- data.frame(V, W_seq) %>%
  arrange(W_seq) %>%
  rename(W = W_seq) %>%
  mutate(B = B_seq) 
 
 
## V = 150 ##
# Items on vocabulary measure (e.g. words on the CDI)
V <- 150

# Total word vocabulary of a child
W <- seq(0, 2*V, by = 25) 

# Balance, i.e. proportion use of non-dominant language (B ≤ .50)
B <- seq(0.5, 1, by = 0.025) 

# Generating sequence of W and B
W_seq <- W %>% # a sequence of 0 to 2V
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>%  # a sequence of 0.5 to 1
  rep(., length(W)) # generate N repetitions of the sequence based on length of W

# Creating the dataframe
TE_V150 <- data.frame(V, W_seq) %>%
  arrange(W_seq) %>%
  rename(W = W_seq) %>%
  mutate(B = B_seq) 


### Combining all dataframes and Calculate other variables
TE_fromVWB <- TE_fromVWB <- rbind(TE_V150, TE_V300, TE_V450, TE_V600) %>%
  # Create other variables
  mutate(D = B*W, # Words produced in the dominant language
         N = (1-B)*W, # Words produced in non-dominant language
         TE = (D*N)/V, # If D and N are independent, TE = DN/V
         C = W-TE, # Concept vocabulary (or total conceptual vocabulary size)
         Du = D-TE, # Unique words in dominant language
         Nu = N-TE) %>% # Unique words in non-dominant language
  # In reality, it would be impossible to get negative numbers for any vocabulary variables, so filter out all cases with negative numbers
  filter(Nu >= 0) %>%
  # It is also not possible for D or N to exceed V, so filter out cases where D or N > V
  filter_at(vars(D, N), all_vars(. <= V)) %>%
  # filter out cases where D or N aren't whole numbers
  filter_at(vars(D, N), any_vars(is.wholenumber(.))) 
```

#### Set 2: Calculate other variables based on V, D, and N ####
```{r}
### Generating variables: D and N
## V = 600 ##
V <- 600
D <- seq(0, V, by = 25) 
N <- seq(0, V, by = 25)

# Generating sequence of D and N
D_seq <- D %>% # Words produced in the dominant language
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

N_seq <- N %>% # Words produced in non-dominant language
  rep(., length(D)) # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V600 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(N = N_seq) 


## V = 450 ##
V <- 450
D <- seq(0, V, by = 25) 
N <- seq(0, V, by = 25)

# Generating sequence of D and N
D_seq <- D %>% # Words produced in the dominant language
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

N_seq <- N %>% # Words produced in non-dominant language
  rep(., length(D)) # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V450 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(N = N_seq) 


## V = 300 ##
V <- 300
D <- seq(0, V, by = 25) 
N <- seq(0, V, by = 25)

# Generating sequence of D and N
D_seq <- D %>% # Words produced in the dominant language
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

N_seq <- N %>% # Words produced in non-dominant language
  rep(., length(D)) # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V300 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(N = N_seq) 


## V = 150 ##
V <- 150
D <- seq(0, V, by = 25) 
N <- seq(0, V, by = 25)

# Generating sequence of D and N
D_seq <- D %>% # Words produced in the dominant language
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

N_seq <- N %>% # Words produced in non-dominant language
  rep(., length(D)) # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V150 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(N = N_seq) 


### Combining all dataframes and Calculate other variables
TE_fromVDN <- rbind(TE_V150, TE_V300, TE_V450, TE_V600) %>%
  # It is not possible for N > D, so keep only cases where D >= N
  filter(D >= N) %>%
  # Create other variables
  mutate(W = D+N, # Total word vocabulary of a child
         B = D/(D+N), # Balance, i.e. proportion use of non-dominant language (B ≤ .50)
         TE = (D*N)/V, # If D and N are independent, TE = DN/V
         C = W-TE, # Concept vocabulary (or total conceptual vocabulary size)
         Du = D-TE, # Unique words in dominant language
         Nu = N-TE) %>%
  # Remove cases where B = NA
  filter(!is.na(B)) 
```

#### Set 3: Calculate other variables based on V, D, and B ####
```{r}
### Creating variables: D and B
## V = 600 #
V <- 600
D <- seq(0, V, by = 25) 

D_seq <- D %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # balance
  rep(., length(D))  # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V600 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(B = B_seq) 


## V = 450 #
V <- 450
D <- seq(0, V, by = 25) 

D_seq <- D %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # balance
  rep(., length(D))  # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V450 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(B = B_seq) 


## V = 300 #
V <- 300
D <- seq(0, V, by = 25) 

D_seq <- D %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # balance
  rep(., length(D))  # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V300 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(B = B_seq) 


## V = 150 #
V <- 150
D <- seq(0, V, by = 25) 

D_seq <- D %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # balance
  rep(., length(D))  # generate N repetitions of the sequence based on length of D

# Creating the dataframe
TE_V150 <- data.frame(V, D_seq) %>%
  arrange(D_seq) %>%
  rename(D = D_seq) %>%
  mutate(B = B_seq) 


### Combining all dataframes and Calculate other variables
TE_fromVDB <- rbind(TE_V150, TE_V300, TE_V450, TE_V600) %>%
  # Create other variables
  mutate(W = D/B, # Total word vocabulary of a child
         N = W-D, # Words produced in non-dominant language
         TE = (D*N)/V, # If D and N are independent, TE = DN/V
         C = W-TE, # Concept vocabulary (or total conceptual vocabulary size)
         Du = D-TE, # Unique words in dominant language
         Nu = N-TE) %>% # Unique words in non-dominant language
  # In reality, it would be impossible to get negative numbers for any vocabulary variables, so filter out all cases with negative numbers
  filter(Nu >= 0) %>%
  # It is also not possible for D or N to exceed V, so filter out cases where D or N > V
  filter_at(vars(D, N), all_vars(. <= V)) %>%
  # filter out cases where N isn't whole number
  filter(is.wholenumber(N))
```

#### Set 4: Calculate other variables based on V, N, and B ####
```{r}
### Generating variables: N and B
## V = 600 #
V <- 600
N <- seq(0, V, by = 25)

N_seq <- N %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # a sequence of 0.5 to 1
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

# Creating the dataframe
TE_V600 <- data.frame(V, N_seq) %>%
  arrange(N_seq) %>%
  rename(N = N_seq) %>%
  mutate(B = B_seq) 


## V = 450 #
V <- 450
N <- seq(0, V, by = 25)

N_seq <- N %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # a sequence of 0.5 to 1
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

# Creating the dataframe
TE_V450 <- data.frame(V, N_seq) %>%
  arrange(N_seq) %>%
  rename(N = N_seq) %>%
  mutate(B = B_seq) 


## V = 300 #
V <- 300
N <- seq(0, V, by = 25)

N_seq <- N %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # a sequence of 0.5 to 1
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

# Creating the dataframe
TE_V300 <- data.frame(V, N_seq) %>%
  arrange(N_seq) %>%
  rename(N = N_seq) %>%
  mutate(B = B_seq) 


## V = 150 #
V <- 150
N <- seq(0, V, by = 25)

N_seq <- N %>% # Words produced in the dominant language
  rep(., length(B)) # generate N repetitions of the sequence based on length of B

B_seq <- B %>% # a sequence of 0.5 to 1
  rep(., length(N)) # generate N repetitions of the sequence based on length of N

# Creating the dataframe
TE_V150 <- data.frame(V, N_seq) %>%
  arrange(N_seq) %>%
  rename(N = N_seq) %>%
  mutate(B = B_seq) 


### Combining all dataframes and Calculate other variables
TE_fromVNB <- rbind(TE_V150, TE_V300, TE_V450, TE_V600) %>%
  # Create other variables
  mutate(W = D/(1-B), # Total word vocabulary of a child
         D = W-N, # Words produced in dominant language
         TE = (D*N)/V, # If D and N are independent, TE = DN/V
         C = W-TE, # Concept vocabulary (or total conceptual vocabulary size)
         Du = D-TE, # Unique words in dominant language
         Nu = N-TE) %>% # Unique words in non-dominant language
  # It is not possible for N > D, so keep only cases where D >= N
  filter(D >= N) %>%
  # In reality, it would be impossible to get negative numbers for any vocabulary variables, so filter out all cases with negative numbers
  filter(Nu >= 0) %>%
  # It is also not possible for D or N to exceed V, so filter out cases where D or N > V
  filter_at(vars(D, N), all_vars(. <= V)) %>%
  # filter out cases where D isn't whole number
  filter(is.wholenumber(D)) %>%
  filter_at(vars(TE, C, Du, Nu), any_vars(is.wholenumber(.))) %>%
  filter(is.wholenumber(Nu)) 
```

#### Combine the 4 sets ####
```{r}
TE_computation <- TE_fromVWB %>%
  bind_rows(TE_fromVDN, TE_fromVDB, TE_fromVNB) %>%
  # constrain all variables but B (balance) to be integers 
  filter_at(vars(TE, C, Du, Nu), any_vars(is.wholenumber(.)))
```

# Correlation
```{r}
Correlation <- TE_computation %>%
  cor_matrix()

library(Hmisc)
mycor <- rcorr(as.matrix(TE_computation), type="pearson")
mycor$r
mycor$P

library(corrplot)
mycor <- cor(TE_computation)
corrplot(mycor)
#write.table(Correlation, "TEcomputation_correlations.tsv", col.names=NA)
```

# Plotting relations between variables
## Stacked barchart showing the vocabulary composition across different balance proportions
```{r}

#plot_composition <- TE_computation %>%
#  # Convert to long data
#  pivot_longer(c(D, N, TE, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
#  filter(vocab_type %notin% c("D", "N", "C")) %>%
#  mutate(vocab_type = factor(vocab_type, levels=c("TE", "Du", "Nu"))) %>%
#  mutate(bin_W = cut(W, breaks = 3, 
#                     labels = c("0-400", "401-800", "801-1200"))) %>%
#  group_by(bin_W, vocab_type, B) %>%
#  summarise(n_words = mean(number)) %>%
#  ggplot(aes(x=B, y = n_words, fill = vocab_type)) + 
#  geom_bar(position="stack", stat="identity") +
#  facet_grid(. ~ bin_W) +
#  #scale_y_continuous(limits = c(0, 1200)) +
#  theme_minimal() +
#  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") + 
#  labs(x = "Balance", 
#       y = "Number of words") 

plot_composition_byB <- TE_computation %>%
  # Convert to long data
  pivot_longer(c(D, N, TE, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("D", "N", "C")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("Nu", "Du", "TE"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  #mutate(bin_W = cut_interval(W, 12,
  #                   labels = c(100,200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200))) %>%
  mutate(bin_W = cut_interval(W, 8,
                     labels = c(150, 300, 450, 600, 750, 900, 1050, 1200))) %>%
  group_by(bin_B, vocab_type, bin_W) %>%
  summarise(n_words = mean(number)) %>%
  ggplot(aes(x = bin_W, y = n_words, fill = vocab_type)) + 
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ bin_B) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) + 
  #scale_y_continuous(limits = c(0, 1200)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom",
        plot.title = element_text(hjust = 0.5)) +
  labs(x = "Total vocabulary size", 
       y = "Number of concepts", 
       title = "Vocabulary composition across different balance proportions") 

ggsave("plot_composition_byB.png", plot_composition_byB)




plot_composition_byW <- TE_computation %>%
  pivot_longer(c(D, N, TE, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("D", "N", "C")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("Nu", "Du", "TE"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  mutate(bin_W = cut_interval(W, 6,
                     labels = c(200, 400, 600, 800, 1000, 1200))) %>%
  group_by(bin_B, vocab_type, bin_W) %>%
  summarise(n_words = mean(number)) %>%
  ggplot(aes(x = bin_B, y = n_words, fill = vocab_type)) + 
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ bin_W) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) + 
  #scale_y_continuous(limits = c(0, 1200)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") + 
  labs(x = "Balance", 
       y = "Number of concepts", 
       title = "Vocabulary composition across different vocabulary size") 

plot_composition_byV <- TE_computation %>%
  pivot_longer(c(D, N, TE, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("D", "N", "C")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("Nu", "Du", "TE"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  group_by(V, bin_B, vocab_type) %>%
  summarise(n_words = mean(number)) %>%
  ggplot(aes(x = bin_B, y = n_words, fill = vocab_type)) + 
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ V) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) + 
  #scale_y_continuous(limits = c(0, 1200)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") + 
  labs(x = "Balance", 
       y = "Number of concepts", 
       title = "Vocabulary composition across different developmental timepoints (V)") 

ggsave("plot_composition_byV.png", plot_composition_byV,
        width = 10, height = 5)

plot_composition_byV <- TE_computation %>%
  pivot_longer(c(D, N, TE, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("D", "N", "C")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("Nu", "Du", "TE"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  group_by(bin_B, vocab_type, V) %>%
  summarize(n_words = mean(number)) %>%
  ggplot(aes(x = bin_B, y = n_words, fill = vocab_type)) +
  geom_bar(position = "stack", stat = "identity", reverse = TRUE) +
  facet_grid(. ~ V) +
  theme_minimal() +
  ggtitle("Vocabulary composition across different developmental timepoints") +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom")

```

## Compare different vocabulary measures across balance
```{r}
vocab_label <- c("Concept Vocabulary (C)", "Unique Dominant Words (Du)", "Unique Non-dominant Words (Nu)")

plot_words <- TE_computation %>%
  # Convert to long data
  pivot_longer(c(D, N, TE, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("D", "N")) %>%
  mutate(vocab_type = as.factor(vocab_type)) %>%
  mutate(vocab_type = recode(vocab_type, C = "Concept vocabulary (C)", Du = "Unique dominant words (Du)",
         Nu = "Unique non-dominant words (Nu)", TE = "Translation equivalents")) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  #mutate(bin_W = cut_interval(W, 12,
  #                   labels = c(100,200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200))) %>%
  group_by(bin_B, vocab_type, W) %>%
  summarise(n_words = mean(number)) %>%
  ggplot(aes(x = W, y = n_words, color = bin_B)) +
  #geom_point() +
  stat_smooth(method = lm, se = F) +
  theme_minimal() + 
  facet_grid(. ~ vocab_type) +
  ylim(0, 600) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Total vocabulary Size (W)", 
       y = "Number of words", 
       color = "Balance",
       title = "Word vocabulary size by balance under different vocabulary measures") +
  guides(colour = guide_legend(nrow = 1))

  
ggsave("plot_words.png", plot_words,
       width = 10, height = 5)
```


## Plotting relations between TEs and different variables
##### Relation between TE & W, D, & N #####
```{r}
### Plot: Y = TE, X = D / N
plot_TEandWDN <- TE_computation %>%
  pivot_longer(c(W, D, N, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %in% c("W", "D", "N")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("W", "D", "N"))) %>%
  #mutate(bin_B = cut(B, breaks = 6, 
  #                   labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = number, y = TE)) +
  facet_grid(. ~vocab_type) +
  labs(x = "Words produced", y = "Total number of TEs") +
  geom_point(shape = 23) +
  geom_smooth(method="lm", se=F) +
  scale_y_continuous(limits = c(0, 600)) +
  theme_minimal()

ggsave("plot_TEandWDN.png", plot_TEandWDN)


### Plot: Y = TE, X = D / N, color by B
plot_TEandWDN_byB <- TE_computation %>%
  pivot_longer(c(W, D, N, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %in% c("W", "D", "N")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("W", "D", "N"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = number, y = TE, colour = bin_B)) +
  facet_grid(. ~vocab_type) +
  labs(x = "Words produced", y = "Total number of TEs",
       colour = "Bins of balance") +
  geom_point(shape = 23) +
  geom_smooth(method="lm", se=F) +
  scale_x_continuous(limits = c(0, 1200)) +
  scale_y_continuous(limits = c(0, 600)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") +
  guides(colour = guide_legend(nrow = 1))

ggsave("plot_TEandWDN_byB.png", plot_TEandWDN_byB)
```

##### Relation between W & TE, Du, & Nu #####
```{r}
### Plot: Y = W, X = TE/ Du / Nu
plot_WandTEDuNu <- TE_computation %>%
  pivot_longer(c(TE, D, N, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %in% c("TE", "Du", "Nu")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("TE", "Du", "Nu"))) %>%
  #mutate(bin_B = cut(B, breaks = 6, 
  #                   labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = number, y = W)) +
  facet_grid(. ~vocab_type) +
  labs(x = "Words produced", y = "Total vocabulary size") +
  geom_point(shape = 23) +
  geom_smooth(method="lm", se=F) +
  scale_y_continuous(limits = c(0, 1200)) +
  theme_minimal()

ggsave("plot_WandTEDuNu.png", plot_WandTEDuNu)


### Plot: Y = W, X = TE/ Du / Nu, color by B
plot_WandTEDuNu_byB <- TE_computation %>%
  pivot_longer(c(TE, D, N, C, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %in% c("TE", "Du", "Nu")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("TE", "Du", "Nu"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = number, y = W, colour = bin_B)) +
  facet_grid(. ~vocab_type) +
  labs(x = "Words produced", y = "Total vocabulary size",
       colour = "Bins of balance") +
  geom_point(shape = 23) +
  geom_smooth(method="lm", se=F) +
  scale_y_continuous(limits = c(0, 1200)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") +
  guides(colour = guide_legend(nrow = 1))

ggsave("plot_WandTEDuNu_byB.png", plot_WandTEDuNu_byB)
```

##### Relation between C & W, D, & N #####
```{r}
### Plot: Y = C, X = W / D / N
plot_CandWDN <- TE_computation %>%
  pivot_longer(c(TE, W, D, N, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %in% c("W", "D", "N")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("W", "D", "N"))) %>%
  #mutate(bin_B = cut(B, breaks = 6, 
  #                   labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = number, y = C)) +
  facet_grid(. ~vocab_type) +
  labs(x = "Words produced", y = "Number of concepts") +
  geom_point(shape = 23) +
  geom_smooth(method="lm", se=F) +
  scale_y_continuous(limits = c(0, 600)) +
  theme_minimal()

ggsave("plot_CandWDN.png", plot_CandWDN)


### Plot: Y = C, X = W / D / N, color by B
plot_CandWDN_byB <- TE_computation %>%
  pivot_longer(c(TE, W, D, N, Du, Nu), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %in% c("W", "D", "N")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("W", "D", "N"))) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = number, y = C, colour = bin_B)) +
  facet_grid(. ~vocab_type) +
  labs(x = "Words produced", y = "Number of concepts",
       colour = "Bins of balance") +
  geom_point(shape = 23) +
  geom_smooth(method="lm", se=F) +
  scale_x_continuous(limits = c(0, 1200)) +
  scale_y_continuous(limits = c(0, 600)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") +
  guides(colour = guide_legend(nrow = 1))

ggsave("plot_CandWDN_byB.png", plot_CandWDN_byB)
```


# Plotting relations between variables (while holding some variables constant)
## TE ~ predictors (input)
```{r}
#TE_Constant <- lm(TE ~ ., data = TE_computation) 
#summary(TE_Constant)

#### run a regression with TE ~ B, D, N
TE_InputConstant <- lm(TE ~ 0 + B + D + N, data = TE_computation) 
summary(TE_InputConstant)

### plot the relation between TE & B / D / N
#effect_plot(TE_InputConstant, pred = B, plot.points = TRUE)
effect_B <- effect(term = "B", mod = TE_InputConstant) %>%
  data.frame()

plotConstant_TE_B <- ggplot(effect_B, aes(x = B, y = fit)) +
  geom_line() +
  ylim(-25, 600) +
  labs(x = 'Balance', y = 'Number of TEs') +
  theme_minimal()

#ggsave("plotConstant_TE_B.png", plotConstant_TE_B)

### plot the relation between TE & D
#effect_plot(TE_InputConstant, pred = D, plot.points = TRUE)
effect_D <- effect(term = "D", mod = TE_InputConstant) %>%
  data.frame()

plotConstant_TE_D <- ggplot(effect_D, aes(x = D, y = fit)) +
  geom_line() +
  ylim(-25, 600) +
  labs(x = 'Dominant vocabulary', y = 'Number of TEs') +
  theme_minimal() 

#ggsave("plotConstant_TE_D.png", plotConstant_TE_D)

### plot the relation between TE & N
#effect_plot(TE_InputConstant, pred = N, plot.points = TRUE)
effect_N <- effect(term = "N", mod = TE_InputConstant) %>%
  data.frame()

plotConstant_TE_N <- ggplot(effect_N, aes(x = N, y = fit)) +
  geom_line() +
  ylim(-25, 600) +
  labs(x = 'Non-dominant vocabulary', y = 'Number of TEs') +
  theme_minimal()

#ggsave("plotConstant_TE_N.png", plotConstant_TE_D)
  
## put the three plots together
plotConstant_TE_BDN <- ggarrange(plotConstant_TE_B, plotConstant_TE_D, plotConstant_TE_N, 
                                 ncol = 3, nrow = 1,
                                 widths = 3, heights = 1) %>%
  annotate_figure(top = text_grob("linear regression model: TE ~ 0 + B + D + N", face = "bold", size = 14))

ggsave("plotConstant_TE_BDN.png", plotConstant_TE_BDN, 
       width = 10, height = 5)
```


## TE ~ predictors (output)
```{r}
#### run a regression with TE ~ C, Du, Nu
TE_OutputConstant <- lm(TE ~ 0 + C + Du + Nu, data = TE_computation) 
summary(TE_OutputConstant)

## plot the relation between TE & C
#effect_plot(TE_OutputConstant, pred = C, plot.points = TRUE)
effect_C <- effect(term = "C", mod = TE_OutputConstant) %>%
  data.frame()

plotConstant_TE_C <- ggplot(effect_C, aes(x = C, y = fit)) +
  geom_line() +
  labs(x = 'Concept vocabulary', y = 'Number of TEs') +
  ylim(-300, 600) +
  theme_minimal()

#ggsave("plotConstant_TE_C.png", plotConstant_TE_C)

## plot the relation between TE & Du
#effect_plot(TE_OutputConstant, pred = Du, plot.points = TRUE)
effect_Du <- effect(term = "Du", mod = TE_OutputConstant) %>%
  data.frame()

plotConstant_TE_Du <- ggplot(effect_Du, aes(x = Du, y = fit)) +
  geom_line() +
  labs(x = 'Unique dominant vocabulary', y = 'Number of TEs') +
  ylim(-300, 600) +
  theme_minimal()

#ggsave("plotConstant_TE_Du.png", plotConstant_TE_Du)

## plot the relation between TE & Nu
#effect_plot(TE_OutputConstant, pred = Nu, plot.points = TRUE)
effect_Nu <- effect(term = "Nu", mod = TE_OutputConstant) %>%
  data.frame()

plotConstant_TE_Nu <- ggplot(effect_Nu, aes(x = Nu, y = fit)) +
  geom_line() +
  labs(x = 'Unique non-dominant vocabulary', y = 'Number of TEs') +
  ylim(-300, 600) +
  xlim(0,600) +
  theme_minimal()

#ggsave("plotConstant_TE_Du.png", plotConstant_TE_Du)

## put the three plots together
plotConstant_TE_CDuNu <- ggarrange(plotConstant_TE_C, plotConstant_TE_Du, plotConstant_TE_Nu, 
                                 ncol = 3, nrow = 1,
                                 widths = 3, heights = 1) %>%
  annotate_figure(top = text_grob("linear regression model: TE ~ 0 + C + Du + Nu", face = "bold", size = 14))

ggsave("plotConstant_TE_CDuNu.png", plotConstant_TE_CDuNu, 
       width = 10, height = 5)
```

# Estimating  if the models is biased towards ot against learning TEs
```{r}
## plot
plot_learnVSpredict <- TE_computation %>%
  mutate(predicted_TE = TE, #predicted TE is based on D*N/V (where V is the max. possible words)
         learned_TE = (D*N)/(W/2)) %>%
  mutate(bin_B = cut(B, breaks = 6, 
                     labels = c("0.5", "0.6", "0.7", "0.8", "0.9", "1"))) %>%
  ggplot(aes(x = learned_TE, y = predicted_TE, color = bin_B)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) +
  labs(x = "Learned translation equivalents (= (D*N)/(W/2))",
       y = "Predicted translation equivalents under the model (= (D*N)/V)",
       color = "Bins of balance") +                                                    
  theme_minimal()

ggsave("plot_learnVSpredict.png", plot_learnVSpredict)

## Kolmogorov-Smirnov test to compare the observed and predicted TE
TE_computation <- TE_computation %>%
  mutate(predicted_TE = TE, #predicted TE is based on D*N/V (where V is the max. possible words)
         learned_TE = (D*N)/(W/2))

stats::ks.test(TE_computation$predicted_TE, TE_computation$learned_TE)

```