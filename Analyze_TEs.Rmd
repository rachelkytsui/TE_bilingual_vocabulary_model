---
title: "acquisition of TEs"
date: "Last update: Nov 27th 2020"
output: 
  html_document: 
    code_folding: show
    collapsed: no
    df_print: kable
    highlight: espresso
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
editor_options: 
  chunk_output_type: console
---
# Preparations
## load libraries
```{r}

# install.packages("devtools")
#devtools::install_github("mikabr/ggpirate")

library(ggpirate)
library(here)
library(tidyverse)
library(tidylog)
library(wordbankr)
library("ggpubr")

library(lme4)
library(lmerTest)
library(scales)
```

# load data
```{r}
cdi_ws = readRDS(here::here("Data","output_analyzeSent.Rdata"))
```

# Participant Exclusions
exclude babies out of 18-33m age range, monolinguals and those with >10% 3rd language exposure
```{r}
# exclude kids that are bilingual at one visit, monolingual at another (regardless of direction)
# switch from other to bilingual, or vice versa, or from other to monolingual and vice versa are ok
exclude.lang_group_change  = cdi_ws %>%
  filter(lang_group !="other") %>%
  group_by(baby_id) %>% 
  distinct(ID_testdate, .keep_all = T) %>%
  mutate(visit_num = 1:n()) %>%  
  mutate(changed_language_group_status = if_else(visit_num == 1, NA, 
                                                 lang_group != lag(lang_group))) %>%
  # uncomment see all visits for babies that have one visit excluded
  #filter(any(changed_language_group_status == TRUE) ) %>% View()
  filter(changed_language_group_status == TRUE) %>% 
  pull(ID_testdate)


# Create exclusion criteria variables
cdi_ws_TE <- cdi_ws %>%
  mutate(
    # create an exclusion criteria for language
    exclude.language = case_when(
      # exclude babies with more than 10% exposure to a 3rd language
      lang_exp_other > 10 ~ 1,
      # exclude language group status changed from bilingual to mono or vice versa
      ID_testdate %in% exclude.lang_group_change ~ 1, 
      lang_group == "bilingual" ~ 0, #bilingual
      lang_group == "monolingual" ~ 0, # monolingual
      TRUE ~ 1), # all other cases exlude
    
    # create an exclusion criteria for age
    exclude.age = case_when(!between(age_months_binned, 18, 33) ~ 1, 
                            TRUE ~ 0) # all other cases keep
  )


# Exclude participants
keepers_ws_TE <- cdi_ws_TE %>%
  filter(
    # exclude participants who have exposure to a third language/ are neither bilingual nor monolingual
    exclude.language == 0,
    # exclude participants who don't fit age range
    exclude.age == 0,
    # exclude participants who don't have both CDI filled
    both_cdi_filled == "Y",
    # keep only babies with at least 15% of E and 15% of F (i.e., exclude monolinguals)
    lang_exp_eng >= 15 & lang_exp_eng <= 85,
    lang_exp_fre >= 15 & lang_exp_fre <= 85)


### Check how many distinct participants and data point we have
keepers_ws_TE %>% summarize(N_visits = n_distinct(ID_testdate),
                            N_babies = n_distinct(baby_id),
                            N_admin = sum(n_administrations, na.rm=T))


### Check if there is any NAs in the vocabulary measures (should all return 0)
keepers_ws_TE %>% filter(is.na(vocab_score)) %>% 
  select(ID_testdate, vocab_type, vocab_score) %>%
  nrow()

keepers_ws_TE %>% filter(is.na(eng_unique_words)) %>% 
  select(ID_testdate) %>% 
  nrow()

keepers_ws_TE %>% filter(is.na(fre_unique_words)) %>% 
  select(ID_testdate) %>%
  nrow()

keepers_ws_TE %>% filter(is.na(number_of_te)) %>% 
  select(ID_testdate) %>%
  nrow()
```

# Prepare the dataset
```{r}

keepers_ws_TE = keepers_ws_TE %>%
  # keep only necessary variables
  select(-c(vocab_type_dom, vocab_cross_lang, n_administrations)) %>% #n_administrations
  spread(vocab_type, vocab_score) %>%
  # calculate age in months (with decimal)
  mutate(age_month_decimal = age_days/30) %>%
  # create balance groups (by exposure)
  mutate(BalanceGroup_byExposure = cut(balance, breaks = 4, 
                                       labels = c("80_20", "70_30", "60_40", "50_50"))) %>%
  mutate(TotalNW_Dom_exposure = case_when(lang_dom == "English" ~ total_words_eng,
                                          lang_dom == "French" ~ total_words_fre),
         TotalNW_NonDom_exposure = case_when(lang_dom == "English" ~ total_words_fre,
                                             lang_dom == "French" ~ total_words_eng),
         Dom_unique_words_exposure = case_when(lang_dom == "French" ~ fre_unique_words, 
                                               lang_dom == "English" ~ eng_unique_words),
         NonDom_unique_words_exposure = case_when(lang_dom == "French" ~ eng_unique_words, 
                                         lang_dom == "English" ~ fre_unique_words)) %>%
  
  #defining dominance based on vocabulary size
  mutate(LangDom_vocab = case_when(total_words_eng > total_words_fre ~ "English",
                                 TRUE ~ "French")) %>%
  mutate(LangDom_vocab = as.factor(LangDom_vocab)) %>%
  mutate(TotalNW_Dom = case_when(total_words_eng > total_words_fre ~ total_words_eng,
                                 TRUE ~ total_words_fre),
         TotalNW_NonDom = case_when(total_words_eng > total_words_fre ~ total_words_fre,
                                    TRUE ~ total_words_eng),
         Dom_unique_words = case_when(total_words_eng > total_words_fre ~ eng_unique_words,
                                      TRUE ~ fre_unique_words),
         NonDom_unique_words = case_when(total_words_eng > total_words_fre ~ fre_unique_words,
                                         TRUE ~ eng_unique_words)) %>%
  mutate(TotalUnique = Dom_unique_words + NonDom_unique_words) %>%
  
  #Defining vocabulary-based balance score
  #mutate(balance_vocab = TotalNW_NonDom/TotalNW_Dom) %>%
  mutate(balance_vocab = TotalNW_Dom/(TotalNW_Dom+TotalNW_NonDom)) %>%
  #Defining proportion of TE (with reference to child's own total vocab size)
  mutate(propTE = number_of_te*2/word_vocab) %>% 
  #Defining proportion of TE (with reference to CDI)
  mutate(propTE_CDI = number_of_te/672) 
  
write.csv(keepers_ws_TE, "Data/keepers_ws_TE.csv", row.names = F)

# check balancedness cutoffs
keepers_ws_TE %>%
  ggplot(aes(x = lang_exp_eng, y = BalanceGroup_byExposure)) + 
  geom_point()

keepers_ws_TE %>%
  ggplot(aes(x = lang_exp_fre, y = BalanceGroup_byExposure)) + 
  geom_point()

```

# Figure 6
```{r}
Observed_plot_inputs_TE <- keepers_ws_TE %>% 
  select(baby_id, ID_testdate, age_days, number_of_te, word_vocab, TotalNW_Dom, TotalNW_NonDom, balance_vocab) %>%
  pivot_longer(c(word_vocab, TotalNW_Dom, TotalNW_NonDom), names_to = "vocab_type", values_to = "number") %>%
  mutate(vocab_type = factor(vocab_type, levels=c("word_vocab", "TotalNW_Dom", "TotalNW_NonDom"))) %>%
  mutate(vocab_type = recode(vocab_type, 
                             word_vocab = "Panel A: Total vocabulary", 
                             TotalNW_Dom = "Panel B: Dominant vocabulary", 
                             TotalNW_NonDom = "Panel C: Non-dominant vocabulary")) %>%
  mutate(bin_B = case_when(balance_vocab < 0.6 ~ "0.5",
                           balance_vocab >= 0.6 & balance_vocab < 0.7 ~ "0.6",
                           balance_vocab >= 0.7 & balance_vocab < 0.8 ~ "0.7",
                           balance_vocab >= 0.8 & balance_vocab < 0.9 ~ "0.8",
                           TRUE ~ "0.9")) %>%
  ggplot(aes(x = number, y = number_of_te, color = bin_B)) +
  #geom_point() +
  stat_smooth(method = lm, se = F) +
  theme_minimal() + 
  facet_grid(. ~ vocab_type) +
  ylim(0, 400) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Number of words", 
       y = "Total observed number of translation equivalents", 
       color = "Balance"
       #, title = "Number of translation equivalent by balance in relation to different input measures "
       ) +
  guides(colour = guide_legend(nrow = 1)) 

ggsave("Output/Observed_plot_inputs_TE.png", Observed_plot_inputs_TE,
       width = 10, height = 5)

```

# Figure 7
```{r}
plot_stacked_byV <- keepers_ws_TE %>%
  select(baby_id, age_months_percentile, balance_vocab, word_vocab, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(V_subset = case_when(age_months_percentile <= 22 ~ "18-22 months",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months",
                              TRUE ~ "28-33 months")) %>%
  #mutate(V_subset = case_when(age_months_percentile <= 21 ~ "18-21",
  #                            age_months_percentile > 21 & age_months_percentile <= 25 ~ "22-25",
  #                            age_months_percentile > 25 & age_months_percentile <= 29 ~ "26-29",
  #                            TRUE ~ "30-33")) %>%
  #mutate(bin_B = case_when(balance_vocab < 0.6 ~ "0.5",
  #                         balance_vocab >= 0.6 & balance_vocab < 0.7 ~ "0.6",
  #                         balance_vocab >= 0.7 & balance_vocab < 0.8 ~ "0.7",
  #                         balance_vocab >= 0.8 & balance_vocab < 0.9 ~ "0.8",
  #                         TRUE ~ "0.9")) %>%
  mutate(BalSubset = case_when(balance_vocab <= 0.65 ~ "Most Balanced",
                               balance_vocab >= 0.80 ~ "Least Balanced",
                               TRUE ~ "Medium Balanced")) %>%
  mutate(BalSubset = factor(BalSubset, levels=c("Most Balanced", "Medium Balanced", "Least Balanced"))) %>%
  arrange(desc(number_of_te)) %>%
  mutate(TE = number_of_te) %>%
  pivot_longer(-c(baby_id, age_months_percentile, balance_vocab, V_subset, BalSubset, word_vocab, TE), 
               names_to = "Type", values_to = "NumberOfWords") %>%
  mutate(Type = factor(Type, levels=c("NonDom_unique_words", "Dom_unique_words", "number_of_te"))) %>%
  mutate(Type = recode(Type, 
                       NonDom_unique_words = "Unique non-dominant word", 
                       Dom_unique_words = "Unique dominant word", 
                       number_of_te = "Translation equivalent")) %>%
  group_by(V_subset, BalSubset, Type) %>%
  summarise(n_words = mean(NumberOfWords)) %>%
  ggplot(aes(x = BalSubset, y = n_words, fill = Type)) +
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ V_subset) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) + 
  #scale_y_continuous(limits = c(0, 1200)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0) , 
        legend.position = "bottom",
        plot.title = element_text(hjust = 0.5)) + 
  labs(x = "Balance", 
       y = "Observed number of concepts", 
       title = "Vocabulary composition across different subset of developmental timepoints") 

ggsave("Output/Observed_plot_stacked_byV.png", plot_stacked_byV,
       width = 10, height = 5)


## Mean proportion of TE
stacked_byV_wide <- keepers_ws_TE %>%
  select(baby_id, age_months_percentile, balance_vocab, word_vocab, concept_vocab, 
         propTE, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(V_subset = case_when(age_months_percentile <= 22 ~ "18-22 months",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months",
                              TRUE ~ "28-33 months")) %>%
  mutate(BalSubset = case_when(balance_vocab <= 0.65 ~ "Most Balanced",
                               balance_vocab >= 0.80 ~ "Least Balanced",
                               TRUE ~ "Medium Balanced")) 


stacked_byV_wide %>%
  group_by(V_subset) %>%
  summarise(mean_propTE = mean(propTE, na.rm=T), 
            sd_propTE = sd(propTE, na.rm=T),
            min_propTE = min(propTE, na.rm=T),
            max_propTE = max(propTE, na.rm=T))

# Anova to compare the number of TEs among the 3 developmental groups in the stacked barchart
stacked_byV_wide %>%  
  group_by(V_subset) %>%
  summarise(mean_TE = mean(number_of_te, na.rm=T), 
            sd_TE = sd(number_of_te, na.rm=T),
            min_TE = min(number_of_te, na.rm=T),
            max_TE = max(number_of_te, na.rm=T))

TE_byV_anova <- aov(propTE ~ V_subset, data = stacked_byV_wide)
summary(TE_byV_anova)

pairwise.t.test(stacked_byV_wide$number_of_te, stacked_byV_wide$V_subset,
                 p.adjust.method = "BH")


## Anova to compare the unique dom vocab size and unique non-dom vocab size among the 3 developmental groups in the stacked barchart
stacked_byV_wide %>%  
  group_by(BalSubset) %>%
  summarise(mean_Du = mean(Dom_unique_words, na.rm=T), 
            sd_Du = sd(Dom_unique_words, na.rm=T),
            min_Du = min(Dom_unique_words, na.rm=T),
            max_Du = max(Dom_unique_words, na.rm=T))

Du_byB_anova <- aov(Dom_unique_words ~ BalSubset, data = stacked_byV_wide)
summary(Du_byB_anova)

pairwise.t.test(stacked_byV_wide$Dom_unique_words, stacked_byV_wide$BalSubset,
                 p.adjust.method = "BH")


stacked_byV_wide %>% 
  group_by(BalSubset) %>%
  summarise(mean_Nu = mean(NonDom_unique_words, na.rm=T), 
            sd_Nu = sd(NonDom_unique_words, na.rm=T),
            min_Nu = min(NonDom_unique_words, na.rm=T),
            max_Nu = max(NonDom_unique_words, na.rm=T))

Nu_byB_anova <- aov(NonDom_unique_words ~ BalSubset, data = stacked_byV_wide)
summary(Nu_byB_anova)

pairwise.t.test(stacked_byV_wide$NonDom_unique_words, stacked_byV_wide$BalSubset,
                 p.adjust.method = "BH")




```

# Descriptives: Vocabulary measures
```{r}
## Mean word vocab size
keepers_ws_TE %>% 
  summarize(mean_W = mean(word_vocab, na.rm=T), 
            sd_W = sd(word_vocab, na.rm=T),
            min_W = min(word_vocab, na.rm=T),
            max_W = max(word_vocab, na.rm=T))

## Mean TE size
keepers_ws_TE %>% 
  summarize(mean_TE = mean(number_of_te, na.rm=T), 
            sd_TE = sd(number_of_te, na.rm=T),
            min_TE = min(number_of_te, na.rm=T),
            max_TE = max(number_of_te, na.rm=T))

## Mean unique word size
keepers_ws_TE %>% 
  summarize(mean_Du = mean(Dom_unique_words, na.rm=T), 
            sd_Du = sd(Dom_unique_words, na.rm=T),
            min_Du = min(Dom_unique_words, na.rm=T),
            max_Du = max(Dom_unique_words, na.rm=T))

keepers_ws_TE %>% 
  summarize(mean_Nu = mean(NonDom_unique_words, na.rm=T), 
            sd_Nu = sd(NonDom_unique_words, na.rm=T),
            min_Nu = min(NonDom_unique_words, na.rm=T),
            max_Nu = max(NonDom_unique_words, na.rm=T))

t.test(keepers_ws_TE$Dom_unique_words, keepers_ws_TE$NonDom_unique_words, 
       paired = TRUE) # paired-samples t-test to compare Du and Nu


## Stacked barchart to plot TE, Du, and Nu of individual infants (facet by balance)
stacked <- keepers_ws_TE %>%
  select(baby_id, balance_vocab, word_vocab, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset balance_vocab by 3 levels 
  #mutate(BalSubset = cut(balance_vocab, breaks = 3, 
  #                       labels=c("MostBalanced", "MediumBalanced", "LeastBalanced"))) %>%
  mutate(BalSubset = case_when(balance_vocab <= 0.65 ~ "MostBalanced",
                               balance_vocab >= 0.80 ~ "LeastBalanced",
                               TRUE ~ "MediumBalanced")) %>%
  arrange(desc(number_of_te)) %>%
  mutate(TE = number_of_te) %>%
  pivot_longer(-c(baby_id, balance_vocab, BalSubset, word_vocab, TE), 
               names_to = "Type", values_to = "NumberOfWords") %>%
  mutate(Type = factor(Type, levels=c("NonDom_unique_words", "Dom_unique_words", "number_of_te"))) %>%
  mutate(Type = recode(Type, 
                       NonDom_unique_words = "Unique non-dominant word", 
                       Dom_unique_words = "Unique dominant word", 
                       number_of_te = "Translation equivalent")) 


LeastBal_plot <- stacked %>%
  filter(BalSubset == "LeastBalanced") %>%
  ggplot(aes(x = reorder(baby_id, -NumberOfWords, sum), y = NumberOfWords)) +
  geom_col(aes(fill = Type)) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_y_continuous(limits = c(0, 1050)) +
  labs(x = "Individual infant", 
       y = "Number of concepts produced",
       title = "Least balanced") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5)) 

MediumBal_plot <- stacked %>%
  filter(BalSubset == "MediumBalanced") %>%
  ggplot(aes(x = reorder(baby_id, -NumberOfWords, sum), y = NumberOfWords)) +
  geom_col(aes(fill = Type)) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_y_continuous(limits = c(0, 1050)) +
  labs(x = "Individual infant", 
       y = "Number of concepts produced",
       title = "Medium balanced") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

MostBal_plot <- stacked %>%
  filter(BalSubset == "MostBalanced") %>%
  ggplot(aes(x = reorder(baby_id, -NumberOfWords, sum), y = NumberOfWords)) +
  geom_col(aes(fill = Type)) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_y_continuous(limits = c(0, 1050)) +
  labs(x = "Individual infant", 
       y = "Number of concepts produced",
       title = "Most balanced") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

Bal_StackedPlot <- ggarrange(LeastBal_plot, 
          MediumBal_plot + rremove("ylab"), 
          MostBal_plot + rremove("ylab"),
          ncol = 3, nrow = 1,
          common.legend = TRUE, legend="bottom")

ggsave("Output/StackedPlot_byBalance.png", Bal_StackedPlot,
       width = 10, height = 5)


## Anova to compare the total vocab size among the 3 balance groups in the stacked barchart
stacked_wide <- keepers_ws_TE %>%
  select(baby_id, balance_vocab, word_vocab, concept_vocab, propTE, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset balance_vocab by 3 levels 
  mutate(BalSubset = case_when(balance_vocab <= 0.65 ~ "MostBalanced",
                               balance_vocab >= 0.80 ~ "LeastBalanced",
                               TRUE ~ "MediumBalanced"))


W_byB_anova <- aov(word_vocab ~ BalSubset, data = stacked_wide)
summary(W_byB_anova)

pairwise.t.test(stacked_wide$word_vocab, stacked_wide$BalSubset, p.adj = "BH")

## Mean proportion of TE
stacked_wide %>%
  group_by(BalSubset) %>%
  summarize(mean_propTE = mean(propTE, na.rm=T), 
            sd_propTE = sd(propTE, na.rm=T),
            min_propTE = min(propTE, na.rm=T),
            max_propTE = max(propTE, na.rm=T))

## Correlation between concept vocab and TE across different balance group
stacked_wide_most <- stacked_wide %>%
  filter(BalSubset == "MostBalanced")

cor.test(stacked_wide_most$number_of_te, stacked_wide_most$concept_vocab, method = "pearson")


stacked_wide_med <- stacked_wide %>%
  filter(BalSubset == "MediumBalanced")

cor.test(stacked_wide_med$number_of_te, stacked_wide_med$concept_vocab, method = "pearson")


stacked_wide_least <- stacked_wide %>%
  filter(BalSubset == "LeastBalanced")

cor.test(stacked_wide_least$number_of_te, stacked_wide_least$concept_vocab, method = "pearson")

## Anova to compare the unique dom vocab size and unique non-dom vocab size among the 3 balance groups in the stacked barchart
stacked_wide %>% 
  group_by(BalSubset) %>%
  summarize(mean_Du = mean(Dom_unique_words, na.rm=T), 
            sd_Du = sd(Dom_unique_words, na.rm=T),
            min_Du = min(Dom_unique_words, na.rm=T),
            max_Du = max(Dom_unique_words, na.rm=T))

Du_byB_anova <- aov(Dom_unique_words ~ BalSubset, data = stacked_wide)
summary(Du_byB_anova)

pairwise.t.test(stacked_wide$Dom_unique_words, stacked_wide$BalSubset,
                 p.adjust.method = "BH")


stacked_wide %>% 
  group_by(BalSubset) %>%
  summarize(mean_Nu = mean(NonDom_unique_words, na.rm=T), 
            sd_Nu = sd(NonDom_unique_words, na.rm=T),
            min_Nu = min(NonDom_unique_words, na.rm=T),
            max_Nu = max(NonDom_unique_words, na.rm=T))

Nu_byB_anova <- aov(NonDom_unique_words ~ BalSubset, data = stacked_wide)
summary(Nu_byB_anova)

pairwise.t.test(stacked_wide$NonDom_unique_words, stacked_wide$BalSubset,
                 p.adjust.method = "BH")
```

# Descriptives
## number of CDIs & Babys
```{r}
# how many unique babies
keepers_ws_TE %>%
  distinct(baby_id) %>%
  count()

keepers_ws_TE %>%
  distinct(participant_id) %>%
  count()

# some babies made multiple visits to the lab
keepers_ws_TE %>% 
  distinct(ID_testdate) %>% 
  count()

N_duplicatedBabyID <- keepers_ws_TE %>%
  filter(duplicated(baby_id))

# Create dataframe of demographics
d_participants <- keepers_ws_TE %>%
  select(baby_id, age_continuous, gender, 
         lang_exp_eng, lang_exp_fre, lang_exp_other, years_education) %>%
  mutate(Female = ifelse(gender == "F", 1, 0)) %>%
  summarise(n = n(),
            age_Month = mean(age_continuous, na.rm = TRUE),
            lang_exp_eng = mean(lang_exp_eng, na.rm = TRUE),
            lang_exp_fre = mean(lang_exp_fre, na.rm = TRUE), 
            lang_exp_other = mean(lang_exp_other, na.rm = TRUE),
            years_education = mean(years_education, na.rm = TRUE),
            number_female = sum(Female)) %>%
  mutate(PercentageFemale = number_female/n)
  
```

## Gender 
```{r}
keepers_ws_TE %>%
  group_by(gender) %>% 
  distinct(baby_id, .keep.all=T) %>%
  count()
```

## English dominant
```{r}
# dominance defined by language exposure
keepers_ws_TE %>% group_by(lang_dom) %>% distinct(baby_id) %>%
  count()

# dominance defined by vocab size
keepers_ws_TE %>% group_by(LangDom_vocab) %>% distinct(baby_id) %>%
  count()
```

## years of maternal education
```{r}
keepers_ws_TE %>% distinct(baby_id, .keep_all = T) %>%
  summarize(mean = mean(years_education, na.rm=T), 
            sd = sd(years_education, na.rm=T))
```

## age range, mean
```{r}
keepers_ws_TE %>%
  distinct(baby_id, .keep_all = T) %>% 
  summarize(sd = sd(age_days, na.rm=T))

do.call(cbind, lapply(keepers_ws_TE %>%
                        distinct(baby_id, .keep_all = T) %>% 
                        select(age_days,age_continuous),
                      summary))

```

## average # of TEs
```{r}
keepers_ws_TE %>%
  filter(both_cdi_filled=="Y") %>%
  summarise(mean = mean(propTE, na.rm=T), 
            min= min(propTE, na.rm=T),
            max= max(propTE, na.rm=T))

```


## Percentile information from WordbankR
```{r}

## English Word&Sentence: Vocabulary size at 90% percentile
english_ws_percentile <-  
  fit_vocab_quantiles(get_administration_data("English (American)", "WS"), 
                      production,
                      quantile = "standard") %>%
  # keep only the 90% percentile
  filter(quantile == 0.90) %>%
  rename(EngWS_90percentile = production)

## Canadian French Word&Sentence: Vocabulary size at 90% percentile
french_ws_percentile <-  
  fit_vocab_quantiles(get_administration_data("French (Quebecois)", "WS"), 
                      production,
                      quantile = "standard") %>%
  # keep only the 90% percentile
  filter(quantile == 0.90) %>%
  rename(FrWS_90percentile = production)

## Merge the two percentile dataframe
ws_percentile <- merge(english_ws_percentile, french_ws_percentile, 
                       by = "age") %>%
  # compute estimate total vocab by adding the two languages
  mutate(Average_90percentile = (EngWS_90percentile + FrWS_90percentile)/2) %>%
  # keep only necessary columns
  select(age, EngWS_90percentile, FrWS_90percentile, Average_90percentile) %>%
  # rename age to prepare for the next step (i.e., merging with keepers_ws_TE
  rename(age_months_percentile = age)

write.csv(ws_percentile, "Output/ws_percentile.csv", row.names = F)
```

# Adding percentile info to keepers_ws_TE dataframe & 
## Creating a new propTE based on the percentile
```{r}
# merge the dataframes
keepers_ws_TE <- keepers_ws_TE %>%
  # as the upper age limit of the CDI-WS is 30m, create a new age variable which replaces all >30m as 30m for merging with the percentile dataframe
  # this means the percentile should be the same for all >30m
  mutate(age_months_percentile = ifelse(age_months_binned > 30, 30, age_months_binned)) %>%
  # merge with the percentile data frame
  left_join(ws_percentile, by = "age_months_percentile") 


%>%
  # calculate TE in relation to CDI percentile data
  mutate(propTE_percentile = number_of_te*2/Total_90percentile)
  # %>% select(baby_id, age_months_binned, age_months_percentile, word_vocab, Total_90percentile,
  #       propTE, propTE_CDI, propTE_percentile)

# check if any baby learn more words than the percentile
# (there are 2 babies know more than the percentile in their dominant language)
MoreThanPercentile <- keepers_ws_TE %>%
  select(ID_testdate, age_months_binned, lang_dom, LangDom_vocab, 
         word_vocab, total_words_eng, EngWS_90percentile, 
         total_words_fre, FrWS_90percentile, word_vocab, Total_90percentile) %>%
  filter(total_words_eng > EngWS_90percentile | 
           total_words_fre > FrWS_90percentile |
           word_vocab > Total_90percentile)
```

# Correlation
```{r}
Correlation <- keepers_ws_TE %>%
  select(age_continuous, Average_90percentile, balance_vocab, word_vocab, TotalNW_Dom, TotalNW_NonDom,
         number_of_te, Dom_unique_words, NonDom_unique_words, concept_vocab) %>%
  # recode the balance_vocab so that it would be in descending order, so the value of the most balanced would be the greatest
  mutate(balance_vocab = balance_vocab*-1) %>%
  # rename variables
  rename(Age_month = age_continuous,
         V = Average_90percentile,
         B = balance_vocab, 
         W = word_vocab,
         D = TotalNW_Dom, 
         N = TotalNW_NonDom, 
         TE = number_of_te, 
         Du = Dom_unique_words, 
         Nu = NonDom_unique_words, 
         C = concept_vocab)


library(Hmisc)
mycor <- rcorr(as.matrix(Correlation), type="pearson")
mycor$r
round(mycor$P, 2)

library(corrplot)
mycor <- round(cor(Correlation), 2)
corrplot(mycor)
write.csv(mycor, "Output/ObservedTE_correlations.csv", col.names=NA)

cor.test(Correlation$TE, Correlation$B, method = "pearson")
cor.test(Correlation$TE, Correlation$W, method = "pearson")
cor.test(Correlation$TE, Correlation$D, method = "pearson")
cor.test(Correlation$TE, Correlation$N, method = "pearson")
cor.test(Correlation$TE, Correlation$V, method = "pearson")
cor.test(Correlation$Du, Correlation$B, method = "pearson")
cor.test(Correlation$Nu, Correlation$B, method = "pearson")

```


###### Theoretical distribution of TEs (Simulation): D * N / V (TotalNW_Dom * TotalNW_NonDom / Average_90percentile) ###### 
```{r}
## Create predicted TEs for simulation
keepers_ws_TE_simulation <- keepers_ws_TE %>%
  mutate(Predicted_TE_percentile = TotalNW_Dom * TotalNW_NonDom/Average_90percentile) 


## Linear regressions of predicted TE models
Percentile_model <- keepers_ws_TE_simulation %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model)


## Ploting Y = observed rawTE  & X = Predicted rawTE 
TEprediction_percentile <- keepers_ws_TE_simulation %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
#  facet_grid(. ~TEgroup) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  xlim(-10,430) +
  ylim(-10,430) +
  theme_minimal()

ggsave(here("Output/TEprediction_percentile.png"), TEprediction_percentile,
       height=5, width=5)

# Kolmogorov-Smirnov test to compare the observed and predicted TE
#stats::ks.test(keepers_ws_TE_simulation$number_of_te,
#               keepers_ws_TE_simulation$Predicted_TE_percentile)



## Looking closer at the infants with total vocabulary < 150

keepers_ws_TE_simulation_LessThan300 <- keepers_ws_TE_simulation %>%
  filter(word_vocab < 300)

stats::ks.test(keepers_ws_TE_simulation_LessThan300$number_of_te,
               keepers_ws_TE_simulation_LessThan300$Predicted_TE_percentile)

keepers_ws_TE_simulation_MoreThan300 <- keepers_ws_TE_simulation %>%
  filter(word_vocab > 300)

stats::ks.test(keepers_ws_TE_simulation_MoreThan300$number_of_te,
               keepers_ws_TE_simulation_MoreThan300$Predicted_TE_percentile)

# Plot
TEprediction_percentile_facetW <- keepers_ws_TE_simulation %>%
  mutate(W_group = if_else(word_vocab < 300, "Less than 300 total vocabulary", "More than 300 total vocabulary")) %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  facet_wrap(~ W_group, scales = "free") +
  #facet_grid(. ~ W_group, scales = "free") +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal()

ggsave(here("Output/TEprediction_percentile_facetW.png"), TEprediction_percentile_facetW,
       height=5,width=10)


Percentile_model_LessThan300W <- keepers_ws_TE_simulation %>%
  filter(word_vocab < 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_LessThan300W)

Percentile_model_MoreThan300W <- keepers_ws_TE_simulation %>%
  filter(word_vocab > 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_MoreThan300W)

```





















# plots
## proportion of TEs
```{r}
keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  ggplot(aes(x = age.days/30, 
             y = propTE)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2))+
  ylab("Percentage of Translation Equivalents") +
  xlab("Age in Months")+
  ggtitle("Percentage of Translation Equivalents by Age") +  
  theme_classic(base_size = 22) +
  scale_x_continuous(breaks= seq(18,32,by = 2))+
  geom_point(size=3) + 
  geom_smooth(method="lm" )

ggsave(here("Output","PlotbyAge.png"), height=10,width=10)
```

## Bar graphs with individual scores (percentage TEs by dominance)
```{r}
keepers_ws_summarize = keepers_ws_TE %>% 
  group_by(balance_group15) %>%
  summarize(mean = mean(propTE, na.rm = T),
         N = n(),
         sd = sd(propTE, na.rm=T),
         se = sd(propTE, na.rm = T)/ sqrt(N)) 


ggplot(data=keepers_ws_summarize,
       aes(x=balance_group15,
           y=mean)) +
    geom_bar(aes(fill = balance_group15),
             show.legend =F,
             colour="black",
             stat="identity",
             position="dodge", width=.7) +
  
   geom_point(data = keepers_ws_TE,aes( y = propTE, fill = balance_group15), alpha = 0.9, show.legend = F, color = "black", pch = 21,size=1.75, 
   stat = "identity",position=position_jitterdodge()) +
  geom_errorbar(aes(ymin = mean - se, 
                    ymax = mean + se), 
                width=0.2,
                position=position_dodge(.9)) +
    ylab("Percentage of Translation Equivalents\n") +
    xlab("Balance") +
scale_x_discrete(breaks= c("80_20", "70_30", "60_40", "50_50"),
                        labels =c("80:20","70:30","60:40","50:50"))+
    ggtitle("Percentage of Translation Equivalents by Balance") +
    theme_classic(base_size = 22) +
  scale_y_continuous(labels = scales::percent_format(accuracy=2))+
    theme(axis.text.x = element_text(angle = 45, hjust = 1), 
          plot.title = element_text(hjust = .5))

ggsave(here("output","PlotTE_byBalance.png"), width=9.5, height= 7)
```
## age by balancedness
```{r}
keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  group_by(balance_group15) %>%
  summarize(median.age = median(age.days))


keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  ggplot(aes(x=balance_group15, y=age.days/30, colour=balance_group15))+
  geom_pirate(bars=F) +ylab("Age (Months)") + coord_flip()

```





## TE: age plot by balancedness
```{r}
keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  ggplot(aes(x = age.days/30, 
             y = propTE)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2))+
  ylab("Percentage of Translation Equivalents\n") +
  xlab("Age in Months")+
  ggtitle("Percentage of Translation Equivalents by Age and Balance") +  guides(colour = guide_legend(reverse=TRUE))+

  theme_classic(base_size = 22) +
 # scale_x_continuous(breaks= seq(18,32,by = 2))+
  geom_point(size=3, colour= "darkgrey") + 
  geom_smooth(size =2, aes(colour=balance_group15), method="lm", se=F)+
  scale_colour_discrete(name="Balance", 
                        breaks= c("80_20", "70_30", "60_40", "50_50"),
                        labels =c("least balanced (80:20)","less balanced (70:30)","more balanced (60:40)","most balanced (50:50)"))
ggsave(here("Output","PlotTE_BalanceByAge.png"), width=13, height= 7)


```







# Statistical tests
## ANOVA for balance
```{r}
res.aov <- aov(propTE ~ balance_group15*cent.age.months, data=keepers_ws_TE) 
summary(res.aov)
```

## Age (old code, not used for poster)
### Running linear model
```{r}
  linear.model<-lmer(propTE ~ cent.age.months+ (1|Baby_ID), data = keepers_ws_TE)
  summary(linear.model)
```
### Running quadratic model
```{r}
 quadratic.model <-lmer(propTE ~ poly(cent.age.months,2) + (1|Baby_ID), data = keepers_ws_TE)
  summary(quadratic.model)
```
### Cubic model
```{r}
cubic.model<-lm(propTE ~ poly(cent.age.months,3), data = keepers_ws_TE)
summary(cubic.model)
```


