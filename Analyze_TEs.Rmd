---
title: "acquisition of TEs"
date: "Last update: Nov 27th 2020"
output: 
  html_document: 
    code_folding: show
    collapsed: no
    df_print: kable
    highlight: espresso
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
editor_options: 
  chunk_output_type: console
---
# Preparations
## load libraries
```{r}

# install.packages("devtools")
#devtools::install_github("mikabr/ggpirate")

library(here)
library(tidyverse)
library(tidylog)
library(wordbankr)
library(ggplot2)
library(patchwork)
library(gridExtra)
library("ggpubr")

library(lme4)
library(lmerTest)
library(scales)

`%notin%` <- Negate(`%in%`)

```

# load data
```{r}
cdi_ws = readRDS(here::here("Data","output_analyzeSent.Rdata"))
```

# Participant Exclusions
exclude babies out of 18-33m age range, monolinguals and those with >10% 3rd language exposure
```{r}
# exclude kids that are bilingual at one visit, monolingual at another (regardless of direction)
# switch from other to bilingual, or vice versa, or from other to monolingual and vice versa are ok
exclude.lang_group_change  = cdi_ws %>%
  filter(lang_group !="other") %>%
  group_by(baby_id) %>% 
  distinct(ID_testdate, .keep_all = T) %>%
  mutate(visit_num = 1:n()) %>%  
  mutate(changed_language_group_status = if_else(visit_num == 1, NA, 
                                                 lang_group != lag(lang_group))) %>%
  # uncomment see all visits for babies that have one visit excluded
  #filter(any(changed_language_group_status == TRUE) ) %>% View()
  filter(changed_language_group_status == TRUE) %>% 
  pull(ID_testdate)


# Create exclusion criteria variables
cdi_ws_TE <- cdi_ws %>%
  mutate(
    # create an exclusion criteria for language
    exclude.language = case_when(
      # exclude babies with more than 10% exposure to a 3rd language
      lang_exp_other > 10 ~ 1,
      # exclude language group status changed from bilingual to mono or vice versa
      ID_testdate %in% exclude.lang_group_change ~ 1, 
      lang_group == "bilingual" ~ 0, #bilingual
      lang_group == "monolingual" ~ 0, # monolingual
      TRUE ~ 1), # all other cases exlude
    
    # create an exclusion criteria for age
    exclude.age = case_when(!between(age_months_binned, 18, 33) ~ 1, 
                            TRUE ~ 0) # all other cases keep
  )


# Exclude participants
keepers_ws_TE <- cdi_ws_TE %>%
  filter(
    # exclude participants who have exposure to a third language/ are neither bilingual nor monolingual
    exclude.language == 0,
    # exclude participants who don't fit age range
    exclude.age == 0,
    # exclude participants who don't have both CDI filled
    both_cdi_filled == "Y",
    # keep only babies with at least 15% of E and 15% of F (i.e., exclude monolinguals)
    lang_exp_eng >= 15 & lang_exp_eng <= 85,
    lang_exp_fre >= 15 & lang_exp_fre <= 85)


### Check how many distinct participants and data point we have
keepers_ws_TE %>% summarize(N_visits = n_distinct(ID_testdate),
                            N_babies = n_distinct(baby_id),
                            N_admin = sum(n_administrations, na.rm=T))


### Check if there is any NAs in the vocabulary measures (should all return 0)
keepers_ws_TE %>% filter(is.na(vocab_score)) %>% 
  select(ID_testdate, vocab_type, vocab_score) %>%
  nrow()

keepers_ws_TE %>% filter(is.na(eng_unique_words)) %>% 
  select(ID_testdate) %>% 
  nrow()

keepers_ws_TE %>% filter(is.na(fre_unique_words)) %>% 
  select(ID_testdate) %>%
  nrow()

keepers_ws_TE %>% filter(is.na(number_of_te)) %>% 
  select(ID_testdate) %>%
  nrow()
```

# Prepare the dataset
```{r}
keepers_ws_TE <- keepers_ws_TE %>%
  # keep only necessary variables
  select(-c(vocab_type_dom, vocab_cross_lang, n_administrations)) %>% #n_administrations
  spread(vocab_type, vocab_score) %>%
  # calculate age in months (with decimal)
  mutate(age_month_decimal = age_days/30) %>%
  #defining dominance based on input
  #mutate(TotalNW_Dom_input = case_when(lang_dom == "English" ~ total_words_eng,
  #                                        lang_dom == "French" ~ total_words_fre),
  #       TotalNW_NonDom_input = case_when(lang_dom == "English" ~ total_words_fre,
  #                                           lang_dom == "French" ~ total_words_eng),
  #       Dom_unique_words_input = case_when(lang_dom == "French" ~ fre_unique_words, 
  #                                             lang_dom == "English" ~ eng_unique_words),
  #       NonDom_unique_words_input = case_when(lang_dom == "French" ~ eng_unique_words, 
  #                                       lang_dom == "English" ~ fre_unique_words)) %>%
  #mutate(balance_input = balance/100) %>%
  #defining dominance based on vocabulary size
  mutate(LangDom_vocab = case_when(total_words_eng > total_words_fre ~ "English",
                                 TRUE ~ "French")) %>%
  mutate(LangDom_vocab = as.factor(LangDom_vocab)) %>%
  mutate(TotalNW_Dom = case_when(total_words_eng > total_words_fre ~ total_words_eng,
                                 TRUE ~ total_words_fre),
         TotalNW_NonDom = case_when(total_words_eng > total_words_fre ~ total_words_fre,
                                    TRUE ~ total_words_eng),
         Dom_unique_words = case_when(total_words_eng > total_words_fre ~ eng_unique_words,
                                      TRUE ~ fre_unique_words),
         NonDom_unique_words = case_when(total_words_eng > total_words_fre ~ fre_unique_words,
                                         TRUE ~ eng_unique_words)) %>%
  mutate(TotalUnique = Dom_unique_words + NonDom_unique_words) %>%
  #Defining vocabulary-based balance score
  mutate(balance_vocab = TotalNW_NonDom/(TotalNW_Dom+TotalNW_NonDom)) %>%
  #defining dominance based on input (with reference to the lang_dom defined by vocab size)
  mutate(LangDom_input = case_when(LangDom_vocab == "English" ~ lang_exp_eng,
                                    TRUE ~ lang_exp_fre),
         LangNonDom_input = case_when(LangDom_vocab == "English" ~ lang_exp_fre,
                                    TRUE ~ lang_exp_eng)) %>%
  mutate(balance_input = LangNonDom_input/(LangDom_input+LangNonDom_input))

write.csv(keepers_ws_TE, "Data/keepers_ws_TE.csv", row.names = F)

```

# Percentile information from WordbankR
```{r}

## English Word&Sentence: Vocabulary size at 90% percentile
english_ws_percentile <-  
  fit_vocab_quantiles(get_administration_data("English (American)", "WS"), 
                      production,
                      quantile = "standard") %>%
  # keep only the 90% percentile
  filter(quantile == 0.90) %>%
  rename(EngWS_90percentile = production)

## Canadian French Word&Sentence: Vocabulary size at 90% percentile
french_ws_percentile <-  
  fit_vocab_quantiles(get_administration_data("French (Quebecois)", "WS"), 
                      production,
                      quantile = "standard") %>%
  # keep only the 90% percentile
  filter(quantile == 0.90) %>%
  rename(FrWS_90percentile = production)

## Merge the two percentile dataframe
ws_percentile <- merge(english_ws_percentile, french_ws_percentile, 
                       by = "age") %>%
  # compute estimate total vocab by adding the two languages
  mutate(Average_90percentile = (EngWS_90percentile + FrWS_90percentile)/2) %>%
  # keep only necessary columns
  select(age, EngWS_90percentile, FrWS_90percentile, Average_90percentile) %>%
  # rename age to prepare for the next step (i.e., merging with keepers_ws_TE
  rename(age_months_percentile = age)

write.csv(ws_percentile, "Output/ws_percentile.csv", row.names = F)
```

# CDI percentile for the hypothetical child Jamie
```{r}
english_ws_percentile_18 <-  
  fit_vocab_quantiles(get_administration_data("English (American)", "WS"), 
                      production,
                      quantile = "standard") %>%
  filter(age == 18) %>%
  rename(English = production) 

french_ws_percentile_18 <-  
  fit_vocab_quantiles(get_administration_data("French (Quebecois)", "WS"), 
                      production,
                      quantile = "standard") %>%
  filter(age == 18) %>%
  rename(French = production) 

ws_percentile_18 <- merge(english_ws_percentile_18, french_ws_percentile_18, 
                       by = c("form", "age","quantile")) %>%
  # compute estimate total vocab by adding the two languages
  mutate(Average_90percentile = (English + French)/2) %>%
  select(-c(language.x, language.y))

```

# Adding percentile info to keepers_ws_TE dataframe & 
## Creating a new propTE based on the percentile
```{r}
# merge the dataframes
keepers_ws_TE <- keepers_ws_TE %>%
  # as the upper age limit of the CDI-WS is 30m, create a new age variable which replaces all >30m as 30m for merging with the percentile dataframe
  # this means the percentile should be the same for all >30m
  mutate(age_months_percentile = ifelse(age_months_binned > 30, 30, age_months_binned)) %>%
  # merge with the percentile data frame
  left_join(ws_percentile, by = "age_months_percentile") 
```


# Simulation 1: simulating infants of the same developmental level with different word vocabularies and balances of exposure (V = 600)
```{r}
## generate the simulation data
simulation1 <- function (V) {
  D_seq <- seq(100, V, by = 100) # sequence of D from 100 to V at an interval of 100
  N_seq <- seq(0, V, by = 10) # sequence of N from 0 to V at an interval of 10
  D <- rep (D_seq, length(N_seq))
  N <- rep(N_seq, length(D_seq))
  data_simulation1 <<- data.frame(V, D, N)
}

simulation1(600) # setting V = 600

## clean the simulation data
data_simulation1 <- data_simulation1 %>%
  arrange(D, N) %>%
  filter(N <= D) %>%
  # Get word vocabulary W
  mutate(W = D + N) %>%
  # Create other variables
  mutate(B = N/(D+N), # balance,
         TE = (D*N)/V) %>% # If D and N are independent, TE = DN/V
  # Round to keep whole numbers only
  mutate_at(vars(-B), round, 0) %>%
  # bin B into 6 groups
  mutate(bin_B = cut(B, breaks = 5, 
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  arrange(D, N, bin_B)

## visualizing Simulation 1
simulation1 <- data_simulation1 %>%
  # convert to long data
  pivot_longer(c(W, D, N), names_to = "vocab_type", values_to = "number") %>%
  mutate(vocab_type = factor(vocab_type, levels=c("D", "N", "W"))) %>%
  mutate(vocab_type = recode(vocab_type, 
                             D = "Panel 1A: Dominant vocabulary (D)", 
                             N = "Panel 1B: Non-dominant vocabulary (N)",
                             W = "Panel 1C: Total vocabulary (W)")) %>%
  ggplot(aes(x = number, y = TE, color = bin_B, linetype = bin_B)) +
  stat_smooth(method = lm, se = F) +
  scale_color_manual(values=c("#bdbdbd", "#737373", "#525252", "#252525", "#000000")) + 
  scale_linetype_manual(values=c("longdash", "dotdash", "dashed", "twodash", "solid")) +
  #scale_color_manual(values=c("#5e4fa2", "#3288bd", "#abdda4", "#fee08b", "#fc8d59", "#d53e4f")) + 
  #scale_color_discrete(direction = -1) +
  theme_minimal() + 
  facet_grid(. ~ vocab_type) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom",
        plot.title = element_text(face = 'bold', size = 18, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=14),
        panel.spacing.x = unit(2, "lines"),
        panel.background = element_rect(fill = NA, color = "black")) +
  ylim(0, 200) +
  labs(x = "Number of words", 
       y = "Total number of translation equivalents (TE)", 
       color = "Balance (B)",
       linetype = "Balance (B)",
       title = "1) Simulated data") +
  guides(color = guide_legend(reverse = T, nrow = 1),
         linetype = guide_legend(reverse = T, nrow = 1)) 

ggsave("Output/plot_Simulation1.png", simulation1,
       width = 10, height = 5)
```

## Observed data: Testing Simulation 1
```{r}
Observed_plot_inputs_TE <- keepers_ws_TE %>% 
  select(baby_id, ID_testdate, age_days, number_of_te, word_vocab, TotalNW_Dom, TotalNW_NonDom, balance_vocab) %>%
  pivot_longer(c(word_vocab, TotalNW_Dom, TotalNW_NonDom), names_to = "vocab_type", values_to = "number") %>%
  mutate(vocab_type = factor(vocab_type, levels=c("TotalNW_Dom", "TotalNW_NonDom", "word_vocab"))) %>%
  mutate(vocab_type = recode(vocab_type, 
                             TotalNW_Dom = "Panel 2A: Dominant vocabulary (D)", 
                             TotalNW_NonDom = "Panel 2B: Non-dominant vocabulary (N)",
                             word_vocab = "Panel 2C: Total vocabulary (W)")) %>%
  mutate(bin_B = cut(balance_vocab, breaks = 5, 
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  #mutate(bin_B = case_when(balance_vocab < 0.2 ~ "0.1",
  #                         balance_vocab >= 0.2 & balance_vocab < 0.3 ~ "0.2",
  #                         balance_vocab >= 0.3 & balance_vocab < 0.4 ~ "0.3",
  #                         balance_vocab >= 0.4 & balance_vocab < 0.5 ~ "0.5",
  #                         TRUE ~ "0.5")) %>%
  ggplot(aes(x = number, y = number_of_te, color = bin_B, linetype = bin_B)) +
  #geom_point() +
  stat_smooth(method = lm, se = F) +
  #scale_color_manual(values=c("#3288bd", "#abdda4", "#fee08b", "#fc8d59", "#d53e4f")) + 
  scale_color_manual(values=c("#bdbdbd", "#737373", "#525252", "#252525", "#000000")) + 
  scale_linetype_manual(values=c("longdash", "dotdash", "dashed", "twodash", "solid")) + 
  theme_minimal() + 
  facet_grid(. ~ vocab_type) +
  theme(axis.text.x = element_text(angle = 90),
        plot.title = element_text(face = 'bold', size = 18, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=14),
        legend.position = "bottom",
        panel.spacing.x = unit(2, "lines"),
        panel.background = element_rect(fill = NA, color = "black")) +
  labs(x = "Number of words", 
       y = "Total number of translation equivalents (TE)", 
       color = "Balance (B)",
       linetype = "Balance (B)",
       title = "2) Observed data") +
  guides(colour = guide_legend(reverse = T, nrow = 1),
         linetype = guide_legend(reverse = T, nrow = 1))

  
plot_Simulation1plusData <- ggarrange(simulation1, 
                                      Observed_plot_inputs_TE,
                                      nrow = 2,
                                      common.legend = TRUE, legend = "bottom")

ggsave("Output/plot_Simulation1plusData.png", plot_Simulation1plusData,
       width = 10, height = 10)

#ggsave("Output/Observed_plot_inputs_TE.png", Observed_plot_inputs_TE,
#       width = 10, height = 5)


### one-way ANOVA to compare the 5 balance groups
aov_TE_binB <- keepers_ws_TE %>% 
  mutate(bin_B = cut(balance_vocab, breaks = 5, 
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  aov(number_of_te ~ bin_B, data = .)

summary(aov_TE_binB)

mean_TE_binB <- keepers_ws_TE %>% 
  mutate(bin_B = cut(balance_vocab, breaks = 5, 
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  group_by(bin_B) %>%
  summarize(n = n(),
            mean_TE = mean(number_of_te, na.rm = T),
            sd_TE = sd(number_of_te, na.rm = T),
            min_TE = min(number_of_te, na.rm = T),
            max_TE = max(number_of_te, na.rm = T),)
  
```



# Simulation 2: simulating patterns of translation equivalent learning as a function of different developmental timepoints (V = 300, 450, or 600)
```{r}
## generate the simulation data
V <- seq(300, 600, by = 150) # set V to 300, 450, and 600

simulation2 <- function (V) {
  D_seq <- seq(100, V, by = 100) # sequence of D from 100 to V at an interval of 100
  N_seq <- seq(0, V, by = 25) # sequence of N from 0 to V at an interval of 25
  D <- rep(D_seq, length(N_seq))
  N <- rep(N_seq, length(D_seq))
  data_simulation2 <<- data.frame(V, D, N)
}

data_simulation2 <- do.call(rbind, lapply(V, simulation2)) %>%
  arrange(V, D, N) %>%
  filter(N <= D) %>%
  # Create other variables
  mutate(W = D + N, # word vocabulary W
         B = N/(D+N), # balance,
         TE = (D*N)/V, # If D and N are independent, TE = DN/V
         DI = D-TE, # Unique words in dominant language
         NI = N-TE) %>% # Unique words in non-dominant language
  # Round to keep whole numbers only
  mutate_at(vars(-B), round, 0) %>%
  # bin B into 3 groups
  mutate(bin_B = case_when(B >= 0.36 ~ "Most Balanced",
                           B <= 0.20 ~ "Least Balanced",
                           TRUE ~ "Medium Balanced")) %>%
  mutate(bin_B  = fct_rev(bin_B)) %>%
  arrange(D, N, bin_B)

## visualizing Simulation 2
simulation2 <- data_simulation2 %>%
  pivot_longer(-c(V, W, B, bin_B), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("D", "N")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("NI", "DI", "TE"))) %>%
  mutate(V_label = case_when(V == 600 ~ "V = 600",
                             V == 450 ~ "V = 450",
                             V == 300 ~ "V = 300")) %>%
  group_by(V, V_label, bin_B, vocab_type) %>%
  summarise(n_words = mean(number)) %>%
  ggplot(aes(x = bin_B, y = n_words, fill = vocab_type)) + 
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ V_label) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_x_discrete(labels = function(BalSubset) str_wrap(BalSubset, width = 10)) + 
  ylim(0, 600) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(face = 'bold', size = 18, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=14),
        panel.spacing.x = unit(2, "lines")) + 
  labs(x = "\nBalance (B)", 
       y = "Number of concepts (C)", 
       title = "Panel A: Simulated data")

ggsave("Output/plot_Simulation2.png", simulation2,
        width = 10, height = 5)
```

## Observed data: Testing Simulation 2
```{r}
plot_stacked_byV <- keepers_ws_TE %>%
  select(baby_id, age_months_percentile, balance_vocab, word_vocab, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(V_subset = case_when(age_months_percentile <= 22 ~ "18-22 months (V = 244.9 - 451.9)",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months (V = 491.8 - 604.1)",
                              TRUE ~ "28-33 months (V = 620.4 - 638.9)")) %>%
  mutate(BalSubset = case_when(balance_vocab >= 0.36 ~ "Most Balanced",
                               balance_vocab <= 0.20 ~ "Least Balanced",
                               TRUE ~ "Medium Balanced")) %>%
  mutate(BalSubset = fct_rev(BalSubset)) %>%
 # mutate(BalSubset = factor(BalSubset, levels=c("Most Balanced", "Medium Balanced", "Least Balanced"))) %>%
  arrange(desc(number_of_te)) %>%
  mutate(TE = number_of_te) %>%
  pivot_longer(-c(baby_id, age_months_percentile, balance_vocab, V_subset, BalSubset, word_vocab, TE), 
               names_to = "Type", values_to = "NumberOfWords") %>%
  mutate(Type = factor(Type, levels=c("NonDom_unique_words", "Dom_unique_words", "number_of_te"))) %>%
  mutate(Type = recode(Type, 
                       NonDom_unique_words = "Initial non-dominant word (NI)", 
                       Dom_unique_words = "Initial dominant word (DI)", 
                       number_of_te = "Translation equivalent (TE)")) %>%
  group_by(age_months_percentile, BalSubset, Type) %>%
  summarise(n_words = mean(NumberOfWords)) %>%
  ggplot(aes(x = BalSubset, y = n_words, fill = Type)) +
  geom_bar(position="stack", stat="identity") +
#  facet_grid(. ~ age_months_percentile) +
  facet_wrap(. ~ age_months_percentile, ncol = 4) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) + 
  scale_x_discrete(labels = function(BalSubset) str_wrap(BalSubset, width = 10)) + 
  ylim(0, 600) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0) , 
        legend.position = "bottom",
        plot.title = element_text(face = 'bold', size = 18, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=14),
        panel.spacing.x = unit(2, "lines")) + 
  labs(x = "\nBalance (B)", 
       y = "Number of concepts (C)",
       title = "Panel B: Observed data") 


plot_Simulation2plusData <- ggarrange(simulation2 + rremove("legend"), 
                                      plot_stacked_byV,
                                      nrow = 2,
                                      heights=c(0.9,1))

ggsave("Output/plot_Simulation2plusData.png", plot_Simulation2plusData,
       width = 10, height = 10)

# One-way Anova to compare the 3 V groups
keepers_ws_TE_3Vsubset <- keepers_ws_TE %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(V_subset = case_when(age_months_percentile <= 22 ~ "18-22 months (V = 244.9 - 451.9)",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months (V = 491.8 - 604.1)",
                              TRUE ~ "28-33 months (V = 620.4 - 638.9)"))

summary(aov(concept_vocab ~ V_subset, data = keepers_ws_TE_3Vsubset))

mean_conceptV_Vsubset <- keepers_ws_TE_3Vsubset %>%
  group_by(V_subset) %>%
  summarise(mean_conceptV = mean(concept_vocab, na.rm = T),
            sd_conceptV = sd(concept_vocab, na.rm = T),
            min_conceptV = min(concept_vocab, na.rm = T),
            max_conceptV = max(concept_vocab, na.rm = T))

pairwise.t.test(keepers_ws_TE_3Vsubset$concept_vocab, keepers_ws_TE_3Vsubset$V_subset,
                 p.adjust.method = "bonferroni")

## Mean proportion of TE
stacked_byV_wide <- keepers_ws_TE %>%
  select(baby_id, age_months_percentile, balance_vocab, word_vocab, concept_vocab, 
         propTE, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(V_subset = case_when(age_months_percentile <= 22 ~ "18-22 months",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months",
                              TRUE ~ "28-33 months")) %>%
  mutate(BalSubset = case_when(balance_vocab <= 0.65 ~ "Most Balanced",
                               balance_vocab >= 0.80 ~ "Least Balanced",
                               TRUE ~ "Medium Balanced")) 


stacked_byV_wide %>%
  group_by(V_subset) %>%
  summarise(mean_propTE = mean(propTE, na.rm=T), 
            sd_propTE = sd(propTE, na.rm=T),
            min_propTE = min(propTE, na.rm=T),
            max_propTE = max(propTE, na.rm=T))

# Anova to compare the number of TEs among the 3 developmental groups in the stacked barchart
stacked_byV_wide %>%  
  group_by(V_subset) %>%
  summarise(mean_TE = mean(number_of_te, na.rm=T), 
            sd_TE = sd(number_of_te, na.rm=T),
            min_TE = min(number_of_te, na.rm=T),
            max_TE = max(number_of_te, na.rm=T))

TE_byV_anova <- aov(propTE ~ V_subset, data = stacked_byV_wide)
summary(TE_byV_anova)

pairwise.t.test(stacked_byV_wide$number_of_te, stacked_byV_wide$V_subset,
                 p.adjust.method = "BH")


## Anova to compare the unique dom vocab size and unique non-dom vocab size among the 3 developmental groups in the stacked barchart
stacked_byV_wide %>%  
  group_by(BalSubset) %>%
  summarise(mean_DI = mean(Dom_unique_words, na.rm=T), 
            sd_DI = sd(Dom_unique_words, na.rm=T),
            min_DI = min(Dom_unique_words, na.rm=T),
            max_DI = max(Dom_unique_words, na.rm=T))

DI_byB_anova <- aov(Dom_unique_words ~ BalSubset, data = stacked_byV_wide)
summary(DI_byB_anova)

pairwise.t.test(stacked_byV_wide$Dom_unique_words, stacked_byV_wide$BalSubset,
                 p.adjust.method = "BH")


stacked_byV_wide %>% 
  group_by(BalSubset) %>%
  summarise(mean_NI = mean(NonDom_unique_words, na.rm=T), 
            sd_NI = sd(NonDom_unique_words, na.rm=T),
            min_NI = min(NonDom_unique_words, na.rm=T),
            max_NI = max(NonDom_unique_words, na.rm=T))

NI_byB_anova <- aov(NonDom_unique_words ~ BalSubset, data = stacked_byV_wide)
summary(NI_byB_anova)

pairwise.t.test(stacked_byV_wide$NonDom_unique_words, stacked_byV_wide$BalSubset,
                 p.adjust.method = "BH")

```



# Simulation 3: Non-independence of dominant-language (D) and non-dominant language words (N)
```{r}
## generate the simulation data
V <- seq(150, 600, by = 150) # set V to 300, 450, and 600

simulation3 <- function (V) {
  D_seq = seq(100, V, by = 100) # sequence of D from 100 to V at an interval of 50
  N_seq = seq(0, V, by = 25) # sequence of N from 0 to V at an interval of 25
  D <- rep(D_seq, length(N_seq))
  N <- rep(N_seq, length(D_seq))
  data_simulation3 <<- data.frame(V, D, N)
}

data_simulation3 <- do.call(rbind, lapply(V, simulation3)) %>%
  arrange(V, D, N) %>%
  filter(N <= D) %>% # eliminate cases when N > D
  mutate(W = D+N, # word vocabulary W
         B = N/(D+N), # balance B
         TE = D*N/V) %>% # If D and N are independent, TE = DN/V
  mutate_at(vars(-B), round, 0) %>%
  mutate(bin_B = cut(B, breaks = 5, 
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  arrange(bin_B)


## Simulation3: TE = IND * (D*N/V)
### defining the independence parameter I
IND1 = 1.5 # IND > 1, TEs are MORE easily learned than unique words
IND2 = 0.5 # IND < 1, TEs are LESS easily learned than unique words

### visualizing the simulation
simulation3 <- data_simulation3 %>%
  ## calculate where IND > 1
  mutate(TE_easier = IND1*(D*N/V)) %>%
  ## calculate where IND < 1
  mutate(TE_harder = IND2*(D*N/V)) %>%
  # round to keep whole numbers only
  mutate_at(vars(-c(B, bin_B)), round, 0) %>%
  # prepare dataset to plot
  pivot_longer(c(TE, TE_harder, TE_easier), 
               names_to = "Model", values_to = "number_TE") %>%
  mutate(Model = factor(Model, levels=c("TE_harder", "TE", "TE_easier"))) %>%
  mutate(Model = recode(Model, 
                        TE = "IND = 1 (Independence Account)",
                        TE_easier = "IND = 1.5 (Enhancement Account)",
                        TE_harder = "IND = 0.5 (Avoidance Account)")) %>%
  # ggplot
  ggplot(aes(x = W, y = number_TE, color = bin_B, linetype = bin_B)) +
  stat_smooth(method = lm, se = F) +
  scale_color_manual(values=c("#bdbdbd", "#737373", "#525252", "#252525", "#000000")) + 
  scale_linetype_manual(values=c("longdash", "dotdash", "dashed", "twodash", "solid")) + 
  # scale_color_discrete(direction = -1) +
  theme_minimal() + 
  facet_grid(. ~ Model) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom") +
  theme(plot.title = element_text(hjust = 0.5),
        text = element_text(size=12),
        panel.spacing.x = unit(2.5, "lines"),
        panel.background = element_rect(fill = NA, color = "black")) +
  labs(x = "Total word vocabulary (W)", 
       y = "Total number of translation equivalents (TE)", 
       color = "Balance (B)",
       linetype = "Balance (B)") +
  guides(colour = guide_legend(reverse = T, nrow = 1),
         linetype = guide_legend(reverse = T, nrow = 1))

ggsave("Output/plot_Simulation3.png", simulation3, 
       width = 10, height = 5)
```

# Testing Simulation 3: Figures 7 & 8
## Theoretical distribution of TEs (Simulation): D * N / V (TotalNW_Dom * TotalNW_NonDom / Average_90percentile) 
```{r}
## Create predicted TEs for simulation
keepers_ws_TE_simulation <- keepers_ws_TE %>%
  mutate(Predicted_TE_percentile = TotalNW_Dom * TotalNW_NonDom/Average_90percentile) %>%
  select(baby_id, ID_testdate, Predicted_TE_percentile, number_of_te, Average_90percentile, TotalNW_Dom, TotalNW_NonDom, word_vocab, age_months_binned)

## LM model
Percentile_model <- keepers_ws_TE_simulation %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model)

## Ploting Y = observed rawTE  & X = Predicted rawTE 
TEprediction_percentile <- keepers_ws_TE_simulation %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
#  facet_grid(. ~TEgroup) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
#  geom_text(aes(label=ID_testdate)) +
  geom_abline(linetype = 2, alpha = 0.5) +
  xlim(-10,450) +
  ylim(-10,450) +
  theme_minimal()

ggsave(here("Output/TEprediction_percentile.png"), TEprediction_percentile,
       height=5, width=5)






## Identifying outliers
CheckOutliers_model <- keepers_ws_TE_simulation %>%
  lm(number_of_te ~ 0 + Predicted_TE_percentile, 
#  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom,
     data = .)
summary(CheckOutliers_model)

keepers_ws_TE_simulation$CD <- cooks.distance(CheckOutliers_model)

TEprediction_percentile_CD <- keepers_ws_TE_simulation %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = T) +
  geom_point(size=3, aes(color=CD)) +
  geom_text(aes(label=ID_testdate)) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal()

qplot_CD <- qplot(keepers_ws_TE_simulation$CD)

grid.arrange(TEprediction_percentile_CD, qplot_CD, ncol = 2)

keepers_ws_TE_simulation_removeCD <- filter(keepers_ws_TE_simulation, CD < 0.4)

TEprediction_percentile_removeCD <- keepers_ws_TE_simulation_removeCD %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = T) +
  geom_point(size=3) +
  geom_text(aes(label=ID_testdate)) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal()

grid.arrange(TEprediction_percentile_removeCD, TEprediction_percentile_CD, ncol = 2)


Percentile_model_removeCD <- keepers_ws_TE_simulation_removeCD %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_removeCD)

## Ploting Y = observed rawTE  & X = Predicted rawTE 
TEprediction_percentile_NoOutliers <- keepers_ws_TE_simulation_removeCD %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
#  facet_grid(. ~TEgroup) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  xlim(-10,430) +
  ylim(-10,430) +
  theme_minimal()


Percentile_model_NoOutliers_LessThan300W <- keepers_ws_TE_simulation_removeCD %>%
  filter(word_vocab < 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_NoOutliers_LessThan300W)

Percentile_model_NoOutliers_MoreThan300W <- keepers_ws_TE_simulation_removeCD %>%
  filter(word_vocab > 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_NoOutliers_MoreThan300W)







## Looking closer at the infants with total vocabulary < 300

keepers_ws_TE_simulation_LessThan300 <- keepers_ws_TE_simulation %>%
  filter(word_vocab < 300)

stats::ks.test(keepers_ws_TE_simulation_LessThan300$number_of_te,
               keepers_ws_TE_simulation_LessThan300$Predicted_TE_percentile)

keepers_ws_TE_simulation_MoreThan300 <- keepers_ws_TE_simulation %>%
  filter(word_vocab > 300)

stats::ks.test(keepers_ws_TE_simulation_MoreThan300$number_of_te,
               keepers_ws_TE_simulation_MoreThan300$Predicted_TE_percentile)

# Plot
TEprediction_percentile_facet_lessW300 <- keepers_ws_TE_simulation %>%
  mutate(W_group = if_else(word_vocab < 300, "Less than 300 total vocabulary", "More than 300 total vocabulary")) %>%
  filter(W_group == "Less than 300 total vocabulary") %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs",
       title = "Less than 300 total vocabulary") +
  xlim(0,80) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

TEprediction_percentile_facet_moreW300 <- keepers_ws_TE_simulation %>%
  mutate(W_group = if_else(word_vocab < 300, "Less than 300 total vocabulary", "More than 300 total vocabulary")) %>%
  filter(W_group == "More than 300 total vocabulary") %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs",
       title = "More than 300 total vocabulary") +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

TEprediction_percentile_facetByW300 <- 
  ggarrange(TEprediction_percentile_facet_lessW300 + rremove("x.title"), 
            TEprediction_percentile_facet_moreW300 + rremove("xy.title"), 
            ncol = 2, nrow = 1) %>%
  annotate_figure(bottom = text_grob("Number of TEs predicted by the Bilingual Vocabulary Model"))

ggsave(here("Output/TEprediction_percentile_facetW.png"), TEprediction_percentile_facetByW300,
       height=5,width=10)


Percentile_model_LessThan300W <- keepers_ws_TE_simulation %>%
  filter(word_vocab < 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_LessThan300W)

Percentile_model_MoreThan300W <- keepers_ws_TE_simulation %>%
  filter(word_vocab > 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_MoreThan300W)


age_info <- keepers_ws_TE %>%
  mutate(group = if_else(word_vocab < 300, "LessThan300W", "MoreThan300W")) %>%
  group_by(group) %>%
  summarize(n = n(),
             mean_age = mean(age_continuous, na.rm = T),
             sd_age = sd(age_continuous, na.rm = T),
             min_age = min(age_continuous, na.rm = T),
             max_age = max(age_continuous, na.rm = T))




Percentile_model_LessThan300W <- keepers_ws_TE_simulation %>%
  filter(number_of_te < 130) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_LessThan300W)

Percentile_model_MoreThan300W <- keepers_ws_TE_simulation %>%
  filter(number_of_te > 130) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + TotalNW_Dom:TotalNW_NonDom, 
     data = .)

summary(Percentile_model_MoreThan300W)

```



# Descriptives
## Gender 
```{r}
keepers_ws_TE %>%
  group_by(gender) %>% 
  distinct(baby_id, .keep.all=T) %>%
  count()
```

## English dominant
```{r}
# dominance defined by language exposure
keepers_ws_TE %>% group_by(lang_dom) %>% distinct(baby_id) %>%
  count()

# dominance defined by vocab size
keepers_ws_TE %>% 
  distinct(ID_testdate, .keep_all = TRUE) %>%
  mutate(Eng_Dom = ifelse(LangDom_vocab == "English", 1, 0)) %>%
  summarise(n = n(),
            n_EngDom = sum(Eng_Dom),
            percent_EngDom = n_EngDom/n * 100,
            percent_FrDom = 100 - percent_EngDom)
            
```

## demographics
```{r}
# How many data points including some babies who made multiple visits to the lab (N)
keepers_ws_TE %>% 
  distinct(ID_testdate) %>% 
  count()

N_duplicatedBabyID <- keepers_ws_TE %>%
  filter(duplicated(baby_id))

# how many unique babies
keepers_ws_TE %>%
  distinct(baby_id) %>%
  count()

keepers_ws_TE %>%
  distinct(participant_id) %>%
  count()

# Create dataframe of demographics
d_participants <- keepers_ws_TE %>%
  select(ID_testdate, gender,age_continuous, years_education, lang_exp_eng, lang_exp_fre, lang_exp_other) %>%
  mutate(female = ifelse(gender == "F", 1, 0)) %>%
  pivot_longer(-c(ID_testdate), names_to = "info", values_to = "value") %>%
  group_by(info) %>%
  summarise(n_subject = n_distinct(ID_testdate),
            mean = mean(value, na.rm=T),
            sd = sd(value, na.rm=T),
            min = min(value, na.rm=T),
            max = max(value, na.rm=T))
```

## average # of vocabulary
```{r}
vocabulary_average <- keepers_ws_TE %>%
  select(ID_testdate, word_vocab, TotalNW_Dom, TotalNW_NonDom, concept_vocab,
         number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  pivot_longer(-ID_testdate, names_to = "vocabulary", values_to = "number") %>%
  group_by(vocabulary) %>%
  summarise(mean = mean(number, na.rm = T), 
            sd = sd(number, na.rm = T),
            min = min(number, na.rm = T),
            max = max(number, na.rm = T)) %>%
  mutate_if(is.numeric, round, digits = 2)

## paired-sample t-test to compare D and N
t.test(keepers_ws_TE$TotalNW_Dom, keepers_ws_TE$TotalNW_NonDom, 
       paired = TRUE) 

## paired-sample t-test to compare DI and NI
t.test(keepers_ws_TE$Dom_unique_words, keepers_ws_TE$NonDom_unique_words, 
       paired = TRUE) 
```


## average balance and comparison with balance by input
```{r}
### Average balance by vocab
keepers_ws_TE %>%
  summarise(mean = mean(balance_vocab, na.rm = T),
            sd = sd(balance_vocab, na.rm = T),
            min = min(balance_vocab, na.rm = T),
            max = max(balance_vocab, na.rm = T))
### grouped by language
keepers_ws_TE %>%
  group_by(LangDom_vocab) %>%
  summarise(mean = mean(balance_vocab, na.rm = T),
            sd = sd(balance_vocab, na.rm = T),
            min = min(balance_vocab, na.rm = T),
            max = max(balance_vocab, na.rm = T))

t.test(balance_vocab ~ LangDom_vocab, keepers_ws_TE) # t-test to compare the two language groups

### Comparsion with balance by input (which is defined with reference to the lang_dom defined by vocab size)
keepers_ws_TE %>%
  mutate(consistent_LangDom = if_else(lang_dom != LangDom_vocab, 0, 1)) %>% # 1= consistent, 0 = inconsistent
  summarise(n = n(),
            n_consistent = sum(consistent_LangDom),
            percentage_consistent = n_consistent/n*100,
            n_inconsistent = n - n_consistent,
            percentage_inconsistent = n_inconsistent/n*100)

keepers_ws_TE_withoutInconsistent <- keepers_ws_TE %>%
  mutate(consistent_LangDom = if_else(lang_dom != LangDom_vocab, 0, 1)) %>% # 1= consistent, 0 = inconsistent
  filter(consistent_LangDom == 1)


### Correlation between balance by vocabulary and balance by input
cor.test(keepers_ws_TE$balance_vocab, keepers_ws_TE$balance_input, method = "pearson")

### Correlation between balance by vocabulary and raw language exposure to the non-dominant language
cor.test(keepers_ws_TE$balance_vocab, keepers_ws_TE$LangNonDom_input, method = "pearson")

plot(keepers_ws_TE$balance_vocab, keepers_ws_TE$LangNonDom_input,
     xlab = "Vocabulary balance (= N/W)",
     ylab = "raw exposure to the non-dominant language") +
  lines(lowess(keepers_ws_TE$balance_vocab, keepers_ws_TE$LangNonDom_input), col="blue") # lowess line (x,y)

  abline(lm(keepers_ws_TE$LangNonDom_input~keepers_ws_TE$balance_vocab), col="red") # regression line (y~x)
lines(lowess(wt,mpg), col="blue") # lowess line (x,y)

```



# Correlation
```{r}
Correlation <- keepers_ws_TE %>%
  select(age_continuous, Average_90percentile, balance_vocab, word_vocab, TotalNW_Dom, TotalNW_NonDom,
         number_of_te, Dom_unique_words, NonDom_unique_words, concept_vocab) %>%
  # rename variables
  rename(Age_month = age_continuous,
         V = Average_90percentile,
         B = balance_vocab, 
         W = word_vocab,
         D = TotalNW_Dom, 
         N = TotalNW_NonDom, 
         TE = number_of_te, 
         DI = Dom_unique_words, 
         NI = NonDom_unique_words, 
         C = concept_vocab)

# Correlation with corrections for multiple comparisons
library(psych)
TE_corr <- corr.test(Correlation, use = "pairwise", method = "pearson", adjust = "BY")

write.csv(round(TE_corr$r, 3), file="Output/ObservedTE_correlations_r.csv")  ## coefficients
write.csv(round(TE_corr$p, 3), file="Output/ObservedTE_correlations_p.csv")  ## p-values


library(Hmisc)
mycor <- rcorr(as.matrix(Correlation), type="pearson")
mycor$r
round(mycor$P, 3)
round(p.adjust(mycor$P, "BY"))

library(corrplot)
corrplot(mycor)
write.csv(mycor, "Output/ObservedTE_correlations.csv", col.names=NA)

cor.test(Correlation$TE, Correlation$B, method = "pearson")
cor.test(Correlation$TE, Correlation$W, method = "pearson")
cor.test(Correlation$TE, Correlation$D, method = "pearson")
cor.test(Correlation$TE, Correlation$N, method = "pearson")
cor.test(Correlation$TE, Correlation$V, method = "pearson")
cor.test(Correlation$DI, Correlation$B, method = "pearson")
cor.test(Correlation$NI, Correlation$B, method = "pearson")

```

# Figure 5: Stacked barchart to plot TE, DI, and NI of individual infants (facet by balance)
```{r}
stacked <- keepers_ws_TE %>%
  select(baby_id, balance_vocab, word_vocab, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset balance_vocab by 3 levels 
  #mutate(BalSubset = cut(balance_vocab, breaks = 3, 
  #                       labels=c("MostBalanced", "MediumBalanced", "LeastBalanced"))) %>%
  mutate(BalSubset = case_when(balance_vocab >= 0.35 ~ "MostBalanced",
                               balance_vocab <= 0.20 ~ "LeastBalanced",
                               TRUE ~ "MediumBalanced")) %>%
  arrange(desc(number_of_te)) %>%
  mutate(TE = number_of_te) %>%
  pivot_longer(-c(baby_id, balance_vocab, BalSubset, word_vocab, TE), 
               names_to = "Type", values_to = "NumberOfWords") %>%
  mutate(Type = factor(Type, levels=c("NonDom_unique_words", "Dom_unique_words", "number_of_te"))) %>%
  mutate(Type = recode(Type, 
                       NonDom_unique_words = "Initial non-dominant word", 
                       Dom_unique_words = "Initial dominant word", 
                       number_of_te = "Translation equivalent")) 


LeastBal_plot <- stacked %>%
  filter(BalSubset == "LeastBalanced") %>%
  ggplot(aes(x = reorder(baby_id, -NumberOfWords, sum), y = NumberOfWords)) +
  geom_col(aes(fill = Type)) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_y_continuous(limits = c(0, 1050)) +
  labs(x = "Individual infant", 
       y = "Number of concepts produced",
       title = "Least balanced") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5)) 

MediumBal_plot <- stacked %>%
  filter(BalSubset == "MediumBalanced") %>%
  ggplot(aes(x = reorder(baby_id, -NumberOfWords, sum), y = NumberOfWords)) +
  geom_col(aes(fill = Type)) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_y_continuous(limits = c(0, 1050)) +
  labs(x = "Individual infant", 
       y = "Number of concepts produced",
       title = "Medium balanced") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

MostBal_plot <- stacked %>%
  filter(BalSubset == "MostBalanced") %>%
  ggplot(aes(x = reorder(baby_id, -NumberOfWords, sum), y = NumberOfWords)) +
  geom_col(aes(fill = Type)) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_y_continuous(limits = c(0, 1050)) +
  labs(x = "Individual infant", 
       y = "Number of concepts produced",
       title = "Most balanced") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

Bal_StackedPlot <- ggarrange(LeastBal_plot, 
          MediumBal_plot + rremove("ylab"), 
          MostBal_plot + rremove("ylab"),
          ncol = 3, nrow = 1,
          common.legend = TRUE, legend="bottom")

ggsave("Output/StackedPlot_byBalance.png", Bal_StackedPlot,
       width = 10, height = 5)


## Anova to compare the total vocab size among the 3 balance groups in the stacked barchart
stacked_wide <- keepers_ws_TE %>%
  select(baby_id, balance_vocab, word_vocab, concept_vocab, propTE, number_of_te, Dom_unique_words, NonDom_unique_words) %>%
  # Subset balance_vocab by 3 levels 
  mutate(BalSubset = case_when(balance_vocab >= 0.35 ~ "MostBalanced",
                               balance_vocab <= 0.20 ~ "LeastBalanced",
                               TRUE ~ "MediumBalanced"))


W_byB_anova <- aov(word_vocab ~ BalSubset, data = stacked_wide)
summary(W_byB_anova)

pairwise.t.test(stacked_wide$word_vocab, stacked_wide$BalSubset, p.adj = "BH")

## Mean proportion of TE
stacked_wide %>%
  group_by(BalSubset) %>%
  summarise(mean_propTE = mean(propTE, na.rm=T), 
            sd_propTE = sd(propTE, na.rm=T),
            min_propTE = min(propTE, na.rm=T),
            max_propTE = max(propTE, na.rm=T))

## Correlation between concept vocab and TE across different balance group
stacked_wide_most <- stacked_wide %>%
  filter(BalSubset == "MostBalanced")

cor.test(stacked_wide_most$number_of_te, stacked_wide_most$concept_vocab, method = "pearson")


stacked_wide_med <- stacked_wide %>%
  filter(BalSubset == "MediumBalanced")

cor.test(stacked_wide_med$number_of_te, stacked_wide_med$concept_vocab, method = "pearson")


stacked_wide_least <- stacked_wide %>%
  filter(BalSubset == "LeastBalanced")

cor.test(stacked_wide_least$number_of_te, stacked_wide_least$concept_vocab, method = "pearson")

## Anova to compare the unique dom vocab size and unique non-dom vocab size among the 3 balance groups in the stacked barchart
stacked_wide %>% 
  group_by(BalSubset) %>%
  summarize(mean_DI = mean(Dom_unique_words, na.rm=T), 
            sd_DI = sd(Dom_unique_words, na.rm=T),
            min_DI = min(Dom_unique_words, na.rm=T),
            max_DI = max(Dom_unique_words, na.rm=T))

DI_byB_anova <- aov(Dom_unique_words ~ BalSubset, data = stacked_wide)
summary(DI_byB_anova)

pairwise.t.test(stacked_wide$Dom_unique_words, stacked_wide$BalSubset,
                 p.adjust.method = "BH")


stacked_wide %>% 
  group_by(BalSubset) %>%
  summarize(mean_NI = mean(NonDom_unique_words, na.rm=T), 
            sd_NI = sd(NonDom_unique_words, na.rm=T),
            min_NI = min(NonDom_unique_words, na.rm=T),
            max_NI = max(NonDom_unique_words, na.rm=T))

NI_byB_anova <- aov(NonDom_unique_words ~ BalSubset, data = stacked_wide)
summary(NI_byB_anova)

pairwise.t.test(stacked_wide$NonDom_unique_words, stacked_wide$BalSubset,
                 p.adjust.method = "BH")
```

















# plots
## proportion of TEs
```{r}
keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  ggplot(aes(x = age.days/30, 
             y = propTE)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2))+
  ylab("Percentage of Translation Equivalents") +
  xlab("Age in Months")+
  ggtitle("Percentage of Translation Equivalents by Age") +  
  theme_classic(base_size = 22) +
  scale_x_continuous(breaks= seq(18,32,by = 2))+
  geom_point(size=3) + 
  geom_smooth(method="lm" )

ggsave(here("Output","PlotbyAge.png"), height=10,width=10)
```

## Bar graphs with individual scores (percentage TEs by dominance)
```{r}
keepers_ws_summarize = keepers_ws_TE %>% 
  group_by(balance_group15) %>%
  summarize(mean = mean(propTE, na.rm = T),
         N = n(),
         sd = sd(propTE, na.rm=T),
         se = sd(propTE, na.rm = T)/ sqrt(N)) 


ggplot(data=keepers_ws_summarize,
       aes(x=balance_group15,
           y=mean)) +
    geom_bar(aes(fill = balance_group15),
             show.legend =F,
             colour="black",
             stat="identity",
             position="dodge", width=.7) +
  
   geom_point(data = keepers_ws_TE,aes( y = propTE, fill = balance_group15), alpha = 0.9, show.legend = F, color = "black", pch = 21,size=1.75, 
   stat = "identity",position=position_jitterdodge()) +
  geom_errorbar(aes(ymin = mean - se, 
                    ymax = mean + se), 
                width=0.2,
                position=position_dodge(.9)) +
    ylab("Percentage of Translation Equivalents\n") +
    xlab("Balance") +
scale_x_discrete(breaks= c("80_20", "70_30", "60_40", "50_50"),
                        labels =c("80:20","70:30","60:40","50:50"))+
    ggtitle("Percentage of Translation Equivalents by Balance") +
    theme_classic(base_size = 22) +
  scale_y_continuous(labels = scales::percent_format(accuracy=2))+
    theme(axis.text.x = element_text(angle = 45, hjust = 1), 
          plot.title = element_text(hjust = .5))

ggsave(here("output","PlotTE_byBalance.png"), width=9.5, height= 7)
```
## age by balancedness
```{r}
keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  group_by(balance_group15) %>%
  summarize(median.age = median(age.days))


keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  ggplot(aes(x=balance_group15, y=age.days/30, colour=balance_group15))+
  geom_pirate(bars=F) +ylab("Age (Months)") + coord_flip()

```





## TE: age plot by balancedness
```{r}
keepers_ws_TE %>%
  filter(vocab_type=="Totalvocabulary", bothCDI_filled=="Y") %>%
  ggplot(aes(x = age.days/30, 
             y = propTE)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2))+
  ylab("Percentage of Translation Equivalents\n") +
  xlab("Age in Months")+
  ggtitle("Percentage of Translation Equivalents by Age and Balance") +  guides(colour = guide_legend(reverse=TRUE))+

  theme_classic(base_size = 22) +
 # scale_x_continuous(breaks= seq(18,32,by = 2))+
  geom_point(size=3, colour= "darkgrey") + 
  geom_smooth(size =2, aes(colour=balance_group15), method="lm", se=F)+
  scale_colour_discrete(name="Balance", 
                        breaks= c("80_20", "70_30", "60_40", "50_50"),
                        labels =c("least balanced (80:20)","less balanced (70:30)","more balanced (60:40)","most balanced (50:50)"))
ggsave(here("Output","PlotTE_BalanceByAge.png"), width=13, height= 7)


```







# Statistical tests
## ANOVA for balance
```{r}
res.aov <- aov(propTE ~ balance_group15*cent.age.months, data=keepers_ws_TE) 
summary(res.aov)
```

## Age (old code, not used for poster)
### Running linear model
```{r}
  linear.model<-lmer(propTE ~ cent.age.months+ (1|Baby_ID), data = keepers_ws_TE)
  summary(linear.model)
```
### Running quadratic model
```{r}
 quadratic.model <-lmer(propTE ~ poly(cent.age.months,2) + (1|Baby_ID), data = keepers_ws_TE)
  summary(quadratic.model)
```
### Cubic model
```{r}
cubic.model<-lm(propTE ~ poly(cent.age.months,3), data = keepers_ws_TE)
summary(cubic.model)
```


