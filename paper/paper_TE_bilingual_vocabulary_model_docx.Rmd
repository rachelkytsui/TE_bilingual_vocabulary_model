---
title: "Are translation equivalents special? Evidence from simulations and empirical data from bilingual infants"

shorttitle: "Are translation equivalents special for bilingual infants?"

header-includes:
  - \usepackage{amsmath}
  - \usepackage[labelformat=empty]{caption}
  - \usepackage{caption}
  - \renewcommand{\topfraction}{1}
  - \renewcommand{\bottomfraction}{1}
  - \renewcommand{\textfraction}{.1}
  - \renewcommand{\floatpagefraction}{1}
  - \setcounter{topnumber}{9}
  - \setcounter{bottomnumber}{9}
  - \setcounter{totalnumber}{20}
  - \setcounter{dbltopnumber}{9}
  - \DeclareUnicodeCharacter{2265}{\ensuremath{\ge}}
  - \DeclareUnicodeCharacter{2264}{\ensuremath{\le}}
  
author: 
  - name          : "Rachel Ka-Ying Tsui"
    affiliation   : "1, 2"
    corresponding : yes    
    address       : "Department of Psychology, 7141 Sherbrooke St. West, Montreal, QC, Canada, H2T1V2.  Current address: Laboratory for Language Development, RIKEN Center for Brain Science, 2-1 Hirosawa, Wako-shi, Saitama, Japan, 351-0198"
    email         : "rachelkytsui@gmail.com"
  - name          : "Ana Maria Gonzalez-Barrero"
    affiliation   : "1" 
  - name          : "Esther Schott"
    affiliation   : "1" 
  - name          : "Krista Byers-Heinlein"
    affiliation   : "1" 

affiliation:
  - id            : "1"
    institution   : "Concordia University"

abstract: |
  The acquisition of translation equivalents is often considered a special component of bilingual children’s vocabulary development, as bilinguals have to learn words that share the same meaning across their two languages. This study examined three contrasting accounts for bilingual children’s acquisition of translation equivalents relative to words that are first labels for a referent: the Avoidance Account whereby translation equivalents are harder to learn, the Preference Account whereby translation equivalents are easier to learn, and the Neutral Account whereby translation equivalents are similar to learn. To adjudicate between these accounts, Study 1 explored patterns of translation equivalent learning under a novel computational model — the Bilingual Vocabulary Model — which quantifies translation equivalent knowledge as a function of the probability of learning words in each language. Study 2 tested model-derived predictions against vocabulary data from 200 French–English bilingual children aged 18–33 months. Results showed a close match between the model predictions and bilingual children’s patterns of translation equivalent learning. At smaller vocabulary sizes, data matched the Preference Account, while at larger vocabulary sizes they matched the Neutral Account. Our findings show that patterns of translation equivalent learning emerge predictably from the word learning process, and reveal a qualitative shift in translation equivalent learning as bilingual children develop and learn more words. 
 

keywords          : "bilingualism, infants, translation equivalents, vocabulary development, word learning, computational modeling"

wordcount         : 

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no # "yes" to omit identifying information from the title page

bibliography      : ["paper_TE_bilingual_vocabulary_model_references.bib"]
replace_ampersands: yes

class             : "man"
output            : papaja::apa6_docx # change to apa6_docx for word document
citation_package  : biblatex
nocite: '@*' # include all the references in the .bib file, because in-text citations were mostly typed manually to fit the apa7 style
---

\captionsetup[table]{labelformat=empty}

```{r load_packages_settings, include = FALSE}
library(rmarkdown)
library(knitr)
library(papaja)
library(kableExtra)
library(flextable)
library(english)
library(here)
library(tidyverse)
library(tidylog)
library(wordbankr)
library(ggplot2)
library(patchwork)
library(gridExtra)
library("ggpubr")
library(broom)
library(lsr)
library(Hmisc)
library(lme4)
library(lmerTest)
library(scales)

`%notin%` <- Negate(`%in%`)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE)

```

```{r load_data}
# read in the final cleaned keepers_data
keepers_ws_TE <- read.csv(here::here("data_keepers/keepers_ws_TE_final.csv"))
```

Bilingual children must learn words that take a different form in each of their languages, but share the same or highly similar meanings. For instance, to refer to the same crisp red-skinned fruit, an English–French bilingual child must use the word “apple” when speaking English, and the word _“pomme”_ when speaking French. These cross-language synonyms are known as translation equivalents (also called doublets; Umbel et al., 1992), and are observed amongst bilingual children’s first words (e.g., David & Wei, 2008; De Houwer et al., 2006; Pearson et al., 1995). Translation equivalents are thought to hold a special status in a bilingual’s developing lexicon due to the strong overlap in their semantics. For example, studies with bilingual toddlers show that the associative semantic properties of a word in one language facilitate the activation of its translation equivalent (e.g., Bilson et al., 2015; Floccia et al., 2020; Jardak & Byers-Heinlein, 2019). That is, upon hearing the English word “apple”, the corresponding French word _“pomme”_ is more easily activated in bilinguals’ minds. In vocabulary acquisition, bilingual children must learn a first label for a referent (a “singlet”; Umbel et al., 1992) before they can learn its translation equivalent. Is translation equivalent learning different from singlet learning? The current paper contrasts three competing accounts: 1) translation equivalents are harder to learn than singlets (Avoidance Account), 2) translation equivalents are easier to learn than singlets (Preference Account), and 3) translation equivalents are similar to learn than singlets (Neutral Account). To adjudicate between these accounts, we introduce the Bilingual Vocabulary Model, which provides a computational account of vocabulary learning, with parameters including bilinguals’ vocabulary in each language and their developmental level. In Study 1, we use the Bilingual Vocabulary Model to derive a set of predictions, which we then test against vocabulary data from 200 18- to 33-month-old bilingual children in Study 2.

## Accounts of translation equivalent learning

### Avoidance Account: Translation equivalents are harder to learn than singlets
Early theories of bilingual development claimed that translation equivalents are conspicuously missing from bilingual children’s early vocabularies [e.g., @Imedadze_1967; @Swain_Wesche_1975; @Volterra_Taeschner_1978]. The phenomenon of missing translation equivalents led theorists to propose that young bilingual children do not differentiate their languages, and thus tend to learn only a single word for each referent. This avoidance of translation equivalents was thought to be due to word learning biases such as mutual exclusivity, whereby children assume that a referent is only associated with one word at the basic level [@Markman_Wachtel_1988; @Markman_1992; @Markman_1994]. For example, when monolingual children see a familiar object (e.g., a cup) next to a novel object (e.g., a garlic press) and hear a novel word like “wug”, they assume that “wug” refers to the garlic press — the object unknown to them — rather than to the cup, the object for which they already know the word.

Although mutual exclusivity is helpful for monolingual vocabulary acquisition, its use is more complex for bilingual vocabulary acquisition (Byers-Heinlein & Werker, 2009; Davidson & Tell, 2005; Houston-Price et al., 2010). When encountering a potential singlet, mutual exclusivity would be equally useful for bilinguals as it is for monolinguals, supporting them in associating an unlabeled referent with a novel word. However, a strong form of mutual exclusivity might prevent bilinguals from associating a translation equivalent word with its referent, given that in this case the referent is already associated with another word (albeit in the other language). Thus, mutual exclusivity could prevent bilinguals from acquiring translation equivalents, leading to an abundance of singlets in their vocabularies.

Contrary to earlier studies, more recent work has indicated that bilinguals do understand and produce translation equivalents from early in development (David & Wei, 2008; De Houwer et al., 2006; Holowka et al., 2002; Legacy et al., 2017; Pearson et al., 1995). Indeed, experimental work has suggested bilingual experience in infancy might not support the development of one-to-one mapping biases such as mutual exclusivity, at least in early infancy. For example, when hearing a novel word like “nil”, monolingual children aged 17–22 months looked towards a novel object rather than a familiar object, but bi- and multilingual children looked similarly to both objects (Byers-Heinlein & Werker, 2009; 2013; Houston-Price et al., 2010). A recent meta-analysis also indicated that bilingual children show mutual exclusivity to a weaker degree than monolinguals (Lewis et al., 2020). 

Overall, converging evidence refutes the position that a strong form of mutual exclusivity prevents bilinguals from acquiring translation equivalents. Nonetheless, it leaves open the possibility that translation equivalents may be less likely acquired in favour of learning singlets even if translation equivalents are not completely avoided. If bilingual children avoid lexical overlap across languages even to a small degree, then under the Avoidance Account translation equivalents would be harder to learn than singlets. 

### Preference Account: Translation equivalents are easier to learn than singlets
Contrary to the Avoidance Account, the Preference Account posits that translation equivalents are easier to learn than singlets. At a minimum, word learning requires encoding and representing the relevant sounds of a word, creating a mental representation of its referent, and linking the two. When a French–English bilingual child encounters the word _“pomme”_ after having learned “apple”, one part of that process has already occurred in that the referent is already represented; because part of the word learning task is already accomplished, translation equivalents might therefore be easier to learn than singlets (e.g., Montanari, 2010; Poulin-Dubois et al., 2013; 2018). Moreover, research suggests that bilingual lexicons are not tightly encapsulated by language, but instead include cross-language mental links between words that are semantically related [e.g., @Floccia_etal_2020; @Jardak_Byers-Heinlein_2019; @Singh_2014]. In this context, the strong semantic overlap makes translation equivalents special, and could facilitate their acquisition (e.g., Bilson et al., 2015; Floccia et al., 2020). The Preference Account predicts that translation equivalents are more easily learned than singlets. 

There are several lines of empirical evidence to support the Preference Account. For example, some early case studies reported that bilinguals tended to learn more translation equivalents than singlets when experiencing a shift in their language exposure that inverted their dominant and non-dominant languages [@Lanvers_1999; @Pearson_Fernandez_1994]. The main explanation that has been given for this finding is that additional exposure to their non-dominant language — which became their new dominant language — enabled fast mapping of words to already-lexicalized concepts.

Other evidence suggesting translation equivalents might be easier to learn than singlets comes from a study that included vocabulary-checklist data from 254 monolingual and 181 bilingual children aged 6 months to 7.5 years (Bilson et al., 2015). The researchers used a network analysis approach to investigate how translation equivalents are learned, focusing on the semantic relationships between the words (e.g., words like “cat” and “dog” are strongly semantically related). Using a statistical model that allowed free semantic relations among vocabulary data from monolingual and bilingual children, the results suggested that words were learned faster when they were semantically connected to more known words in children’s lexicons. This effect applied not only to words within the same language, but also to words across languages including translation equivalents (e.g., English “dog” and French _“chien”_) and words that had other cross-language relations (e.g., “cat” and _“chien”_). The authors then simulated bilingual vocabulaires by modeling bilingual lexicons as combinations of two independent vocabulary-size-matched monolinguals. Comparison with actual bilingual children’s vocabulary data revealed that bilingual children acquired more translation equivalents than predicted by the simulation. The authors therefore concluded that bilingual children learn translation equivalents more easily than singlets. Note that, in their study, expected translation equivalent knowledge was simulated based on the number of lexical items that overlapped between two randomly chosen English monolinguals (e.g., whether both monolinguals knew the word “cat”). However, it is unclear whether this is an appropriate point of comparison for bilingual children as this approach may overlook variables that impact bilinguals’ vocabulary learning including vocabulary size in each language and the developmental level of a child — a point that we will return to later in the introduction.

Overall, there is some evidence that bilingual children more readily learn translation equivalents than singlets. If the strong semantic overlap between translation equivalents facilitates their learning, then under the Preference Account translation equivalents will be more easily learned than singlets.

### Neutral Account: Translation equivalents are similar to learn than singlets
The previous accounts rely on the idea that bilingual vocabulary development unfolds differently than monolingual development, as monolinguals encounter only singlets but bilinguals encounter both singlets and translation equivalents. There is an underlying assumption that translation equivalent learning is somehow special relative to singlet learning — the Avoidance Account proposes that translation equivalents are harder to learn than singlets, whereas the Preference Account proposes that translation equivalents are easier to learn than singlets. However, it is also possible that translation equivalents are neither harder nor easier for bilingual children to learn than singlets. We call this the Neutral Account.

The Neutral Account implies that bilingual children’s two languages develop relatively independently. Indeed, language and processing measures for bilingual children tend to be tightly correlated within a particular language, with weakly if at all correlated across languages. For example, 30-month-old bilingual children’s processing efficiency in a particular language closely correlated with vocabulary size in that language, but was unrelated to vocabulary size in their other language (Marchman et al., 2010). Due to differences in the amount of language exposure, bilingual children seldom show equal vocabulary growth in both of their languages (e.g., Pearson & Fernandez, 1994; Pearson et al., 1997), and the amount of exposure to a particular language has been reported to modulate the within-language association between language processing ability and vocabulary size (Hurtado et al., 2014). Bilingual children with greater exposure to a particular language tended to process that language faster, and in turn learned more words in that language. 

In a study whose results support the Neutral Account, Pearson and colleagues (1995) randomly paired the single-language English lexicons from a subset of bilingual children to the single-language Spanish lexicons from another subset of bilingual children to derive a percentage of by-chance lexical overlaps shared between monolingual lexicons of two randomly paired children. The researchers found that the percentage of translation equivalents observed in English–Spanish bilingual children was similar to the by-chance percentage of translation equivalents between randomly-paired children. This evidence implied that singlets and translation equivalents are equally learnable. In sum, the Neutral Account predicts that translation equivalents are similar for bilingual children to learn as singlets.

## Contributors to translation equivalent knowledge
The previous section discussed three theoretical accounts concerning the relative learnability of translation equivalents. However, to date, aspects of translation equivalent learning have mostly been examined in isolation, rather than integrated within the larger context of bilingual lexical development. In this section, we consider two proximal variables that we expect to predict the number of translation equivalents bilingual children know: vocabulary size in each language, and word learnability as a function of children’s developmental level.

### Vocabulary size in bilinguals’ two languages
Because translation equivalents are words from different languages that refer to the same concept, the number of words a bilingual knows in each of their languages will necessarily constrain the number of translation equivalent pairs they could possibly know. For example, a child with a less balanced vocabulary across the two languages might only say 5 words in one language but many more words in the other language; this means that the child could only produce a maximum of 5 translation equivalents, regardless of how many words they know in their other language. Conversely, it seems reasonable to expect that if a child knows a similar number of words in each language and thus has a more balanced vocabulary across the two languages, there would be more potential for some of those words to be translation equivalents.

Balance between the two vocabulary sizes is a function of the number of words bilingual children produce in each language, which tends to be tightly linked to their exposure to each language. In general, more language exposure leads to larger vocabulary size (e.g., Barnes & Garcia, 2013; Boyce et al., 2013; Hurtado et al., 2014; Marchman et al., 2010; Pearson et al., 1997; Place & Hoff, 2011). Bilingual children usually know more words in the language in which they have greater exposure (i.e; dominant language) relative to the language in which they have less exposure (i.e., non-dominant language; Pearson et al., 1997; Place & Hoff, 2011). This is because the more often a bilingual hears a language, the more opportunities there will be for learning new words in that language.

### Word learnability as a function of developmental level
An often overlooked factor that could contribute to bilingual children’s learning of translation equivalents is related to the changes in the learnability of different words over time based on children’s developmental level. Evidence from monolingual children shows that some types of words are characteristically learned before others. For example, across many languages including English, children show a noun bias in their early lexicons (Braginsky et al., 2019; Goodman et al., 2008), although for other languages such as Mandarin it appears that verbs and nouns are more equally acquired [@Tardif_1996]. Certain classes of words are rarely known at the onset of lexical development, such as prepositions and words for time [@Fenson_etal_2007]. This is thought to be due to the cognitive and linguistic machinery that must be in place in order for children to represent these concepts, a necessary prerequisite for learning certain word types (Bergelson, 2020; Braginsky et al., 2019). If this is the case, then children might be more likely to learn translation equivalents than singlets, simply because translation equivalents are more likely to be learnable at their stage of development. That is, potential singlets might be “too hard” to be learned at a particular age. Thus, a seeming overabundance of translation equivalents might be a product of developmental constraints on word learning, rather than due to semantic facilitation.

## The Bilingual Vocabulary Model
Taking into account the contributions of language exposure and developmental level to bilingual children’s vocabulary acquisition, we put forward the Bilingual Vocabulary Model. This model proposes that the number of translation equivalents that bilingual children produce is a function of vocabulary learning in each language, in the context of the number of potentially learnable words given the children’s developmental level. We formalize learning a translation equivalent pair as the joint probability of learning each of the words in the pair. This provides a straight-forward empirical test of different theoretical accounts of translation equivalent learning, by asking whether or not the probability of knowing a word is independent of knowing its translation equivalent. The logic is similar to that of the familiar chi-squared test for independence, where the independence of two events from the same population is tested as the probability of their intersection computed by multiplying the probability of each individual event: P(A and B) = P(A) × P(B | A) where P(B | A) = P(B) if A and B are independent (see Box 1 for a detailed example). The full model is shown in Figure 1. In the next paragraphs, we define each of the model parameters in detail, and these are also summarized in Table 1. 

\newpage
```{r box1, results="asis", tab.cap = NULL}
box1 <- data.frame(title = "To test the independence of two events from the same population, as an example, we might ask whether Psychology majors are more likely to be left-handed. To determine independence, we must know the probability of being a psychology major, the probability of being left handed, and the probability of being both a psychology major and left-handed. The numerator of these probabilities will be the number of students who are left-handed, psychology majors, and both (respectively) and the denominator will be the total population of students we are observing. Imagine a college of 1000 students. If 100/1000 (or 1/10) students are left-handed, and 200/1000 (or 1/5) students are psychology majors, then if these variables are independent we expect a proportion of 1/10 × 1/5 = 1/50 students to be left-handed psychology majors. To determine the number we expect to observe in the college, we multiple 1/50 × 1000 = 20 students. When we compare this expected number to the actual number of left-handed students, there are three possible outcomes. First, we may observe many more than 20 left-handed psychology students at the college (say 100 students), which suggests that being left-handed increases the probability of majoring in psychology. Or, second, we may observe many fewer than 20 left-handed psychology students at the college (say 5 students), this suggests that being left-handed decreases the probability of majoring in psychology (in this example by a factor of 1/4). Finally, if left-handedness and majoring in psychology are independent, we can predict the number of left-handed psychology students by multiplying the observed number of left-handed students (100) by the observed number of psychology students (200), and dividing by the total population of the college (1000), so for example 100×200/1000 = 20. Thus, comparing expected and observed numbers can inform us about the independence of the underlying phenomena.") %>%
  rename("Box 1. Example of test for independence." = title)

#kable(box1,
#      format="latex", booktabs=TRUE, longtable = TRUE) %>%
#  column_spec(1, width = "450px") %>%
#  kable_styling(font_size = 9)

flextable(box1) %>%
  width(width = 6.5)

```

```{r fig1, fig.cap="Illustration of the Bilingual Vocabulary Model.", fig.align='center', out.width='90%'}

knitr::include_graphics("./Figure1_illustration.jpg")
```

The model takes four main parameters: the number of words produced in the dominant language (DOM), the number of words produced in the non-dominant language (NONDOM), vocabulary size of potentially learnable words in each language (LEARNABLE), and a bias parameter (BIAS) which indicates whether the model is biased towards (BIAS > 1) or against (BIAS < 1) learning translation equivalents. The language in which a child knows more words is the dominant language, whereas the one in which a child knows fewer words is the non-dominant language. 
Next, we turn to the LEARNABLE parameter (i.e., the number of potentially learnable words). If DOM and NONDOM are measured with an instrument such as the MacArthur-Bates Communicative Development inventories (CDI; Fenson et al., 2007), one option would be to set LEARNABLE to be the total number of items on the CDI. For convenience, consider the effect of setting LEARNABLE to 600, as a round number (the actual number of CDI items is usually slightly higher than 600, depending on the language of the adaptation). Very young children would not be expected to know many of the “harder” words on the CDI, such as “lawn mower”, “sidewalk”, or “vitamins'', due to children’s immature cognitive machinery and conceptual development. A more reasonable solution might be to determine how many CDI words are potentially learnable given the child’s developmental level, which could be approximated by their age. For example, imagine that Jamie who is 18 months old produces 50 English words and 20 French words, thus a total of 70 words. Monolingual children his age with the very largest productive vocabularies (those at the 90th percentile averaging between English and French norms) produce a total of 245 words (retrieved from the Wordbank database; Frank et al., 2016). Although there is likely considerable individual variability as to the cognitive capacity even amongst children of the same age, we argue that this provides a reasonable — if imperfect — estimate of the number of learnable words (LEARNABLE) that a child of Jamie’s age could potentially acquire in each language. Thus, we might expect that Jamie could potentially have learned up to 245 English words and 245 French words, although he has thus far only learned 50 in English and 20 in French. 

Using the mathematical concept of independence, we can then quantify the number of translation equivalents (TE) expected given children’s vocabulary sizes in the dominant (DOM) and non-dominant (NONDOM) languages, as well as the number of potentially learnable words (LEARNABLE). If dominant-language and non-dominant-language words are learned independently from each other, we multiply DOM × NONDOM (the number of words known in the dominant and non-dominant language respectively), and divide by the total population of learnable words in one language (LEARNABLE) — which is the possible number of words that could overlap across both languages — to predict the number of translation equivalents. 
We further introduce the bias parameter (BIAS), which allows us to examine whether translation equivalent learning is best described by the Avoidance, Preference, or Neutral account. Adding this parameter, translation equivalents can be derived from TE = BIAS × (DOM × NONDOM)/LEARNABLE. For the Avoidance Account, BIAS will be less than 1, meaning that TEs are less easily learned than singlets; for the Preference Account, BIAS will be greater than 1, meaning that translation equivalents are more easily learned than singlets; for the the Neutral Account, BIAS is exactly 1 (i.e., the model is unbiased with respect to whether translation equivalents are more difficult or easier to acquire than singlets). Going back to the example of 18-month-old Jamie, we would set the denominator at 245 which is the number of potentially learnable words at 18 months. If translation equivalents are half as easy to learn as singlets (following the Avoidance Account), we would expect Jamie to produce .5×(50×20/245) = 2.0 translation equivalents. Conversely, if translation equivalents are twice as easy to learn as singlets (following the Preference Account), we would expect Jamie to produce 2×(50×20/245) = 8.2 translation equivalents. Under the Neutral Account, we would expect Jamie to learn 1×(50×20/245) = 4.1 translation equivalents. 

Finally, based on the main parameters, we can calculate additional, commonly-reported descriptors of bilingual vocabulary, which we detail below and describe as derived parameters. 

Balance of vocabulary (BALANCE) is the proportion of total words that children produce in each language. For convenience, balance is defined in reference to the non-dominant language with the formula NONDOM/(DOM+NONDOM), such that scores can range from 0.0 (completely unbalanced) to 0.5 (completely balanced). For example, since 18-month-old Jamie produces 50 dominant vocabulary words and 20 non-dominant vocabulary words, he would have a balance score of 0.29. Note that this calculation does not take into account overlap in meaning across the two languages (i.e., how many of the words he produces are translation equivalents).

Word vocabulary (WORD; sometimes called total productive vocabulary) is the total number of words that a child produces across the two languages, calculated as the sum of the dominant vocabulary (DOM) and non-dominant vocabulary (NONDOM). 
Concept vocabulary (CONCEPT; sometimes called total conceptual vocabulary) is the number of concepts that are lexicalized by the child — that is, the total number of concepts that are lexicalized in either language. This can be calculated by subtracting the number of translation equivalents (TE) from the word vocabulary (WORD). Finally, we can also calculate singlets that are produced in each language, that is words for which the child does not yet produce a translation equivalent. Singlets in the dominant language (DOM-SINGLET) can be calculated by subtracting translation equivalents (TE) from dominant-language vocabulary (DOM); singlets in the non-dominant language (NONDOM-SINGLET) can be calculated by subtracting translation equivalents (TE) from non-dominant language vocabulary (NONDOM). It is also possible to decompose children’s word vocabulary (WORD) into the sum of TE, DOM-SINGLET, and NONDOM-SINGLET.

```{r table1, results = "asis"}

table1 <- data.frame(
  Variable = c("LEARNABLE", "DOM", "NONDOM", "BIAS", "BALANCE", "WORD", "TE", "CONCEPT", "DOM-SINGLET", "NONDOM-SINGLET"),
  Definition = c("Number of learnable words in each language, given the child’s developmental level",
                 "Words produced in the dominant language",
                 "Words produced in the non-dominant language",
                 "Bias parameter",
                 "Balance (relative proportion of words produced in the non-dominant language to the total words produced in both languages)",
                 "Word vocabulary (or total vocabulary size)",
                 "Translation equivalents produced",
                 "Concept vocabulary (or total conceptual vocabulary size)",
                 "Singlets in dominant language",
                 "Singlets in non-dominant language"),
  Constraints = c("Varies by age. No greater than the number of words on CDI.",
                  "DOM \u2265 NONDOM (children always produce more words in dominant than non-dominant language); DOM \u2264 LEARNABLE",
                  "NONDOM \u2264 DOM (children always produce fewer words in non-dominant than dominant language); NONDOM \u2264 LEARNABLE",
                  "BIAS < 1 implies the Avoidance Account; BIAS > 1 implies the Preference Account; BIAS = 1 implies the Neutral Account",
                  "0 \u2264 BALANCE \u2264 .50 (greater values indicate children producing a more similar number of words in their two languages)",
                  "W \u2264 2×LEARNABLE (maximum word vocabulary is knowing each word in both languages)",
                  "", "", "", ""),
  "Relationship to other parameters" = c("Maximum number that could be learned in DOM or NONDOM",
                                         "DOM = (1-BALANCE)×WORD; DOM = WORD - NONDOM",
                                         "NONDOM = BALANCE×WORD; NONDOM = WORD - DOM",
                                         "",
                                         "BALANCE = NONDOM/WORD; BALANCE = NONDOM/(DOM+NONDOM)",
                                         "WORD = DOM+NONDOM; WORD = DOM/(1-BALANCE); WORD = NONDOM/(BALANCE)",
                                         "TE = BIAS × DOM×NONDOM/LEARNABLE",
                                         "CONCEPT = WORD - TE; CONCEPT = TE + DOM-SINGLET + NONDOM-SINGLET",
                                         "DOM-SINGLET = DOM - TE",
                                         "NONDOM_SINGLET = NONCOM - TE")
) 

#landscape(
#  kable(table1,
#        format = "latex", booktabs = TRUE,
#        caption = "Table 1. Summary of the parameters in the Bilingual Vocabulary Model.") %>%
#    kableExtra::kable_styling(font_size = 7) %>%
#    pack_rows("Main Parameters", 1, 4) %>%
#    pack_rows("Derived Parameters", 5, 10) %>%
#    column_spec(2:4, width = "175px") %>%
#    footnote(general = "All vocabulary measures are constrained to be integers.")
#)

flextable(table1) %>%
  fontsize(part = "all", size = 8) %>% 
  set_header_labels(Relationship.to.other.parameters = "Relationship to other parameters") %>%
  set_caption("Table 1. Summary of the parameters in the Bilingual Vocabulary Model.") %>%
  width(width = 2)
  
```

## Current research
The current research aimed to better understand the nature of translation equivalent learning in bilingual children. Study 1 simulated the expected patterns of translation equivalent learning under the Bilingual Vocabulary Model proposed in the introduction, with reference to the proportion of words learned in the dominant and non-dominant language and the number of words that are learnable at various developmental levels. We also compared predicted learning outcomes for when translation equivalents are harder to learn, or easier to learn, or similar to learn than singlets. 

In Study 2, we examined real-world translation equivalent development in light of the predictions from the Bilingual Vocabulary Model, using archival data from 200 French–English bilingual children aged 18 to 33 months, whose vocabularies and translation equivalent knowledge were measured by parent report using the MacArthur-Bates CDI: Words and Sentences form in English [@Fenson_etal_2007] and Québec French (Trudeau et al., 1999). Together, the Bilingual Vocabulary Model and real-world data allowed us to examine contrasting hypotheses about translation equivalents: whether translation equivalents learning is harder (Avoidance Account), whether translation equivalent learning is easier (Preference Account), or similar to learn than singlets (Neutral Account).

# Study 1: Simulations
Study 1 provides a computational implementation of the Bilingual Vocabulary Model outlined in the introduction (see also Figure 1), which we use to simulate different scenarios to examine the effect of vocabulary sizes and developmental variables on translation equivalent learning. Note that usually only three values are necessary to calculate all the other variables (see Table 1). Most commonly, we can calculate other variables based on the total number of learnable words (LEARNABLE) together with either the words known in each language (DOM and NONDOM) or word vocabulary plus balance (WORD and BALANCE) which allow us to compute DOM and NONDOM. It is also possible to calculate other variables based on the total number of learnable words (LEARNABLE) with balance and words known in either language (BALANCE and DOM or BALANCE and NONDOM).

Three simulations were generated to explore expected patterns of translation equivalent learning under the Bilingual Vocabulary Model. In the first simulation, we examined how translation equivalent learning relates to vocabulary balance (BALANCE), as well as different metrics of vocabulary size, including dominant-language vocabulary (DOM), non-dominant language vocabulary (NON-DOM), and word vocabulary (WORD). In the second simulation, we explored relationships between translation equivalents (TE), balance (BALANCE), and learnable words (LEARNABLE). In the first two simulations, the BIAS parameter was held constant at 1 (Neutral Account); in the third simulation, we varied the bias parameter (BIAS) to compare translation equivalent learning under the Avoidance, Preference, and Neutral Accounts. A summary of the parameter values used in each simulation is provided in Table 2.

```{r table2, results = "asis"}

table2 <- data.frame(
  Simulation = c("1", "2", "3"),
  LEARNABLE = c("Constant at 600", "Varied at 300, 450, and 600", "Varied at 150, 300, 450, and 600"),
  DOM = c("Varied, ranging from 100 to LEARNABLE at an interval of 100", 
          "Varied, ranging from 100 to LEARNABLE at an interval of 100",
          "Varied, ranging from 100 to LEARNABLE at an interval of 100 "),
  NONDOM = c("Varied, ranging from 0 to DOM at an interval of 10",
             "Varied, ranging from 0 to DOM at an interval of 25",
             "Varied, ranging from 0 to DOM at an interval of 25"),
  WORD = c("Calculated as WORD = DOM + NONDOM",
           "Calculated as WORD = DOM + NONDOM",
           "Calculated as WORD = DOM + NONDOM"),
  BALANCE = c("Calculated as BALANCE = NONDOM / (DOM+NONDOM)",
              "Calculated as BALANCE = NONDOM / (DOM+NONDOM)",
              "Calculated as BALANCE = NONDOM / (DOM+NONDOM)"),
  BIAS = c("Constant at 1", "Constant at 1", 
           "Varied at 0.5 (Avoidance Account), 1 (Neutral Account), and 1.5 (Preference Account)"),
  n_data = c(216, 161, 166)
) 

landscape(
  kable(table2,
        col.names = c("Simulation",
                      "Learnable words (LEARNABLE)",
                      "Words in dominant Language (DOM)",
                      "Words in non-dominant language (NONDOM)",
                      "Word vocabulary (WORD)",
                      "Balance of vocabulary (BALANCE)",
                      "Bias parameter (BIAS)",
                      "Total number of data points generated"),
        align = "clllllll",
        format="latex", booktabs = TRUE,
        caption = "Table 2. Summary of the parameters used in each simulation.") %>%
    column_spec(1:2, width = "45px") %>%
    column_spec(3:7, width = "75px") %>%
    column_spec(8, width = "45px") %>%
    kable_styling(font_size = 8)
)
  
```

## 1.1 Simulation 1: Children of the same developmental level with different word vocabularies and balances of vocabulary
In Simulation 1, we first illustrate the relationships between different variables in the model by simulating three hypothetical children who are at the same developmental level and thus have the same number of potentially learnable words (LEARNABLE), but with different word vocabularies (WORD) and BALANCE. For convenience, we set LEARNABLE = 600 in this example, which roughly corresponds to what is expected for an English-learning 26 month-old (i.e., the most verbal 26-month-old English-learner at the 90th percentile of vocabulary produces around 600 words as retrieved from the Wordbank database; Frank et al., 2016). We set BIAS to 1, meaning that in these examples translation equivalents are similarly easy to learn as singlets.

We first illustrate with three hypothetical children. Infant Annie (small vocabulary, unbalanced exposure) produces 270 words in the dominant language and 30 words in her non-dominant language. She has a word vocabulary of 300, and a balance score of .10 (10% of her words are in the non-dominant language). Based on the formula TE = DOM×NONDOM/LEARNABLE (we drop BIAS from the formula since it is 1 here) and as seen in Table 3, Annie is expected to produce 13.5 translation equivalents. Infant Bernie (small vocabulary, balanced exposure) produces 180 dominant-language words, and 120 non-dominant language words. Like Annie, he has a word vocabulary of 300, but he has a higher balance score of .40 (40% of his words are in the non-dominant language). Based on our formula, we expect Bernie to produce 36 translation equivalents. Comparing Annie and Bernie, two children who produce the same word vocabulary (i.e., WORD is held constant), the child with more balanced language vocabulary (Bernie) is expected to produce more translation equivalents. Like Bernie, infant Charlie also has a balanced vocabulary, but has a larger word vocabulary (WORD), producing 540 words in the dominant language (DOM) and 360 in the non-dominant language (NONDOM) for a total of 900 words (WORD), and thus BALANCE = .40. Based on our formula for Simulation 1, we expect Charlie to produce 324 translation equivalents (TE). Infants Bernie and Charlie illustrate that for two children equal in BALANCE, the child with larger word vocabulary (WORD) is expected to produce more translation equivalents (TE). Other vocabulary metrics are calculated for each hypothetical child as described in Table 3.

```{r table3, results="asis"}

# create columns that contain information to be added to table3 in the next step
## Definition column: the definition of each variable in the table
Definition <- c("Bias parameter", "Learnable words in each language", "Words produced in the dominant language", "Words produced in the non-dominant language",
                "Word vocabulary (or total vocabulary size)", "Vocabulary balance", "Translation equivalents produced", 
                "Concept vocabulary (or total conceptual vocabulary size)", "Singlets in dominant language", "Singlets in non-dominant language")
## Calculation column: the formula used to calculate the derived parameters
Calculation <- c("", "", "", "", 
                 "DOM + NONDOM", "NONDOM / (DOM + NONDOM)", "DOM × NONDOM / LEARNABLE", "WORD - TE", "DOM - TE", "NONDOM - TE")

table3 <- data.frame(
    # define the main parameters
    hypotheical_child = c("Infant Anne (small vocabulary, unbalanced)",
                        "Infant Bernie (small vocabulary, balanced)",
                        "Infant Charlie (large vocabulary, balanced)"),
    BIAS = 1, 
    LEARNABLE = 600, 
    DOM = c(270, 180, 540),
    NONDOM = c(30, 120, 360)
  ) %>%
  # calculate the derived parameters from the main parameters
  mutate(WORD = DOM + NONDOM,
         BALANCE = NONDOM/(DOM+NONDOM),
         TE = DOM*NONDOM/LEARNABLE,
         CONCEPT = WORD - TE,
         "DOM-SINGLET" = DOM - TE, 
         "NONDOM-SINGLET" = NONDOM - TE) %>%
  # transpose the data set for presentation
  pivot_longer(-("hypotheical_child"), names_to = "Variable", values_to = "value") %>%
  pivot_wider(names_from = "hypotheical_child", values_from = "value") %>%
  # append other information for presentation
  mutate(Definition = Definition, 
         Calculation = Calculation) %>%
  # reorder columns
  relocate(c(Definition, Calculation), .before = "Infant Anne (small vocabulary, unbalanced)")
  
landscape(
  kable(table3,
      align = "llllll",
      format="latex", booktabs = TRUE,
      caption = "Table 3. Examples for Simulation 1 of three hypothetical children with different hypothetical word vocabularies (WORD) and vocabulary balance (BALANCE), where the number of learnable words (LEARNABLE) = 600 and BIAS = 1.") %>%
  pack_rows("Main Parameters", 1, 4) %>%
  pack_rows("Derived Parameters", 5, 10) %>%
  column_spec(c(1), width = "100px") %>%
  column_spec(c(2:3), width = "140px") %>%
  column_spec(c(4:6), width = "60px") %>%
  kable_styling(font_size = 8) 
)
```

We then broadened this simulation to the more general case and examined patterns of translation equivalent learning, where simulated children had the capacity to learn 600 words (LEARNABLE held constant at 600), and their vocabulary size in each language (DOM and NONDOM) varied. BIAS was once again constant at 1. Data from a total of 216 simulated children were generated (see Table 2 for a summary of the parameter values used in this simulation). Based on these values, we derived simulated children’s word vocabulary (WORD, calculated as DOM+NONDOM) and their vocabulary balance (BALANCE, calculated as NONDOM/(DOM+NONDOM)). In Figure 2, we plotted TE knowledge as a function of DOM, NONDOM, and WORD at different levels of BALANCE. Across all three Panels (1A, 1B, and 1C), simulated children with the most balanced vocabulary consistently produced more translation equivalents than other children. Moreover, Panels 1A and 1C show that, as the number of DOM (dominant language words) and WORD (word vocabulary) increased, TE also increased regardless of BALANCE. Interestingly, Panel 1B shows that NONDOM and TE were extremely tightly coupled. In sum, we observed three important patterns, which served as Prediction Set 1 from the Bilingual Vocabulary Model for Study 2: 

* Prediction 1a: Children with more balanced vocabularies (BALANCE) will produce more translation equivalents (TE). 
* Prediction 1b: Children who produce more total words (WORD) or more dominant-language words (DOM) will produce more translation equivalents (TE).
* Prediction 1c: Children who produce more non-dominant language words (NONDOM) will produce more translation equivalents (TE); but unlike for WORD and DOM this does not interact with BALANCE; instead, non-dominant vocabulary size will be an almost perfect predictor of translation equivalent knowledge (see panel 1B of Figure 2).

```{r simulation1, echo = FALSE}
# Simulation 1: simulating infants of the same developmental level with different word vocabularies and balances of exposure (LEARNABLE = 600)

## generate the simulation data
simulation1 <- function (LEARNABLE) {
  DOM_seq <- seq(100, LEARNABLE, by = 100) # sequence of D from 100 to V at an interval of 100
  NONDOM_seq <- seq(0, LEARNABLE, by = 10) # sequence of N from 0 to V at an interval of 10
  DOM <- rep (DOM_seq, length(NONDOM_seq))
  NONDOM <- rep(NONDOM_seq, length(DOM_seq))
  data_simulation1 <<- data.frame(LEARNABLE, DOM, NONDOM)
}

simulation1(600) # setting V = 600

## clean the simulation data
data_simulation1 <- data_simulation1 %>%
  arrange(DOM, NONDOM) %>%
  filter(NONDOM <= DOM) %>%
  # Get word vocabulary W
  mutate(WORD = DOM + NONDOM) %>%
  # Create other variables
  mutate(BALANCE = NONDOM/(DOM+NONDOM), 
         TE = (DOM*NONDOM)/LEARNABLE) %>% # If DOM and NONDOM are independent, TE = DOM*NONDOM/LEARNABLE
  # Round to keep whole numbers only
  mutate_at(vars(-BALANCE), round, 0) %>%
  # bin B into 5 groups
  mutate(bin_BALANCE = cut(BALANCE, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5), include.lowest=T,
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  arrange(DOM, NONDOM, bin_BALANCE)

## visualizing Simulation 1
simulation1 <- data_simulation1 %>%
  # convert to long data
  pivot_longer(c(WORD, DOM, NONDOM), names_to = "vocab_type", values_to = "number") %>%
  mutate(vocab_type = factor(vocab_type, levels=c("DOM", "NONDOM", "WORD"))) %>%
  mutate(vocab_type = recode(vocab_type, 
                             DOM = "Panel 1A: \n Dominant vocabulary \n (DOM)", 
                             NONDOM = "Panel 1B: \n Non-dominant vocabulary \n (NONDOM)",
                             WORD = "Panel 1C: \n Total vocabulary \n (WORD)")) %>%
  ggplot(aes(x = number, y = TE, color = bin_BALANCE, linetype = bin_BALANCE)) +
  stat_smooth(method = lm, se = F) +
  scale_color_manual(values=c("#bdbdbd", "#737373", "#525252", "#252525", "#000000")) + 
  scale_linetype_manual(values=c("longdash", "dotdash", "dashed", "twodash", "solid")) +
  theme_minimal() + 
  facet_grid(. ~ vocab_type) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom",
        plot.title = element_text(face = 'bold', size = 12, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=12),
        panel.spacing.x = unit(2, "lines"),
        panel.background = element_rect(fill = NA, color = "black")) +
  ylim(0, 600) +
  xlim(0, 1000) +
  labs(x = "Number of words", 
       y = "Number of translation equivalents (TE)", 
       color = "Vocabulary balance (BALANCE)",
       linetype = "Vocabulary balance (BALANCE)",
       title = "1) Simulated data") +
  guides(color = guide_legend(reverse = T, nrow = 1),
         linetype = guide_legend(reverse = T, nrow = 1)) 
```

```{r simulation1-plus_observed_data, echo = FALSE}
Observed_plot_inputs_TE <- keepers_ws_TE %>% 
  select(baby_id, ID_testdate, age_days, number_of_te, word_vocab, total_words_dom, total_words_nondom, balance_vocab) %>%
  pivot_longer(c(word_vocab, total_words_dom, total_words_nondom), names_to = "vocab_type", values_to = "number") %>%
  mutate(vocab_type = factor(vocab_type, levels=c("total_words_dom", "total_words_nondom", "word_vocab"))) %>%
  mutate(vocab_type = recode(vocab_type, 
                             total_words_dom = "Panel 2A: \n Dominant vocabulary \n (DOM)", 
                             total_words_nondom = "Panel 2B:\n Non-dominant vocabulary \n (NONDOM)",
                             word_vocab = "Panel 2C: \n Total vocabulary \n (WORD)")) %>%
  mutate(bin_BALANCE = cut(balance_vocab, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5), include.lowest=T,
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  ggplot(aes(x = number, y = number_of_te, color = bin_BALANCE, linetype = bin_BALANCE)) +
  #geom_point() +
  stat_smooth(method = lm, se = F) +
  scale_color_manual(values=c("#bdbdbd", "#737373", "#525252", "#252525", "#000000")) + 
  scale_linetype_manual(values=c("longdash", "dotdash", "dashed", "twodash", "solid")) + 
  theme_minimal() + 
  facet_grid(. ~ vocab_type) +
  theme(axis.text.x = element_text(angle = 90),
        plot.title = element_text(face = 'bold', size = 12, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=12),
        legend.position = "bottom",
        panel.spacing.x = unit(2, "lines"),
        panel.background = element_rect(fill = NA, color = "black")) +
  ylim(0, 600) +
  xlim(0, 1000) +
  labs(x = "Number of words", 
       y = "Number of translation equivalents (TE)", 
       color = "Vocabulary balance (BALANCE)",
       linetype = "Vocabulary balance (BALANCE)",
       title = "2) Observed data") +
  guides(colour = guide_legend(reverse = T, nrow = 1),
         linetype = guide_legend(reverse = T, nrow = 1))

# combine Simulation1 visualization + observed data visualization
plot_Simulation1plusData <- ggarrange(simulation1, 
                                      Observed_plot_inputs_TE,
                                      nrow = 2,
                                      common.legend = TRUE, legend = "bottom")
```

```{r fig2, fig.cap="Number of translation equivalents (TE) across different levels of vocabulary balance (BALANCE) in relation to dominant vocabulary size (DOM; Panel A), non-dominant vocabulary size (NONDOM; Panel B), and word vocabulary (WORD; Panel C). Row 1 represents the simulated data in Study 1 while holding the number of learnable words (LEARNABLE) constant at 600 and BIAS constant at 1. Row 2 represents the observed vocabulary data in Study 2.", echo=FALSE, dpi=600, fig.align='center', fig.height=7, out.height="80%", out.width="110%", fig.pos = "H"}

plot_Simulation1plusData
```


## 1.2 Simulation 2: Acquisition of translation equivalents and singlets at different developmental levels
In our previous simulation, we assumed that each simulated child was at the same developmental level and had the capacity to learn up to 600 words in each language (i.e., LEARNABLE held constant at 600). As laid out in the introduction, under the Bilingual Vocabulary Model, the learnability of different words changes with a child’s developmental level, where LEARNABLE increases as a child grows older. Therefore, in Simulation 2, we looked at the expected patterns of translation equivalent learning across varying levels of LEARNABLE (i.e., the number of learnable words in each language as developmental level changes). Additionally, we further examined vocabulary composition by computing the number of singlets in the dominant (DOM-SINGLET) and non-dominant (NONDOM-SINGLET) language. BIAS was once again kept constant at 1.

Translation equivalent knowledge was simulated across children at three developmental levels (the number of LEARNABLE words = 300, 450, 600), in conjunction with a wide range of values for words in the dominant language (DOM) and the non-dominant language (NONDOM). In total, data from 161 simulated children were generated (see Table 2 for a summary of the parameters used in this simulation). Again, balance (BALANCE) was calculated based on the values of DOM and NONDOM. We also calculated the number of singlet words in the dominant (DOM-SINGLET) and non-dominant (NONDOM-SINGLET) languages, so that simulated children’s concept vocabulary (CONCEPT) could be decomposed as the sum of TE (translation equivalents), DOM-SINGLET, and NONDOM-SINGLET. Figure 3 plots this decomposition for simulated children of different developmental levels, with vocabulary ranging from most balanced (BALANCE = .35 - .50), to medium balanced (BALANCE = .20 - .35), to least balanced (BALANCE = .00 - .02).

```{r simulation2, echo = FALSE}
# Simulation 2: simulating patterns of translation equivalent learning as a function of different developmental timepoints (LEARNABLE = 300, 450, or 600)

## generate the simulation data
LEARNABLE <- seq(300, 600, by = 150) # set LEARNABLE to 300, 450, and 600

simulation2 <- function (LEARNABLE) {
  DOM_seq <- seq(100, LEARNABLE, by = 100) # sequence of D from 100 to V at an interval of 100
  NONDOM_seq <- seq(0, LEARNABLE, by = 25) # sequence of N from 0 to V at an interval of 25
  DOM <- rep(DOM_seq, length(NONDOM_seq))
  NONDOM <- rep(NONDOM_seq, length(DOM_seq))
  data_simulation2 <<- data.frame(LEARNABLE, DOM, NONDOM)
}

data_simulation2 <- do.call(rbind, lapply(LEARNABLE, simulation2)) %>%
  arrange(LEARNABLE, DOM, NONDOM) %>%
  filter(NONDOM <= DOM) %>%
  # Create other variables
  mutate(WORD = DOM + NONDOM, # word vocabulary 
         BALANCE = NONDOM/(DOM+NONDOM), # balance,
         TE = (DOM*NONDOM)/LEARNABLE, # If D and N are independent, TE = DN/V
         DOM_SINGLET = DOM-TE, # Unique words in dominant language
         NONDOM_SINGLET = NONDOM-TE) %>% # Unique words in non-dominant language
  # Round to keep whole numbers only
  mutate_at(vars(-BALANCE), round, 0) %>%
  # bin B into 3 groups
  mutate(bin_BALANCE = case_when(BALANCE >= 0.36 ~ "Most Balanced",
                                 BALANCE <= 0.20 ~ "Least Balanced",
                                 TRUE ~ "Medium Balanced")) %>%
  mutate(bin_BALANCE  = fct_rev(bin_BALANCE)) %>%
  arrange(DOM, NONDOM, bin_BALANCE)

## visualizing Simulation 2
simulation2 <- data_simulation2 %>%
  pivot_longer(-c(LEARNABLE, WORD, BALANCE, bin_BALANCE), names_to = "vocab_type", values_to = "number") %>%
  filter(vocab_type %notin% c("DOM", "NONDOM")) %>%
  mutate(vocab_type = factor(vocab_type, levels=c("NONDOM_SINGLET", "DOM_SINGLET", "TE"))) %>%
  mutate(LEARNABLE_label = case_when(LEARNABLE == 600 ~ "LEARNABLE = 600",
                                     LEARNABLE == 450 ~ "LEARNABLE = 450",
                                     LEARNABLE == 300 ~ "LEARNABLE = 300")) %>%
  group_by(LEARNABLE, LEARNABLE_label, bin_BALANCE, vocab_type) %>%
  summarise(n_words = mean(number)) %>%
  ggplot(aes(x = bin_BALANCE, y = n_words, fill = vocab_type)) + 
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ LEARNABLE_label) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) +
  scale_x_discrete(labels = function(bin_BALANCE) str_wrap(bin_BALANCE, width = 10)) + 
  ylim(0, 600) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(face = 'bold', size = 12, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=10),
        panel.spacing.x = unit(2, "lines")) + 
  labs(x = "\nVocabulary balance (BALANCE)", 
       y = "Number of concepts (CONCEPT)", 
       title = "Panel A: Simulated data")
```

```{r simulation2-plus_observed_data, echo = FALSE}
plot_stacked_byLEARNABLE <- keepers_ws_TE %>%
  select(baby_id, age_months_percentile, balance_vocab, word_vocab, number_of_te, total_singlet_dom, total_singlet_nondom) %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(LEARNABLE_subset = case_when(age_months_percentile <= 22 ~ "18-22 months \n (LEARNABLE = 244.9 - 451.9)",
                                      age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months \n (LEARNABLE = 491.8 - 604.1)",
                                      TRUE ~ "28-33 months \n (LEARNABLE = 620.4 - 638.9)")) %>%
  mutate(BalSubset = case_when(balance_vocab > 0.35 ~ "Most Balanced",
                               balance_vocab <= 0.20 ~ "Least Balanced",
                               TRUE ~ "Medium Balanced")) %>%
  mutate(BalSubset = fct_rev(BalSubset)) %>%
  arrange(desc(number_of_te)) %>%
  mutate(TE = number_of_te) %>%
  pivot_longer(-c(baby_id, age_months_percentile, balance_vocab, LEARNABLE_subset, BalSubset, word_vocab, TE), 
               names_to = "Type", values_to = "NumberOfWords") %>%
  mutate(Type = factor(Type, levels=c("total_singlet_nondom", "total_singlet_dom", "number_of_te"))) %>%
  mutate(Type = recode(Type, 
                       total_singlet_nondom = "Singlet in non-dominant language (NONDOM-SINGLET)", 
                       total_singlet_dom = "Singlet in dominant language (DOM-SINGLET)", 
                       number_of_te = "Translation equivalent (TE)")) %>%
  group_by(LEARNABLE_subset, BalSubset, Type) %>%
  summarise(n_words = mean(NumberOfWords)) %>%
  ggplot(aes(x = BalSubset, y = n_words, fill = Type)) +
  geom_bar(position="stack", stat="identity") +
  facet_grid(. ~ LEARNABLE_subset) +
  scale_fill_manual(values = c("#1f78b4", "#a6cee3", "#33a02c")) + 
  scale_x_discrete(labels = function(BalSubset) str_wrap(BalSubset, width = 10)) + 
  ylim(0, 600) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0) , 
        legend.position = "bottom",
        plot.title = element_text(face = 'bold', size = 12, hjust = 0, vjust = 2),
        plot.title.position = "plot",
        text = element_text(size=10),
        panel.spacing.x = unit(2, "lines")) + 
  guides(fill=guide_legend(nrow=3,byrow=TRUE)) + 
  labs(x = "\nVocabulary balance (BALANCE)", 
       y = "Number of concepts (CONCEPT)",
       title = "Panel B: Observed data") 

# combine Simulation2 visualization + observed data visualization
plot_Simulation2plusData <- ggarrange(simulation2 + rremove("legend"), 
                                      plot_stacked_byLEARNABLE,
                                      nrow = 2,
                                      heights=c(0.8,1))
```

```{r fig3, fig.cap="Number of translation equivalents (TE) and singlets in dominant (DOM-SINGLET) and non-dominant language (NONDOM-SINGLET) across different developmental levels/ages, which sets the number of LEARNABLE words. Panel A represents the model simulation in Study 1, where developmental levels of simulated children are set at three values: LEARNABLE = 300, 450, and 600. Panel B represents the observed vocabulary data in Study 2, where developmental level was divided into 3 subsets with children of 18-22 months (left), children of 23-27 months (middle), and children of 28-33 months (right). Proportion of balance (BALANCE) was divided into three groups, where the least balanced group had a range of .00 - .20 vocabulary balance, the medium balanced group had a range of .20 - .35, and the most balanced group had a range of .35 - .50.", echo=FALSE, dpi=600, fig.align='center', fig.height=7, out.width="80%", fig.pos = "H"}

plot_Simulation2plusData
```

In general, simulated children at a later developmental level had larger concept vocabularies (CONCEPT). Moreover, we continued to observe a pattern reported in prediction 1a, whereby simulated children with more balanced vocabularies produced more translation equivalents (TE). Moreover, regardless of balance, simulated children at later developmental levels (i.e., older children with more potentially LEARNABLE words) acquired more translation equivalents (TE). Overall, we generated 3 additional predictions (Prediction Set 2) made by the Bilingual Vocabulary Model. Compared to children at an earlier developmental level (i.e., younger infants with fewer potentially learnable words), children at a later developmental level (i.e., older infants with more potentially learnable words) will

* Prediction 2a: Have larger concept vocabularies (CONCEPT). 
* Prediction 2b: Produce more translation equivalents (TE), regardless of vocabulary balance (BALANCE).
* Prediction 2c: Produce more dominant-language singlet words (DOM-SINGLET). Moreover, those with the least _balanced_ vocabulary (BALANCE) will produce the most DOM-SINGLET.
* Prediction 2d: Produce more non-dominant-language singlets (NONDOM-SINGLET). Moreover, those with the most _balanced_ vocabulary (BALANCE) will produce the most NONDOM-SINGLET. 

## 1.3 Simulation 3: Bias towards or against translation equivalent learning compared to singlets
In Simulations 1 and 2, we modeled cases in accordance to the Neutral Account where dominant-language and non-dominant language words were learned independently, such that the bias parameter (BIAS) was exactly 1 when we calculated TE as DOM×NONDOM/LEARNABLE. In our final simulation, we examined cases where dominant-language and non-dominant language words were not independent, corresponding to the Avoidance Account and the Preference Account. Mathematically, this requires varying the BIAS parameter. For the Preference Account, BIAS will be greater than 1, meaning that TEs are more easily learned than singlets. On the other hand, for the Avoidance Account, BIAS will be less than 1, meaning that TEs are less easily learned than singlets. 

Translation equivalent (TE) knowledge was first simulated across different developmental levels (as indicated by number of LEARNABLE words = 150, 300, 450, 600), in conjunction with a wide range of values for DOM and NONDOM. Again, BALANCE and word vocabulary (WORD) were calculated based on the values of DOM and NONDOM. The final simulated data set contained 166 data points (see Table 2 for a summary of the parameters used). Three scenarios of translation equivalent learning (TE) were then generated using the formula TE = BIAS × DOM×NONDOM/LEARNABLE. To illustrate the Avoidance Account, BIAS was set at .5 (i.e., TEs are 50% less likely to be learned than singlets). To illustrate the Neutral Account, BIAS was set at 1 (i.e., TEs are equal to learn as singlets). Finally, to illustrate the Preference Account, BIAS was set at 1.5 (i.e., TE are 50% more likely to be learned than singlets). In Figure 4, we illustrate the three different scenarios of simulated translation equivalent (TE) knowledge. Again, we continue to observe a pattern consistent with prediction 1a where, in all cases, simulated children with more balanced vocabularies (BALANCE) produced more translation equivalents (TE). Thus, overall relationships between BALANCE and TE remained similar across the Avoidance, Preference, and Neutral Accounts. What changed was the slope of translation equivalent learning: the slopes were the shallowest under the Avoidance Account where BIAS = 0.5, whereas the slopes were steepest under the Preference Account where BIAS = 1.5. With this, we further outline Prediction Set 3: 

* Prediction 3: Whether translation equivalents are harder to learn, easier to learn, or similar to learn than singlets will change the slope of translation equivalent learning as a function of word vocabulary (WORD), with a shallower slope if TEs are less easily learned (i.e., Avoidance Account), and a steeper slope if TEs are more easily learned (i.e., Preference Account) compared to where translation equivalents are similar to learn as singlets (i.e., Neutral Account). 

```{r simulation3, echo = FALSE}
# Simulation 3: Non-independence of dominant-language (DOM) and non-dominant language words (NONDOM)

## generate the simulation data
LEARNABLE <- seq(150, 600, by = 150) # set LEARNABLE to 300, 450, and 600

simulation3 <- function (LEARNABLE) {
  DOM_seq = seq(100, LEARNABLE, by = 100) # sequence of DOM from 100 to LEARNABLE at an interval of 100
  NONDOM_seq = seq(0, LEARNABLE, by = 25) # sequence of NONDOM from 0 to LEARNABLE at an interval of 25
  DOM <- rep(DOM_seq, length(NONDOM_seq))
  NONDOM <- rep(NONDOM_seq, length(DOM_seq))
  data_simulation3 <<- data.frame(LEARNABLE, DOM, NONDOM)
}

data_simulation3 <- do.call(rbind, lapply(LEARNABLE, simulation3)) %>%
  arrange(LEARNABLE, DOM, NONDOM) %>%
  filter(NONDOM <= DOM) %>% # eliminate cases when NONDOM > DOM
  mutate(WORD = DOM+NONDOM, # word vocabulary
         BALANCE = NONDOM/(DOM+NONDOM), # balance 
         TE = DOM*NONDOM/LEARNABLE) %>% # If DOM and NONDOM are independent, TE = DOM*NONDOM/LEARNABLE
  mutate_at(vars(-BALANCE), round, 0) %>%
  mutate(bin_BALANCE = cut(BALANCE, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5), include.lowest=T,
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5"))) %>%
  arrange(bin_BALANCE)


## Simulation3: TE = BIAS * (DOM*NONDOM/LEARNABLE)
### defining the bias parameter I
BIAS1 = 1.5 # BIAS > 1, TEs are MORE easily learned than unique words
BIAS2 = 0.5 # BIAS < 1, TEs are LESS easily learned than unique words

### visualizing the simulation
plot_simulation3 <- data_simulation3 %>%
  mutate(TE_easier = BIAS1*(DOM*NONDOM/LEARNABLE), # calculate where BIAS > 1
         TE_harder = BIAS2*(DOM*NONDOM/LEARNABLE)) %>% # calculate where BIAS < 1
  # round to keep whole numbers only
  mutate_at(vars(-c(BALANCE, bin_BALANCE)), round, 0) %>%
  # prepare dataset to plot
  pivot_longer(c(TE, TE_harder, TE_easier), 
               names_to = "Model", values_to = "number_TE") %>%
  mutate(Model = factor(Model, levels=c("TE_harder", "TE", "TE_easier"))) %>%
  mutate(Model = recode(Model, 
                        TE = "BIAS = 1 \n (Neutral Account)",
                        TE_easier = "BIAS = 1.5 \n (Preference Account)",
                        TE_harder = "BIAS = 0.5 \n (Avoidance Account)")) %>%
  # ggplot
  ggplot(aes(x = WORD, y = number_TE, color = bin_BALANCE, linetype = bin_BALANCE)) +
  stat_smooth(method = lm, se = F) +
  scale_color_manual(values=c("#bdbdbd", "#737373", "#525252", "#252525", "#000000")) + 
  scale_linetype_manual(values=c("longdash", "dotdash", "dashed", "twodash", "solid")) + 
  theme_minimal() + 
  facet_grid(. ~ Model) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom") +
  theme(plot.title = element_text(hjust = 0.5),
        text = element_text(size=11),
        panel.spacing.x = unit(2.5, "lines"),
        panel.background = element_rect(fill = NA, color = "black")) +
  labs(x = "Word vocabulary (WORD)", 
       y = "Number of translation equivalents (TE)", 
       color = "Vocabulary balance (BALANCE)",
       linetype = "Vocabulary balance (BALANCE)") +
  guides(colour = guide_legend(reverse = T, nrow = 1),
         linetype = guide_legend(reverse = T, nrow = 1))
```

```{r fig4, fig.cap="Different scenarios of expected translation equivalents learning (TE) as a function of WORD vocabulary, under scenarios where TEs are harder to learn (BIAS < 1), easier to learn (BIAS > 1), or similar to learn (BIAS = 1) as singlets.", echo=FALSE, dpi=600, fig.align='center', fig.height=3.5, out.height="80%", out.width="100%", fig.pos = "H"}

plot_simulation3
```


# Study 2: Empirical data
In Study 1, we used a simulation based on the Bilingual Vocabulary Model to generate several predictions about the relationship between translation equivalent knowledge and other vocabulary variables. In Study 2, we tested these predictions using archival vocabulary data from 200 French–English bilingual children aged 18 to 33 months. 

## 2.1 Method
Ethics approval was obtained by the Human Research Ethics Board of Concordia University (Certification Number 10000439) and informed consent was obtained from the children’s parents. 

## 2.1.1 Participants
```{r participants, include = FALSE}
# how many distinct participants and data point we have
keepers_ws_TE %>% 
  summarise(N_babies = n_distinct(baby_id),
            N_admin = n_distinct(ID_testdate))

# how many girls and boys we have
d_gender <- keepers_ws_TE %>%
  group_by(gender) %>% 
  distinct(baby_id, .keep.all=T) 
  # %>% count() 

# number of participants who contributed multiple data points
d_multiple <- keepers_ws_TE %>% 
  count(baby_id) %>% 
  filter(n>1)

# checking which baby_id has multiple data
n_duplicatedBabyID <- keepers_ws_TE %>%
  filter(duplicated(baby_id)) %>%
  arrange(baby_id)

## percentage of english-dominant & french-dominant children
# dominance defined by vocab size
d_lang_dom <- keepers_ws_TE %>% 
  distinct(ID_testdate, .keep_all = TRUE) %>%
  mutate(Eng_Dom = ifelse(lang_dom_vocab == "English", 1, 0)) %>%
  summarise(n = n(),
            n_EngDom = sum(Eng_Dom),
            percent_EngDom = n_EngDom/n * 100,
            percent_FrDom = 100 - percent_EngDom)
```

Archival data from `r length(unique(keepers_ws_TE$baby_id))` bilingual children acquiring English and French (age range: `r round(min(keepers_ws_TE$age_continuous),2)` - `r round(max(keepers_ws_TE$age_continuous),2)` months; `r length(d_gender$gender[d_gender$gender == "F"])` girls and `r length(d_gender$gender[d_gender$gender == "M"])` boys) who participated in prior studies at the XYZ lab were included in the present study, drawn from the same set of participants as Gonzalez-Barrero et al. (2020). Some children took part in more than one in-lab study (n = `r length(d_multiple$baby_id)`); thus, they contributed data at more than one time point. This resulted in a larger number of datapoints relative to the number of unique participants. The total number of data points included in the analyses was `r length(keepers_ws_TE$ID_testdate)` (i.e., `r length(keepers_ws_TE$eng_cdi_filled[keepers_ws_TE$eng_cdi_filled == "Y"])` English and `r length(keepers_ws_TE$fre_cdi_filled[keepers_ws_TE$fre_cdi_filled == "Y"])` French CDI questionnaires). Participants were recruited through government birth lists, online ads, daycares, and infant-parent group activities (e.g., children’s library activities). Inclusion criteria were the following: full term-pregnancy ( i.e., > 36 weeks of gestation), normal birth weight (> 2500 grams), and absence of major medical conditions (i.e., meningitis). Only children who had complete data in both CDI forms (i.e., English and French) were retained for analysis. Bilingual children were defined as those exposed at least 25% of the time over the course of their lives globally to both English and French and with less than 10% of exposure to a third language. For children who participated more than once, their language exposure followed such criteria for all visits. Following the approach in Study 1, children’s dominant language was deemed to be the language in which the child produced a greater number of words; vocabulary balance was then determined based on the proportion of words produced in the non-dominant language relative to the total words produced across both languages using the same formula as in Study 1: NONDOM/(DOM+NONDOM). Within the `r length(keepers_ws_TE$ID_testdate)` data points, `r round(d_lang_dom$percent_EngDom, 2)`% of children were English-dominant and `r round(d_lang_dom$percent_FrDom, 2)`% were French-dominant. Data collection was conducted in Montréal, Québec, Canada. Montréal is a multicultural city where both English and French are widely used in society. Children’s demographic characteristics including age, maternal education, and language exposure, are presented in Table 4.

&nbsp;
```{r table4, results="asis"}
# Create dataframe of demographics
d_participants <- keepers_ws_TE %>%
  # keep only relevant variables
  select(ID_testdate, age_continuous, years_education, lang_exp_eng, lang_exp_fre, lang_exp_other) %>%
  # rename variables
  rename("Age in months" = age_continuous,
         "Maternal education in years" = years_education,
         "% Global exposure to English"  = lang_exp_eng,
         "% Global exposure to French"  = lang_exp_fre, 
         "% Global exposure to Other" = lang_exp_other) %>%
  # summarize the data
  pivot_longer(-c(ID_testdate), names_to = "info", values_to = "value") %>%
  group_by(info) %>%
  summarise(mean = mean(value, na.rm=T),
            sd = sd(value, na.rm=T),
            min = min(value, na.rm=T),
            max = max(value, na.rm=T)) %>%
  mutate(across(where(is.numeric),round, 1)) %>%
  # combine min and max to form range
  unite("range", min:max, sep = " - ", remove = TRUE, na.rm = FALSE) %>%
  # arrange rows in custom order
  mutate(info = factor(info, levels = c("Age in months", "Maternal education in years", 
                                        "% Global exposure to English", "% Global exposure to French",
                                        "% Global exposure to Other"))) %>%
  arrange(info)

# generate the apa table
papaja::apa_table(d_participants, format.args = list(digits = 1),
                  caption = "Table 4. Demographic characteristics of participants (data points = 229).",
                  col.names =c("","Mean","$SD$","Range"),
                  align=c("l","c","c","c"),
                  placement = "h")
```

## 2.1.2 Measures

```{r cdi_filled_by, include = FALSE}
# who filled out the CDIs
d_cdi_filled_by <- keepers_ws_TE %>% 
  # combine grandmother & other family member
  mutate(cdi_filled_by = replace(cdi_filled_by, cdi_filled_by == "Grandmother", "Other family member")) %>% 
  # count number of respondents
  count(cdi_filled_by) %>%
  mutate(percentage = n/sum(n)*100)  # calculate percentages
```

### MacArthur-Bates Communicative Development Inventories: Words and Sentences (CDI)
Bilingual children’s expressive vocabulary was measured by the Words and Sentences form of the MacArthur-Bates CDI. Caregivers completed the original CDI English version [@Fenson_etal_2007] and its Québec French adaptation (Trudeau et al., 1999). We asked the caregiver more familiar with each language to complete the respective CDI form, and the forms are mainly filled out by mothers (`r round(d_cdi_filled_by$percentage[2],0)`%), fathers (`r round(d_cdi_filled_by$percentage[1],0)`%), both parents (`r round(d_cdi_filled_by$percentage[3],0)`%), others (< `r round(d_cdi_filled_by$percentage[4],0)`%; e.g., grandmother), and respondent not indicated (`r round(d_cdi_filled_by$percentage[5],0)`%). In some cases different caregivers filled out each form, while in other cases the same caregiver filled out both forms. Our analyses focused on the vocabulary checklist of this questionnaire, which includes different nouns, verbs, adjectives, and other words used by young children. There are 680 words in the English CDI version and 664 in the Québec French version. 

Translation equivalents (TE) were determined in the same manner as Gonzalez-Barrero et al. (2020) by three proficient bilingual French–English adults who carefully examined each language version of the CDI. Word pairs that made reference to the same concept (e.g., English “apple” and French _“pomme”_) were considered to be translation equivalents. In cases of disagreement, a discussion of the likely uses of the word in question by children (rather than potential adult uses of the word) was conducted and then a decision was made. Words that had similar phonetic realizations (e.g., English “alligator” and French _“alligator”_) were also considered translation equivalents. Most of the items on both vocabulary checklists had an equivalent word in the other language, which resulted in a total of 611 translation equivalents. A full list of translation equivalents is available at [https://osf.io/2t5kw/]. 

After determining the dominant language of a child based on the vocabulary size, we then computed the number of singlets that children knew in their dominant (DOM-SINGLET) and non-dominant (NONDOM-SINGLET) languages by deducting the number of translation equivalents produced from the total number of words produced in each language (i.e., DOM - TE and NONDOM - TE as in Study 1). Concept vocabulary (CONCEPT) was computed based on the number of concepts for which a child produced a word, calculated by subtracting the number of translation equivalents from word vocabulary (i.e., WORD - TE as in Study 1).

### Language Exposure Questionnaire using the MAPLE approach
Children’s language exposure was measured using the Language Exposure Questionnaire (LEQ; Bosch & Sebastián-Gallés, 2001) and the Multilingual Approach to Parent Language Estimates (MAPLE; Byers-Heinlein et al., 2020). The LEQ is a structured interview that lasts approximately 15 minutes. It includes targeted questions that quantify the child’s language exposure from birth until their current age. The LEQ and MAPLE provide a global language exposure estimate based on the number of hours the child is exposed to each language within all contexts (e.g., home, daycare, etc.). Children’s average global exposure to each language is described in Table 4. 

## 2.1.3 Procedure
Caregivers were asked to fill out the CDI questionnaires as part of their child’s participation in experimental studies on language development, speech perception, and word learning. Caregivers were instructed to check off the words produced by their child using either a CDI paper questionnaire or the same questionnaire administered on a tablet. Data from paper based questionnaires was double entered and checked by trained research assistants. 

## 2.2 Results
Data analyses were conducted using R (Version 4.0.2, 2020). Analysis scripts and the data set used in the present study are available at [https://osf.io/2t5kw/]. We first present descriptive measures of vocabulary, and then tests of the three sets of predictions generated in Study 1. 

## 2.2.1 Descriptive measures of vocabulary

```{r vocabulary_descriptives, include = FALSE}
# average vocabulary scores
vocabulary_average <- keepers_ws_TE %>%
  select(ID_testdate, word_vocab, total_words_dom, total_words_nondom, concept_vocab,
         number_of_te, total_singlet_dom, total_singlet_nondom) %>%
  pivot_longer(-ID_testdate, names_to = "vocabulary", values_to = "number") %>%
  group_by(vocabulary) %>%
  summarise(mean = mean(number, na.rm = T), 
            sd = sd(number, na.rm = T),
            min = min(number, na.rm = T),
            max = max(number, na.rm = T)) %>%
  mutate(across(where(is.numeric), round, 1))

## paired-sample t-test to compare DOM and NONDOM
t_test_DOM_NONDOM <- tidy(t.test(keepers_ws_TE$total_words_dom, keepers_ws_TE$total_words_nondom, paired = TRUE))

d_DOM_NONDOM <- cohensD(keepers_ws_TE$total_words_dom, keepers_ws_TE$total_words_nondom, method = "paired") # cohen's d effect size

## paired-sample t-test to compare DOM-SINGLET and NONDOM-SINGLET
t_test_SINGLET <- tidy(t.test(keepers_ws_TE$total_singlet_dom, keepers_ws_TE$total_singlet_nondom, paired = TRUE)) 

d_SINGLET <- cohensD(keepers_ws_TE$total_singlet_dom, keepers_ws_TE$total_singlet_nondom, method = "paired")  # cohen's d effect size
```

On average, bilinguals in the sample had a mean word vocabulary size (WORD) of `r vocabulary_average$mean[7]` (SD = `r vocabulary_average$sd[7]`), with a wide range of `r vocabulary_average$min[7]` - `r vocabulary_average$max[7]` words. As expected by the way language dominance was defined, children produced more words in their dominant language (DOM; M = `r vocabulary_average$mean[5]`, SD = `r vocabulary_average$sd[5]`, range = `r vocabulary_average$min[5]` - `r vocabulary_average$max[5]`) than in their non-dominant language (NONDOM; M = `r vocabulary_average$mean[6]`, SD = `r vocabulary_average$sd[6]`, range = `r vocabulary_average$min[6]` - `r vocabulary_average$max[6]`), _t_(`r t_test_DOM_NONDOM$parameter[1]`) = `r t_test_DOM_NONDOM$statistic[1]`, $p `r papaja::printp(t_test_DOM_NONDOM$p.value[1])`$, $d = `r round(d_DOM_NONDOM, 2)`$.

Children produced an average of `r vocabulary_average$mean[2]` translation equivalents (TE; SD = `r vocabulary_average$sd[2]`, range = `r vocabulary_average$min[2]` - `r vocabulary_average$max[2]`). The remainder of words were singlets: Children produced many more singlets in their dominant language (DOM-SINGLET; M = `r vocabulary_average$mean[3]`, SD = `r vocabulary_average$sd[3]`, range = `r vocabulary_average$min[3]` - `r vocabulary_average$max[3]`) than in their non-dominant language (NONDOM-SINGLET; M = `r vocabulary_average$mean[4]`, SD = `r vocabulary_average$sd[4]`, range = `r vocabulary_average$min[4]` - `r vocabulary_average$max[4]`), _t_(`r t_test_SINGLET$parameter[1]`) = `r t_test_SINGLET$statistic[1]`, $p `r papaja::printp(t_test_SINGLET$p.value[1])`$, $d = `r round(d_SINGLET, 2)`$. On average, children’s concept vocabulary size was `r vocabulary_average$mean[1]` (CONCEPT; SD = `r vocabulary_average$sd[1]`, range = `r vocabulary_average$min[1]` - `r vocabulary_average$max[1]`).

```{r balance_descriptives, include = FALSE}
# Average BALANCE score (defined by vocabulary balance)
balance_average <- keepers_ws_TE %>%
  summarise(mean = mean(balance_vocab, na.rm = T),
            sd = sd(balance_vocab, na.rm = T),
            min = min(balance_vocab, na.rm = T),
            max = max(balance_vocab, na.rm = T))

# Average BALANCE score grouped by language-dominance
balance_average_group <- keepers_ws_TE %>%
  group_by(lang_dom_vocab) %>%
  summarise(mean = mean(balance_vocab, na.rm = T),
            sd = sd(balance_vocab, na.rm = T),
            min = min(balance_vocab, na.rm = T),
            max = max(balance_vocab, na.rm = T))

## paired-sample t-test to compare balance score between English-dominant vs. French-dominant children 
t_test_balance <- tidy(t.test(balance_vocab ~ lang_dom_vocab, keepers_ws_TE))

d_balance <- cohensD(balance_vocab ~ lang_dom_vocab, data = keepers_ws_TE, method = "pooled") # cohen's d effect size

# vocabulary balance vs. input balance

## check to see how many children have consistent/inconsistent dominant language between vocabulary-defined and input-defined dominance
dominance_consistency <- keepers_ws_TE %>%
  mutate(consistent_lang_dom = if_else(lang_dom != lang_dom_vocab, 0, 1)) %>% # 1= consistent, 0 = inconsistent
  summarise(n = n(),
            n_consistent = sum(consistent_lang_dom),
            percentage_consistent = n_consistent/n*100,
            n_inconsistent = n - n_consistent,
            percentage_inconsistent = n_inconsistent/n*100)

## correlation between vocabulary balance and input balance (raw language exposure to the non-dominant language)
correlation_balance <- tidy(cor.test(keepers_ws_TE$balance_vocab, keepers_ws_TE$lang_nondom_input, method = "pearson"))


```

Vocabulary balance (BALANCE) was then determined based on the proportion of total words produced in the non-dominant language following the formula BALANCE = NONDOM/WORD as in Study 1. On average, bilingual children in our sample had a balance score BALANCE of `r balance_average$mean[1]` (SD = `r balance_average$sd[1]`), ranging from `r balance_average$min[1]` to `r balance_average$max[1]`. Similar vocabulary balance was found between the children who were English-dominant and those who were French-dominant, _t_(`r round(t_test_balance$parameter[1],2)`) = `r round(t_test_balance$statistic[1],2)`, $p = `r papaja::printp(t_test_balance$p.value[1])`$, $d = `r round(d_balance, 2)`$. The `r round(d_lang_dom$percent_EngDom, 1)`% of children who were English-dominant had an average BALANCE of `r round(balance_average_group$mean[1], 2)` (SD = `r round(balance_average_group$sd[1], 2)`, range = `r round(balance_average_group$min[1], 2)` - `r round(balance_average_group$max[1], 2)`) whereas the remaining `r round(d_lang_dom$percent_FrDom, 2)`% who were French-dominant had an average BALANCE of `r round(balance_average_group$mean[2], 2)` (SD = `r round(balance_average_group$sd[2], 2)`, range = `r round(balance_average_group$min[2], 2)` - `r round(balance_average_group$max[2], 2)`). 

Note that in this paper, we defined BALANCE in terms of relative vocabulary in each language, but for young bilinguals balance can also be considered in terms of input in each language. We therefore compare the vocabulary balance with the proportion of exposure bilingual children received in their non-dominant language. To make values comparable, the language designated as DOM and NONDOM was based on vocabulary-defined dominance, rather than the language that children heard most and least often. For most children, the language in which they produced the most words was also the language that they heard most often (`r dominance_consistency$n_consistent` children, `r round(dominance_consistency$percentage_consistent,2)`%), although this was not the case for some children (`r dominance_consistency$n_inconsistent` children, `r round(dominance_consistency$percentage_inconsistent,2)`%). The correlation between vocabulary-defined BALANCE and the raw percentage of exposure to the non-dominant language was moderate, _r_(`r correlation_balance$parameter[1]`) = `r round(correlation_balance$estimate[1], 2)`, $p `r papaja::printp(correlation_balance$p.value[1])`$ (see also Figure 5). Thus, these two constructs were related, although not identical.

&nbsp;
```{r fig5, fig.cap="Correlation between balance defined by vocabulary (BALANCE) and balance defined by exposure.", echo=FALSE, dpi=600, fig.align='center', out.width="75%", fig.pos = "H"}

# plotting the correlation between balance by vocabulary and balance by input (raw language exposure to the non-dominant language)
keepers_ws_TE %>%
  ggplot(aes(x = balance_vocab, y = lang_nondom_input)) +
  stat_smooth(method = lm, se = F, color = "black") +
  geom_point(shape = 1) + 
  theme_light() + 
  labs(x = "Balance based on vocabulary (BALANCE)", 
       y = "Balance based on exposure") +
  theme(text = element_text(size=16))

```

## 2.2.2 Testing Prediction Set 1: Univariate relationships between translation equivalents and different vocabulary measures
Prediction Set 1 pertained to the pairwise relationships between word vocabulary (WORD), dominant (DOM) and non-dominant vocabulary (NONDOM), vocabulary balance (BALANCE), and translation equivalents (TE), which we examined through Pearson’s correlations. Overall, the univariate statistics showed strong correspondence with the relationships predicted by Prediction 1 under the Bilingual Vocabulary Model (see Table 5 for a full table of pairwise correlations). 

```{r testing_prediction1, include = FALSE}

# correlation between TE and BALANCE
cor_TE_balance <- tidy(cor.test(keepers_ws_TE$number_of_te, keepers_ws_TE$balance_vocab, method = "pearson"))

# one-way ANOVA to compare TE among the 5 BALANCE groups 

keepers_ws_TE <- keepers_ws_TE %>% # divide children into 5 balance subset groups (0 < BALANCE ≤ 0.1, 0.2, 0.3, 0.4, and 0.5)
  mutate(bin_BALANCE = cut(balance_vocab, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5), include.lowest=T,
                     labels = c("0.1", "0.2", "0.3", "0.4", "0.5")))

aov_TE_binBALANCE <- tidy(keepers_ws_TE %>% # one-way ANOVA
                            aov(number_of_te ~ bin_BALANCE, data = .))


# correlation between TE and WORD
cor_TE_word <- tidy(cor.test(keepers_ws_TE$number_of_te, keepers_ws_TE$word_vocab, method = "pearson"))

# correlation between TE and DOM
cor_TE_dom <- tidy(cor.test(keepers_ws_TE$number_of_te, keepers_ws_TE$total_words_dom, method = "pearson"))

# correlation between TE and NONDOM
cor_TE_nondom <- tidy(cor.test(keepers_ws_TE$number_of_te, keepers_ws_TE$total_words_nondom, method = "pearson"))
```

Prediction 1a was that children with more balanced vocabularies would produce more translation equivalents. As shown in Figure 2 Row 2, our vocabulary data confirmed the prediction, _r_(`r cor_TE_balance$parameter[1]`) = `r round(cor_TE_balance$estimate[1],2)`, $p `r papaja::printp(cor_TE_balance$p.value[1])`$, where children with the most balanced vocabulary produced the most translation equivalents. We further tested this prediction by dividing children into 5 balance subset groups (0 < BALANCE ≤ 0.1, 0.2, 0.3, 0.4, and 0.5), and a one-way ANOVA revealed a significant effect of BALANCE, _F_(`r aov_TE_binBALANCE$df[1]`, `r aov_TE_binBALANCE$df[2]`) = `r aov_TE_binBALANCE$statistic[1]`, $p = `r papaja::printp(aov_TE_binBALANCE$p.value[1])`$. The children with a BALANCE score of 0.5 (i.e., with more balanced vocabulary) produced the most translation equivalents, whereas children with a BALANCE score of 0.1 (i.e., with less balanced vocabulary) produced the least translation equivalents. Detailed descriptive statistics are reported in Table 6.

Prediction 1b was that children with larger word vocabularies and larger dominant-language vocabularies would produce more translation equivalents, and the results from our dataset confirmed this prediction, for word vocabulary (WORD): _r_(`r cor_TE_word$parameter[1]`) = `r round(cor_TE_word$estimate[1],2)`, $p `r papaja::printp(cor_TE_word$p.value[1])`$, and dominant-language vocabulary (DOM): _r_(`r cor_TE_dom$parameter[1]`) = `r round(cor_TE_dom$estimate[1],2)`, $p `r papaja::printp(cor_TE_dom$p.value[1])`$. Figure 2 Row 2 further illustrates these relationships observed in our dataset.

Prediction 1c was that children who produce more words in the non-dominant language (NONDOM) would produce more translation equivalents (TE), specifically that this relationship would be nearly perfect. As shown in Figure 2 Row 2, we observed that these two variables were indeed nearly perfectly correlated, _r_(`r cor_TE_nondom$parameter[1]`) = `r round(cor_TE_nondom$estimate[1],2)`, $p `r papaja::printp(cor_TE_nondom$p.value[1])`$.

```{r table5, results = "asis"}
# correlation among variables in the observed data

## keep only relevant variables for the correlation analysis
correlation_data <- keepers_ws_TE %>%
  select(age_continuous, Average_90percentile, balance_vocab, word_vocab, total_words_dom, total_words_nondom,
         number_of_te, total_singlet_dom, total_singlet_nondom, concept_vocab) %>%
  # rename variables
  rename("Age (in month)" = age_continuous,
         LEARNABLE = Average_90percentile,
         BALANCE = balance_vocab, 
         WORD = word_vocab,
         DOM = total_words_dom, 
         NONDOM = total_words_nondom, 
         TE = number_of_te, 
         "DOM-SINGLET" = total_singlet_dom, 
         "NONDOM-SINGLET" = total_singlet_nondom, 
         CONCEPT = concept_vocab)

## correlation analysis
### corstars function to add significant * to the correlation matrix
corstars <-function(x, method=c("pearson", "spearman"), removeTriangle=c("upper", "lower")){ # x = data
    #Compute correlation matrix
    require(Hmisc)
    x <- as.matrix(x)
    correlation_matrix<-rcorr(x, type=method[1])
    R <- correlation_matrix$r # Matrix of correlation coeficients
    p <- correlation_matrix$P # Matrix of p-value 
    
    ## Define notions for significance levels; spacing is important.
    mystars <- ifelse(p < .001, "***", ifelse(p < .01, "**", ifelse(p < .05, "*", " ")))
    
    ## trunctuate the correlation matrix to two decimal
    R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
    
    ## build a new matrix that includes the correlations with their apropriate stars
    Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
    diag(Rnew) <- paste(diag(R), " ", sep="")
    rownames(Rnew) <- colnames(x)
    colnames(Rnew) <- paste(colnames(x), "", sep="")
    
    ## remove upper triangle of correlation matrix
    if(removeTriangle[1]=="upper"){
      Rnew <- as.matrix(Rnew)
      Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove lower triangle of correlation matrix
    else if(removeTriangle[1]=="lower"){
      Rnew <- as.matrix(Rnew)
      Rnew[lower.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove last column and return the correlation matrix
    Rnew <- cbind(Rnew[2:length(Rnew)])
    return(Rnew)
} 

correlation_table <- corstars(correlation_data, "pearson", "lower") # generate correlation matrix with our data using corstars function

# print table
papaja::apa_table(correlation_table,
                  caption = "Table 5. Pairwise correlations among variables (corrected for multiple comparisons using Benjamini and Yekutieli [2001]).",
                  note = "*** p < .001, ** p < .01, * p < .05.",
                  align="l",
                  landscape = TRUE,
                  font_size = "scriptsize")
```

```{r table6, results="asis"}

# TE descriptive statistics of the 5 balance group
mean_TE_binBALANCE <- keepers_ws_TE %>% 
  group_by(bin_BALANCE) %>%
  summarise(n = n(),
            mean_TE = mean(number_of_te, na.rm = T),
            sd_TE = sd(number_of_te, na.rm = T),
            min_TE = min(number_of_te, na.rm = T),
            max_TE = max(number_of_te, na.rm = T)) %>%
  mutate(across(!bin_BALANCE & !sd_TE, ~ round(.,0))) %>%
  mutate_at(vars(sd_TE), ~ round(.,2)) %>%
  # combine min and max to form range
  unite("range", min_TE:max_TE, sep = " - ", remove = TRUE, na.rm = FALSE) %>%
  # sort bin_BALANCE with descending order
  arrange(desc(bin_BALANCE)) %>%
  # rename each level of bin_BALANCE
  mutate(bin_BALANCE = recode(bin_BALANCE,
                              "0.5" = "0.4 < BALANCE \u2264 0.5",
                              "0.4" = "0.3 < BALANCE \u2264 0.4",
                              "0.3" = "0.2 < BALANCE \u2264 0.3",
                              "0.2" = "0.1 < BALANCE \u2264 0.2",
                              "0.1" = "0 < BALANCE \u2264 0.1")) %>%
  # rename column
  rename(" " = bin_BALANCE, "N" = n, "Mean" = mean_TE, "SD" = sd_TE)

# print table
papaja::apa_table(mean_TE_binBALANCE,
                  caption = "Average number of translation equivalents (TE) produced by each balance group.",
                  col.names =c("","N","Mean","$SD$","range"),
                  align="c")

#kable(mean_TE_binBALANCE,
#      format="latex", booktabs=TRUE, align = "c",
#      caption = "Table 6. Average number of translation equivalents (TE) produced by each balance group.") %>%
#  column_spec(1, width = "150px") %>%
#  column_spec(2:4, width = "50px") %>%
#  column_spec(5, width = "75px") %>%
#  kable_styling(position = "center")
```

## 2.2.3 Testing Prediction Set 2: The vocabulary composition of bilingual children at different developmental levels
Prediction Set 2 pertained to expected patterns of acquisition of translation equivalents and singlets for children of different developmental levels. In our data set, developmental level was approximated by children’s age. Figure 3 Panel B shows the concept vocabulary (CONCEPT) of the bilingual children as a function of different ages (a proxy for developmental level), used to estimate the number of LEARNABLE words. To illustrate the acquisition of translation equivalents and singlets at different developmental levels, we divided children into three age groups: younger children of 18–22 months, middle children of 23–27 months, and older children of 28–33 months.

```{r testing_prediction2, include = FALSE}

# testing prediction 2a: To compare CONCEPT among the 3 LEARNABLE groups in the stacked bar chart

## correlation between age (in months) and CONCEPT
cor_age_CONCEPT <- tidy(cor.test(keepers_ws_TE$age_continuous, keepers_ws_TE$concept_vocab, method = "pearson"))

## one-way ANOVE to compare CONCEPT among the 3 LEARNABLE groups
keepers_ws_TE_3LEARNABLEsubset <- keepers_ws_TE %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(LEARNABLE_subset = case_when(age_months_percentile <= 22 ~ "18-22 months (V = 244.9 - 451.9)",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months (V = 491.8 - 604.1)",
                              TRUE ~ "28-33 months (V = 620.4 - 638.9)"))

aov_age_CONCEPT <- tidy(aov(concept_vocab ~ LEARNABLE_subset, data = keepers_ws_TE_3LEARNABLEsubset))

pairwise.t.test(keepers_ws_TE_3LEARNABLEsubset$concept_vocab, keepers_ws_TE_3LEARNABLEsubset$LEARNABLE_subset,
                p.adjust.method = "BH")

## mean CONCEPT by LEARNABLE subset
mean_concept_LEARNABLEsubset <- keepers_ws_TE_3LEARNABLEsubset %>%
  group_by(LEARNABLE_subset) %>%
  summarise(mean_concept = mean(concept_vocab, na.rm = T),
            sd_concept = sd(concept_vocab, na.rm = T),
            min_concept = min(concept_vocab, na.rm = T),
            max_concept = max(concept_vocab, na.rm = T)) %>%
  mutate(across(is.numeric, ~ round(.,1)))


# testing prediction 2b: To compare TE among the 3 LEARNABLE groups in the stacked bar chart

## correlation between age (in months) and TE
cor_age_TE <- tidy(cor.test(keepers_ws_TE$age_continuous, keepers_ws_TE$number_of_te, method = "pearson"))

## one-way ANOVA to compare TE among LEARNABLE
stacked_byLEARNABLE_wide <- keepers_ws_TE %>%
  select(baby_id, age_months_percentile, balance_vocab, word_vocab, concept_vocab, 
         number_of_te, total_singlet_dom, total_singlet_nondom) %>%
  # Subset developmental level (i.e., Average_90percentile) by 3 levels 
  mutate(LEARNABLE_subset = case_when(age_months_percentile <= 22 ~ "18-22 months",
                              age_months_percentile > 22 & age_months_percentile <= 27 ~ "23-27 months",
                              TRUE ~ "28-33 months")) %>%
  # Subset balance level by 3 groups
  mutate(BalSubset = case_when(balance_vocab > 0.35 ~ "Most Balanced",
                               balance_vocab <= 0.20 ~ "Least Balanced",
                               TRUE ~ "Medium Balanced"))

aov_age_TE <- tidy(aov(number_of_te ~ LEARNABLE_subset, data = stacked_byLEARNABLE_wide))

pairwise.t.test(stacked_byLEARNABLE_wide$number_of_te, stacked_byLEARNABLE_wide$LEARNABLE_subset,
                 p.adjust.method = "BH")

## mean TE by LEARNABLE subset
mean_TE_LEARNABLEsubset <- stacked_byLEARNABLE_wide %>%  
  group_by(LEARNABLE_subset) %>%
  summarise(mean_TE = mean(number_of_te, na.rm=T), 
            sd_TE = sd(number_of_te, na.rm=T),
            min_TE = min(number_of_te, na.rm=T),
            max_TE = max(number_of_te, na.rm=T)) %>%
  mutate(across(is.numeric, ~ round(.,1)))


# testing prediction 2c: To compare DOM-SINGLET among the 3 LEARNABLE groups in the stacked bar chart

## correlation between DOM-SINGLET and age (in month)
cor_age_DOMSING <- tidy(cor.test(keepers_ws_TE$age_continuous, keepers_ws_TE$total_singlet_dom, method = "pearson"))

## correlation between DOM-SINGLET and BALANCE
cor_BALANCE_DOMSING <- tidy(cor.test(keepers_ws_TE$balance_vocab, keepers_ws_TE$total_singlet_dom, method = "pearson"))

## one-way ANOVA to compare DOM-SINGLET among LEARNABLE
aov_balance_DOMSING <- tidy(aov(total_singlet_dom ~ BalSubset, data = stacked_byLEARNABLE_wide))

pairwise.t.test(stacked_byLEARNABLE_wide$total_singlet_dom, stacked_byLEARNABLE_wide$BalSubset,
                 p.adjust.method = "BH")

## mean DOM-SINGLET by LEARNABLE subset
mean_DOMSINGLET_LEARNABLEsubset <- stacked_byLEARNABLE_wide %>%  
  group_by(BalSubset) %>%
  summarise(mean_DOM_SINGLET = mean(total_singlet_dom, na.rm=T), 
            sd_DOM_SINGLET = sd(total_singlet_dom, na.rm=T),
            min_DOM_SINGLET = min(total_singlet_dom, na.rm=T),
            max_DOM_SINGLET = max(total_singlet_dom, na.rm=T)) %>%
  mutate(across(is.numeric, ~ round(.,1)))


# testing Prediction 2d: To compare NONDOM-SINGLET among the 3 LEARNABLE groups in the stacked barchart

## correlation between NONDOM-SINGLET and age (in month)
cor_age_NONDOMSING <- tidy(cor.test(keepers_ws_TE$age_continuous, keepers_ws_TE$total_singlet_nondom, method = "pearson"))

## correlation between NONDOM-SINGLET and BALANCE
cor_BALANCE_NONDOMSING <- tidy(cor.test(keepers_ws_TE$balance_vocab, keepers_ws_TE$total_singlet_nondom, method = "pearson"))

## one-way ANOVA to compare NONDOM-SINGLET among LEARNABLE
aov_balance_NONDOMSING <- tidy(aov(total_singlet_nondom ~ BalSubset, data = stacked_byLEARNABLE_wide))

pairwise.t.test(stacked_byLEARNABLE_wide$total_singlet_nondom, stacked_byLEARNABLE_wide$BalSubset,
                 p.adjust.method = "BH")

## mean NONDOM-SINGLET by LEARNABLE subset
mean_NONDOMSINGLET_LEARNABLEsubset <-stacked_byLEARNABLE_wide %>% 
  group_by(BalSubset) %>%
  summarise(mean_NONDOM_SINGLET = mean(total_singlet_nondom, na.rm=T), 
            sd_NONDOM_SINGLET = sd(total_singlet_nondom, na.rm=T),
            min_NONDOM_SINGLET = min(total_singlet_nondom, na.rm=T),
            max_NONDOM_SINGLET = max(total_singlet_nondom, na.rm=T)) %>%
  mutate(across(is.numeric, ~ round(.,1)))
```

Prediction 2a was that older children (i.e., those at a later developmental level) would have larger concept vocabularies than younger children (i.e., those at an earlier developmental level). We observed a positive correlation between age (used as a proxy for developmental level, which determines LEARNABLE) and concept vocabulary (CONCEPT) in our dataset, _r_(`r cor_age_CONCEPT$parameter[1]`) = `r round(cor_age_CONCEPT$estimate[1],2)`, $p `r papaja::printp(cor_age_CONCEPT$p.value[1])`$, and therefore confirmed the prediction. This pattern was further confirmed by a one-way ANOVA, where the three age groups significantly differed in the number of concept vocabulary they produced, ($F$(`r aov_age_CONCEPT$df[1]`, `r aov_age_CONCEPT$df[2]`) = `r round(aov_age_CONCEPT$statistic[1],2)`, $p `r papaja::printp(aov_age_CONCEPT$p.value[1])`$). Older children of 28–33 months (i.e., at a later developmental level) produced the most with an average concept vocabulary of `r round(mean_concept_LEARNABLEsubset$mean_concept[3],2)` ($p$s < .001), those middle children of 23–27 months (i.e., at an intermediate developmental level) produced an average concept vocabulary of `r round(mean_concept_LEARNABLEsubset$mean_concept[2],2)`, and those younger children of 18–22 months (i.e., at an earlier developmental level) produced the least with an average concept vocabulary of `r round(mean_concept_LEARNABLEsubset$mean_concept[1],2)` ($p$s < .001).

Prediction 2b was that older children would produce more translation equivalents than younger children. First, we observed a positive correlation between age (our proxy for LEARNABLE) and number of translation equivalents in our dataset, _r_(`r cor_age_TE$parameter[1]`) = `r round(cor_age_TE$estimate[1],2)`, $p `r papaja::printp(cor_age_TE$p.value[1])`$, and therefore confirmed the prediction. In a one-way ANOVA with age group as factor, we further found that groups differed in how many translation equivalents they produced ($F$(`r aov_age_TE$df[1]`, `r aov_age_TE$df[2]`) = `r round(aov_age_TE$statistic[1],2)`, $p `r papaja::printp(aov_age_TE$p.value[1])`$). Younger children of 18–22 months produced an average of `r round(mean_TE_LEARNABLEsubset$mean_TE[1],2)` translation equivalents, middle children of 23–27 months produced an average of `r round(mean_TE_LEARNABLEsubset$mean_TE[2],2)` translation equivalents, and older children of 28–33 months produced an average of `r round(mean_TE_LEARNABLEsubset$mean_TE[3],2)` translation equivalents ($p$s < .01). 

Prediction 2c was that both older children and those with the least balanced vocabularies (BALANCE) would produce more dominant-language singlets (DOM-SINGLET). This pattern was confirmed by the results from our dataset, with a positive correlation between dominant-language singlets (DOM-SINGLET) and age (which determined LEARNABLE), _r_(`r cor_age_DOMSING$parameter[1]`) = `r round(cor_age_DOMSING$estimate[1],2)`, $p `r papaja::printp(cor_age_DOMSING$p.value[1])`$, and a negative correlation between BALANCE and dominant-language singlets (DOM-SINGLET), _r_(`r cor_BALANCE_DOMSING$parameter[1]`) = `r round(cor_BALANCE_DOMSING$estimate[1],2)`, $p `r papaja::printp(cor_BALANCE_DOMSING$p.value[1])`$. As shown in Figure 3 Panel B, children were divided into least balanced (range of balance: .00 - .20), medium balanced (range of balance: .20 - .35) and most balanced (range of balance: .35 - .50) groups (i.e., the same criteria as in Figure 5). In a one-way ANOVA with balance group as a between-subjects factor, we observed that the least balanced children produced the most singlets in their dominant language ($p$s < .001), with the least balanced, medium balanced, most balanced children producing respectively: `r round(mean_DOMSINGLET_LEARNABLEsubset$mean_DOM_SINGLET[1],2)`, `r round(mean_DOMSINGLET_LEARNABLEsubset$mean_DOM_SINGLET[2],2)`, and `r round(mean_DOMSINGLET_LEARNABLEsubset$mean_DOM_SINGLET[3],2)` words in their dominant language ($F$(`r aov_balance_DOMSING$df[1]`, `r aov_balance_DOMSING$df[2]`) = `r round(aov_balance_DOMSING$statistic[1],2)`, $p `r papaja::printp(aov_balance_DOMSING$p.value[1])`$).

Prediction 2d was that older children and those with the most balanced vocabularies (BALANCE) would produce more singlets in their non-dominant language. This pattern was also observed in our dataset, with a positive correlation between the number of non-dominant singlets (NONDOM-SINGLET) and age (which determined LEARNABLE), _r_(`r cor_age_NONDOMSING$parameter[1]`) = `r round(cor_age_NONDOMSING$estimate[1],2)`, $p = `r papaja::printp(cor_age_NONDOMSING$p.value[1])`$, and a positive correlation between BALANCE and the number of non-dominant singlets (NONDOM-SINGLET), _r_(`r cor_BALANCE_NONDOMSING$parameter[1]`) = `r round(cor_BALANCE_NONDOMSING$estimate[1],2)`, $p `r papaja::printp(cor_BALANCE_NONDOMSING$p.value[1])`$. In a one-way ANOVA with balance group as a between-subjects factor, we confirmed that children who differed in how balanced their vocabulary knowledge was also differed in how many singlets they produced in their non-dominant language ($F$(`r aov_balance_NONDOMSING$df[1]`, `r aov_balance_NONDOMSING$df[2]`) = `r round(aov_balance_NONDOMSING$statistic[1],2)`, $p `r papaja::printp(aov_balance_NONDOMSING$p.value[1])`$). As shown in Figure 3 Panel B, we observed that children produced very few singlets in their non-dominant language, although the most balanced children produced the most singlets in their non-dominant language (mean of the most balanced children = `r round(mean_NONDOMSINGLET_LEARNABLEsubset$mean_NONDOM_SINGLET[3],2)` > mean of the medium balanced children = `r round(mean_NONDOMSINGLET_LEARNABLEsubset$mean_NONDOM_SINGLET[2],2)` > mean of the most balanced children = `r round(mean_NONDOMSINGLET_LEARNABLEsubset$mean_NONDOM_SINGLET[1],2)`; $p$s < .001).


## 2.2.4 Testing Prediction Set 3: Rate of translation equivalent learning
Prediction Set 3 pertained to the overall nature of translation equivalent learning, describing expected patterns of translation equivalent learning under the Neutral Account, the Avoidance Account, or the Preference Account. To directly test the correspondence of our data with these different accounts, we built a linear regression model predicting the observed number of translation equivalents from the Bilingual Vocabulary Model using the formula TE = DOM×NONDOM/LEARNABLE , and we allowed the model to estimate BIAS parameter. 

First, we will walk through the parameters in this model. The size of dominant vocabulary (DOM) and size of non-dominant vocabulary (NONDOM) were taken to be the number of words produced by individual children observed in the vocabulary data. As for the number of learnable vocabulary (LEARNABLE), this was determined by the averaging of English and French productive CDI vocabulary at the 90th percentile at different ages which was obtained from Wordbank (Frank et al., 2016), and Table 7 lists the denominator at different ages. For example, for an 18 month-old infant, the denominator was 244.9 words which was calculated by averaging the 268.7 English words and 221.1 French words, based on what 18-month-old children would typically produce at the 90th percentile. For children who were between 31 to 33 months in our dataset, the 90th percentile of 30-month-old children was used since the 90th percentile information was available only up to 30 months.

```{r table7, results = "asis"}
# read in the percentile file
ws_percentile <- read.csv(here::here("data_keepers/ws_percentile.csv")) %>%
  # as the upper age limit of the CDI-WS is 30m, create a new row for age 30-33m
  mutate(age_months_percentile = case_when(age_months_percentile == 30 ~ "30 - 33", 
                                           TRUE ~ as.character(age_months_percentile))) %>%
  # rename variables for presentation
  rename("Age (months)" = age_months_percentile,
         "Number of English words produced at 90th percentile" = EngWS_90percentile,
         "Number of French words produced at 90th percentile" = FrWS_90percentile,
         "Average (LEARNABLE)" = Average_90percentile) %>%
  # round to 1 decimal place
  mutate(across(where(is.numeric),round,1))

kable(ws_percentile,
        format = "latex", booktabs = TRUE, align = "c",
        caption = "Table 7. The number of total English and French productive CDI vocabulary at the 90th percentile at different ages, and the average between the two which serves as the denominator in our computation model.") %>%
  kableExtra::kable_styling(font_size = 10) %>%
  column_spec(1, width = "75px") %>%
  column_spec(2:4, width = "125px")

```

Furthermore, the intercept of the linear regression model was set at 0 since no translation equivalents are expected to be produced if a child does not know any dominant or non-dominant vocabulary (i.e., when the predictor variables are 0). To reproduce the Bilingual Vocabulary Model’s formula TE = DOM×NONDOM/LEARNABLE, an interaction between dominant and non-dominant vocabulary was entered in the model, but main effects were not included in the model (denoted in R by using a colon rather than an asterisk between the interacting predictors). Therefore, our final linear regression model equation was:

_ObservedTE ~ 0 + Dominant vocabulary:Non-dominant vocabulary/90 percentile of CDI items._

\noindent (In R language, the model was entered as:

_ObservedTE * 90 percentile of CDI items ~ 0 + Dominant vocabulary:Non-dominant vocabulary_)

\noindent With the observed number of translation equivalents as the dependent variable, the regression coefficient estimated by the model would indicate how the BIAS parameter was consistent with the empirical vocabulary data, which would then indicate whether bilingual children were biased towards or against learning translation equivalents. If the coefficient is close to 1, then there is no bias and translation equivalents are learned equally to other words (i.e., the Neutral Account). Otherwise, a coefficient less than 1 represents a bias against learning translation equivalents where translation equivalents are less easily learned (i.e., the Avoidance Account), and a coefficient greater than 1 represents a bias towards learning translation equivalents where translation equivalents are more easily learned (i.e., the Preference Account). 

```{r testing_prediction3, include = FALSE}

# testing Prediction 3: linear regression model comparing simulated and observed TE

## creating predicted TEs for simulation
keepers_ws_TE_simulation <- keepers_ws_TE %>%
  mutate(Predicted_TE_percentile = total_words_dom * total_words_nondom/Average_90percentile) %>%
  select(baby_id, ID_testdate, Predicted_TE_percentile, number_of_te, Average_90percentile, total_words_dom, total_words_nondom, 
         word_vocab, age_months_binned)

## linear regression model
test_prediction3_model <- keepers_ws_TE_simulation %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + total_words_dom:total_words_nondom, data = .)


# checking outliers
## calculating cook's distance
check_outliers_model <- keepers_ws_TE_simulation %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + total_words_dom:total_words_nondom,
     data = .)

keepers_ws_TE_simulation$CD <- cooks.distance(check_outliers_model)

number_of_outliers <- filter(keepers_ws_TE_simulation, CD > 0.4) # check number of outliers with cook's distance > 0.4

## linear regression model without the outliers
model_remove_outliers <- keepers_ws_TE_simulation %>%
  filter(CD < 0.4) %>% 
  lm(number_of_te*(Average_90percentile) ~ 0 + total_words_dom:total_words_nondom, 
     data = .)


# splitting the linear regression model for children with WORD < 300 and those with WORD > 300

## linear regression model for those with WORD > 300
percentile_model_more300w <- keepers_ws_TE_simulation %>%
  filter(word_vocab > 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + total_words_dom:total_words_nondom, 
     data = .)

## linear regression model for those with WORD < 300
percentile_model_less300w <- keepers_ws_TE_simulation %>%
  filter(word_vocab < 300) %>%
  lm(number_of_te*(Average_90percentile) ~ 0 + total_words_dom:total_words_nondom, 
     data = .)

```

Our model showed an excellent model fit of $R^2$ = `r round(summary(test_prediction3_model)$r.squared,2)`, indicating that our model explained `r round(summary(test_prediction3_model)$r.squared,2) * 100`% of the variance in bilinguals’ translation equivalent knowledge. The linear regression model estimated a BIAS coefficient of `r round(summary(test_prediction3_model)$coefficient[1],2)`, $p `r papaja::printp(summary(test_prediction3_model)$coefficient[4])`$. This value is extremely close to 1, suggesting that our data are consistent with the account whereby translation equivalents are learned equivalently to other words.

To illustrate the close fit between the Neutral Account and our data, we used the Bilingual Vocabulary Model formula TE = 1 × (DOM×NONDOM/LEARNABLE) to estimate each child’s expected translation equivalent knowledge (setting BIAS = 1), which is plotted against our observed data in Figure 6. Expected and observed translation equivalents were closely aligned with the Neutral Account of the Bilingual Vocabulary Model (i.e., BIAS = 1), suggesting that the Neutral Account provides a parsimonious explanation for bilinguals’ translation equivalent knowledge. This provides evidence for the notion that translation equivalents are neither harder nor easier to learn than singlets in bilingual vocabulary learning. Note that visual inspection suggested that there could be some possible outliers. Cook’s distance was estimated for our linear regression model listed above and identified `r words(length(number_of_outliers$ID_testdate))` data points with a cook’s distance over 0.4. After removing those `r words(length(number_of_outliers$ID_testdate))` data points, the linear regression model returned a coefficient of `r round(summary(model_remove_outliers)$coefficient[1],2)`, $p `r papaja::printp(summary(model_remove_outliers)$coefficient[4])`$, with $R^2$ = `r round(summary(model_remove_outliers)$r.squared,2)`. As the model fit was similar to the model without eliminating the `r words(length(number_of_outliers$ID_testdate))` outlier data points, we proceeded with the full data set keeping the `r words(length(number_of_outliers$ID_testdate))` potential outlier data points.

```{r fig6, fig.cap="The number of simulated and observed translation equivalents plotted against each other. The dots represent the value of a child tested on the CDI, with their observed number of TEs and the expected number of TEs based on our model. The diagonal dashed line represents the case where the bias parameter equals 1 (BIAS = 1) such that the predicted and observed number of TEs are equal, and the solid blue line represents the model predictions.", echo=FALSE, dpi=600, fig.align='center', fig.height=7, out.height="60%", out.width="60%"}

# ploting Y = observed rawTE  & X = Predicted rawTE 
keepers_ws_TE_simulation %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  xlim(-10,450) +
  ylim(-10,450) +
  theme_minimal() + 
  theme(text = element_text(size=16))

```

Despite the good overall fit to the data, a close examination of Figure 6 suggested that the model might less closely fit the data of children with smaller vocabulary sizes. Figure 7 displays the model fit separately for children with a word vocabulary (WORD) less than 300 words and those with a word vocabulary (WORD) of 300 or greater. Based on visual inspection, the slope of translation equivalent learning appeared steeper for children with less than 300 total vocabulary, suggesting that translation equivalents are more easily learned (i.e., BIAS > 1); whereas the slope of translation equivalent learning appeared to align with the Neutral Account of the Bilingual Vocabulary Model (i.e., BIAS = 1) for children with more than 300 total vocabulary. To further explore this pattern, we ran the same linear regression twice, separately for children with less than 300 total vocabulary and for those with more than 300 total vocabulary. The model for those with larger total word vocabulary (WORD) returned a coefficient of BIAS = `r round(summary(percentile_model_more300w)$coefficient[1],2)`, $p `r papaja::printp(summary(percentile_model_more300w)$coefficient[4])`$, whereas the model for those with less than 300 total word vocabulary (WORD) returned a coefficient of BIAS = `r round(summary(percentile_model_less300w)$coefficient[1],2)`, $p `r papaja::printp(summary(percentile_model_less300w)$coefficient[4])`$. Both models fit well, although a somewhat better fit was obtained for children with larger vocabulary size ($R^2$ = `r round(summary(percentile_model_more300w)$r.squared,2)`) than children with smaller vocabulary size ($R^2$ = `r round(summary(percentile_model_less300w)$r.squared,2)`). Overall, this analysis suggests that translation equivalent learning for children with larger vocabularies corresponds best to the Neutral Account, but translation equivalent learning for children with smaller vocabularies corresponds best to the Preference Account.

&nbsp;
```{r fig7, fig.cap="The number of observed translation equivalents as a function of number of expected translation equivalents under the Bilingual Vocabulary Model other (represented by the blue solid line), plotted separately for children with fewer than 300 word vocabulary (left panel) and for those with more than 300 word vocabulary (right panel). The dashed diagonal line represents the case where the parameter equals 1 (BIAS = 1) such that the predicted and observed number of TEs are equal.", echo=FALSE, dpi=600, fig.align='center', fig.height=4, out.width="120%"}

# plotting the two separate models (those with WORD < 300 + those with WORD > 300)
TEprediction_percentile_facet_lessW300 <- keepers_ws_TE_simulation %>%
  mutate(W_group = if_else(word_vocab < 300, "Less than 300 word vocabulary (WORD)", "More than 300 word vocabulary (WORD)")) %>%
  filter(W_group == "Less than 300 word vocabulary (WORD)") %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs",
       title = "Less than 300 word vocabulary (WORD)") +
  xlim(0,80) +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal() +
  theme(plot.title = element_text(size = 11, hjust = 0.5),
  text = element_text(size=11))

TEprediction_percentile_facet_moreW300 <- keepers_ws_TE_simulation %>%
  mutate(W_group = if_else(word_vocab < 300, "Less than 300 word vocabulary (WORD)", "More than 300 word vocabulary (WORD)")) %>%
  filter(W_group == "More than 300 word vocabulary (WORD)") %>%
  ggplot(aes(x = Predicted_TE_percentile, y = number_of_te)) +
  labs(x = "Number of TEs predicted by the Bilingual Vocabulary Model", y = "Observed total number of TEs",
       title = "More than 300 word vocabulary (WORD)") +
  geom_smooth(method = "lm", se = F) +
  geom_point(shape = 23) +
  geom_abline(linetype = 2, alpha = 0.5) +
  theme_minimal() +
  theme(plot.title = element_text(size = 11, hjust = 0.5),
        text = element_text(size=11))

TEprediction_percentile_facetByW300 <- 
  ggarrange(TEprediction_percentile_facet_lessW300 + rremove("x.title"), 
            TEprediction_percentile_facet_moreW300 + rremove("xy.title"), 
            ncol = 2, nrow = 1) %>%
  annotate_figure(bottom = text_grob("Number of TEs predicted by the Bilingual Vocabulary Model"))

TEprediction_percentile_facetByW300
```

# Discussion
The aim of the current study was to better understand translation equivalent learning in bilingual children, specifically investigating whether translation equivalents are harder (Avoidance Account), easier (Preference Account), or similar (Neutral Account) for bilingual children to learn than singlet words (i.e., the first label for a particular referent). To test these accounts, we developed the Bilingual Vocabulary Model, which quantifies the number of translation equivalents that children produce as a product of words they know in their dominant and non-dominant language, divided by the number of words that are learnable at their developmental level. The inclusion of a learnability parameter was a unique aspect of our approach, and was crucial to quantifying how many translation equivalents versus singlets were available to be learned given the child’s age. The relative difficulty of learning translation equivalents relative to singlets was modeled via the bias parameter (BIAS), which indicated whether translation equivalent learning is consistent with the Avoidance (BIAS < 1), Preference (BIAS > 1), or Neutral Account (BIAS = 1). 

## Confirmation of model predictions
In Study 1, we simulated vocabulary and translation equivalent knowledge based on the Bilingual Vocabulary Model, and in Study 2 we tested three sets of model-generated predictions using archival CDI data from 200 bilingual children aged 18-33 months. Three sets of model predictions were confirmed in our empirical dataset. 

Prediction Set 1 pertained to relationships between translation equivalent knowledge, vocabulary balance, and vocabulary size in the dominant and non-dominant languages. In both the simulated and observed data, children with more balanced vocabularies (i.e., those who produced a similar number of words in each of their languages) produced more translation equivalents. This pattern is consistent with reports from previous research (David & Wei, 2008; Legacy et al., 2016; Montanari, 2010; Pearson et al., 1995; 1997). Moreover, both the simulated and observed data showed that the children who produced more total words produced more translation equivalents, which is in line with previous research showing that the number of translation equivalents a bilingual child knows increases along with their total vocabulary size (Legacy et al., 2016; Montanari, 2010). Additionally, both our simulated and observed data showed that the more words children knew in their dominant language, the more translation equivalents they produced. This pattern is consistent with previous research reporting a positive correlation between bilingual children’s size of dominant language vocabulary and the proportion of translation equivalents (Legacy et al., 2016; Poulin-Dubois et al., 2013). Finally, both our simulated and observed data showed that the more words children produced in their non-dominant language, the more translation equivalents they produced. A similar pattern has been reported by Legacy and colleagues (2016), where vocabulary size in the non-dominant language positively correlated with the proportion of translation equivalents known by the child (Legacy et al., 2016). 

Prediction Set 2 pertained to the relationship between the number of potentially learnable words for a child (constrained by their developmental level) and the production of translation equivalents and singlets (i.e., words without a translation equivalent). We operationalized developmental level in terms of children’s age, and set the number of learnable words at the number produced by children at the 90th percentile for that age (averaged across French and English). Both simulated and observed data showed older children had larger concept vocabularies, a pattern consistent with reports from previous literature (Pearson et al., 1993). Likewise, Prediction 2b was confirmed by the observed data as older children produced more translation equivalents than younger children. This pattern is consistent with the literature that bilingual children learn more translation equivalents as they grow older (David & Wei, 2008; Legacy et al., 2016). Predictions 2c and 2d were also confirmed by our vocabulary data. While children produced more singlets in both the dominant and non-dominant languages with age, the least balanced children produced the most singlets in their dominant language and the most balanced children produced the most singlets in their non-dominant language. These patterns are also in line with the notion that bilingual children learn words in proportion to their relative exposure to each language (e.g., Boyce et al., 2013; Hoff et al., 2012; Marchman et al., 2010; Pearson et al., 1997; Place & Hoff, 2011). Therefore, within the number of words that are potentially learnable at a particular developmental level, bilingual children with less balanced language exposure have more opportunities to learn more words in their dominant language than their non-dominant language, whereas bilingual children with more balanced language exposure have more equal opportunities to learn words in each of their language.

Overall, we observed a strong correspondence between the data simulated under the Bilingual Vocabulary Model and our observed data. Moreover, our model predicted numerous disparate patterns that have been previously reported in the literature. 

Having validated our overall approach, Prediction 3 motivated using the Bilingual Vocabulary Model to quantitatively test three conceptual accounts of translation equivalent learning: the Avoidance Account, the Preference Account, and the Neutral Account. The number of translation equivalents children produced was a very close fit to the Neutral Account (i.e., translation equivalents learning are similar to learn than singlets), with this model explaining `r round(summary(test_prediction3_model)$r.squared,2) * 100`% of variance in the data. However, there was some indication that the Neutral Account provided a poorer fit for children with smaller vocabulary sizes. Modeling their data separately, we found evidence for the Preference account: younger children at around `r round(keepers_ws_TE %>% filter(word_vocab < 300) %>% summarise(mean_age = mean(age_continuous, na.rm = T)),0)` months appeared to learn translation equivalents more easily than singlets, whereas older children at around `r round(keepers_ws_TE %>% filter(word_vocab > 300) %>% summarise(mean_age = mean(age_continuous, na.rm = T)),0)` months learned translation equivalents similarly to singlets. This could indicate a qualitative shift in word learning that occurs as bilingual children develop and learn more words, from the Preference Account to the Neutral Account. This pattern of a qualitative shift contradicts previous evidence proposing that bilingual children between the ages of 6 months and 7 years learn translation equivalents more easily than singlets (Bilson et al., 2015). The discrepancy could potentially be explained by the difference in how expected patterns of translation equivalent learning were simulated in each study. Previous approaches simulated bilingual language learning using data from randomly-paired monolinguals or lexicons of two different bilinguals as a reference point for the Neutral Account (e.g., Bilson et al., 2015; Pearson et al., 1995). The Bilingual Vocabulary Model represents a significant theoretical and methodological advance, as it does not make reference to randomly-paired children, and instead uses children’s own dominant and non-dominant vocabulary size, together with their developmental level, to gauge how many translation equivalents they are expected to learn. 

## Developmental change in translation equivalent learning
The developmental change of bilingual children’s ability to learn translation equivalents could be related to changes in children’s use of one-to-one mapping biases such as mutual exclusivity. As revealed by previous studies, younger children and children with smaller vocabulary size and thus less vocabulary knowledge seem to not have a strong bias for a one-to-one mapping between words and referents (Halberda, 2003; Lewis et al., 2020; Merriman et al., 1989). In other words, children with less experience in word learning may be more inclined to accept multiple words for the same referent (Halberda, 2003; Merriman et al., 1989). In contrast, children with larger vocabulary size appear to become more certain about the one-to-one mapping relationships between referents and words (Lewis et al., 2020), while at the same time they also take better advantage of their bilingual exposure to accept that referents can have different words between languages [@Au_Glusman_1990; @Davidson_Tell_2005]. At first blush, strengthening of one-to-one mapping biases over age could explain why younger children appear to learn relatively more translation equivalents than older children. Yet, this explanation would not predict that younger bilinguals’ data would follow the Preference Account as we observed, and might instead predict development from the Neutral to the Avoidance account, before perhaps returning to the Neutral account once children realize that each referent should have a label in each language. Thus, changes in one-to-one mapping biases do not provide a complete explanation for our results.

Another possible explanation is that the nature of bilingual input changes as children become more advanced word learners. Some recent research has suggested that bilingual parents sometimes code-switch to use a word that they know to be in their child’s vocabulary (Kremin et al., 2021; Nicoladis & Secco, 2000). For example, a caregiver may choose to say to their English–French bilingual child “Can you grab the livre?” if they know their child understands the French word “livre” but not the English equivalent “book”. This may provide fewer opportunities for children to learn translation equivalents, since they would be less exposed to the unfamiliar translation equivalents. However, this observation would predict that young bilinguals would know fewer translation equivalents as a proportion of their vocabularies than older bilinguals, which was opposite to what we observed. Thus, changes in bilingual input also do not provide an adequate explanation for our results of a qualitative change in translation equivalent learning. Overall, more research will be needed to understand why translation equivalents appear to be over-represented in younger bilinguals’ vocabularies.

## Assumptions, limitations, and future directions
Our Bilingual Vocabulary Model presented an integrated computational account of translation equivalent learning, focusing on the joint probability of learning the word for a concept in each language. To do so, our model parameters included the number of words produced in each language, as well as children’s developmental level. However, our model does not consider that vocabulary acquisition could also be predicted by other factors such as children’s ability to segment words from the continuous stream of speech (e.g., Brent & Siskind, 2001; Swingley & Humphrey, 2018), children’s efficiency of processing words they hear (e.g., Hurtado et al., 2013; Weisleder & Fernald, 2013), and cognitive development and perceptual bias (e.g., Benedict ,1979; Goodman et al., 2008), as well as other qualitative factors including family socioeconomic status (e.g., Fernald et al., 2013; Hoff, 2003), parents’ interaction with their children (e.g., Blewitt et al., 2009; Yu & Smith, 2012), and the quality of parental language input over time (e.g., Raneri et al., 2020; Rowe, 2012). It would be interesting for future studies to take into consideration the qualitative factors in a bilingual word learning model, including different amounts of input and the quality of that input. Such a model may better characterize and predict bilingual vocabulary development as a function of experience. Moreover, it would be important to extend our Bilingual Vocabulary Model to longitudinal data or data of a different bilingual population to investigate if it is possible to replicate the qualitative shift where bilingual children’s ability to learn translation equivalents appears to change across development.

Another limitation of our model is that it takes a somewhat simplified view of translation equivalents, assuming that children encounter the same conceptual categories in each of their languages and are exposed to the corresponding words. However, the reality of bilingual experience might be more complex. First, some concepts expressed as a single word in one language may be lexicalized by two words in another language (e.g., English has a single word for “sister” but Mandarin has separate words for _“jiějie”_ [older sister] and _“mèimei”_ [younger sister]). As another example, some words may not have a translation equivalent in the other language (e.g., the Japanese word _“sushi”_ is borrowed into other languages). Still other languages categorize objects differently within conceptual categories (e.g., a shallow dish might be called a “bowl” in English but an _“assiette”_ [plate] in French). There is mixed evidence for whether bilingual adults maintain separate (Jared et al., 2012) versus integrated (Ameel et al., 2009) conceptual representations across their two languages, and little to no data from bilingual children. Second, our model did not take into account that bilingual children appear to learn similar-sounding translation equivalents (i.e., cognates like the English–French pair “banana” – _“banane”_) more easily than those that do not share similar phonological form (e.g., the English–French pair “dog” – _“chien”_) [@Bosch_Ramon-Casas_2014]. Likewise, some bilingual children learn language pairs that share more cognates than others (e.g., Spanish and Italian share more phonologically similar translation equivalents than English and French; Schepens et al., 2013). While more research will be needed on how these factors impact bilingual vocabulary learning, the close correspondence between our model and data from bilingual children suggest that even if our assumptions are a simplification, deviations from these assumptions might have a relatively small impact. Moreover, if they do prove to be important, such factors could be added to future iterations of the Bilingual Vocabulary Model.

Another assumption of our model was that bilingual children hear labels from both languages for the same set of referents. However, following the Complementarity Principle [@Grosjean_2016], bilinguals may have different experiences in each of their languages. For example, a French–English bilingual child who always spends bathtime with an English-speaking parent might encounter bath words primarily in English (e.g., “soap”, “bath”, “bubbles”), therefore having less opportunity to acquire their translation equivalents in French. At the same time, cross-linguistic data has provided evidence of a high degree of commonality in the first words children produced (e.g., Braginsky et al., 2019; Tardif et al., 2008). For example, words for important people (“mommy”, “daddy”), social routines (“hi”, “bye”, “yes”, “no”), and common nouns (“ball”, “dog”) are among the first words children acquired across languages and cultures. It therefore seems reasonable to expect that bilingual children growing up in a bilingual household would be exposed to a similar set of referents and labels in each of their languages. Moreover, if indeed bilingual children tend to encounter different words in different linguistic contexts, we would have expected our data to be consistent with the Avoidance account (e.g., fewer than expected translation equivalents), which is not what we observed. Nonetheless, future studies of bilingual corpora could directly address whether early translation equivalent learning might be impacted by the Complementarity Principle.

Finally, we must note the reciprocal relationship in the Bilingual Vocabulary Model between the bias parameter (BIAS) and the parameter that accounts for how many words are potentially learnable at a particular age (LEARNABLE). Under the Bilingual Vocabulary Model, the learnability parameter and the bias parameter jointly predict the number of translation equivalents that a child will learn based on the number of words that they know in each of their languages. That is, if the assumed learnability parameter changes by a factor of two (e.g., whereby only 122 words in each language are learnable for 18-month-olds, rather than 244), then estimates of the bias parameter will also change by a factor of two (i.e., rather than a parameter of 2.22 which supports the Preference account, we would estimate a parameter of 1.11 which is closer to the Neutral Account). Our model estimated the number of learnable words to be the number that children at the 90th percentile at a particular age produce. Small changes to this approach (e.g., taking the number of words children at the 95th percentile produce) would likely not drastically alter our results, nor change the qualitative shift that we observed in our data. Nonetheless, future research will be needed to more precisely quantify the number of words that are learnable by particular children at particular ages.

## Conclusions
In sum, the acquisition of translation equivalents has been considered a special component in bilingual children’ vocabulary development. Previous research has put forward three diverging accounts of translation equivalent learning: the Avoidance Account, the Preference Account, and the Neutral Account. We proposed the Bilingual Vocabulary Model, which provides a quantitative way to test these accounts, by modeling translation equivalent learning in relation to vocabulary size in each language and the number of potentially learnable words, which is constrained by children’s developmental level. Results using archival data from a large number of young French–English bilingual children showed that our model was a good fit to the Neutral Account, although younger children may show a preference for translation equivalent learning in line with the Preference Account. Moreover, our model parsimoniously explained previously disparate observations about bilingual children’s translation equivalent learning, for example that the number of translation equivalents children produce is tightly linked to their vocabulary size in their non-dominant language, and thus all else equal children with more balanced vocabularies will produce more translation equivalents. Future studies with data from other populations of bilinguals will be important to more fully test the Bilingual Vocabulary Model.

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}

<div id = "refs"></div>
\endgroup
